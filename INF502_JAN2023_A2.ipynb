{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "1s8Xq3fLsKBg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "fc987df7-0025-4464-8e7c-4ec3dc5b35ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gdrive_dir=\"/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1\"\n",
        "%cd \"{gdrive_dir}\""
      ],
      "metadata": {
        "id": "MyYVuueK8Ork",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "305e2386-3871-4734-ea88-93a7e92bb902"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/microsoft/LMOps.git"
      ],
      "metadata": {
        "id": "Aa1WwljV9-1T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "aa130754-d22c-4103-f9d5-207e02756411"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'LMOps' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "icl_base_dir= gdrive_dir + \"/LMOps/understand_icl\"\n",
        "gpt_icl_dir = icl_base_dir + \"/gpt_icl/\"\n",
        "%mkdir -p \"{gpt_icl_dir}\"\n",
        "%cd \"{icl_base_dir}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUZsA2RnCpzO",
        "outputId": "17f5626a-dda6-4da9-9d6d-d1e1cc14fcc8",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mYuy8RJoAnw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "be1f83f9-a6f8-4222-864a-b467801284c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets==2.4.0\n",
            "  Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets==2.4.0) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.4.0) (14.0.2)\n",
            "Collecting dill<0.3.6 (from datasets==2.4.0)\n",
            "  Downloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.8/95.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.4.0) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.4.0) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.4.0) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets==2.4.0) (3.4.1)\n",
            "Collecting multiprocess (from datasets==2.4.0)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.4.0) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.4.0) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.4.0) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==2.4.0) (23.2)\n",
            "Collecting responses<0.19 (from datasets==2.4.0)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.4.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.4.0) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.4.0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.4.0) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.4.0) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.4.0) (4.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==2.4.0) (3.13.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==2.4.0) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==2.4.0) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.4.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.4.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.4.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.4.0) (2024.2.2)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets==2.4.0)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading multiprocess-0.70.13-py310-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.4.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.4.0) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets==2.4.0) (1.16.0)\n",
            "Installing collected packages: dill, responses, multiprocess, datasets\n",
            "\u001b[33m  WARNING: The script datasets-cli is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed datasets-2.4.0 dill-0.3.5.1 multiprocess-0.70.13 responses-0.18.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --user datasets==2.4.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --user tensorboard scikit-learn"
      ],
      "metadata": {
        "id": "7Ax6blvqHU05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "5a60024c-2ffd-40a7-808e-b2e2a1f937b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.15.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.62.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.5.2)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.25.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --user jsonlines"
      ],
      "metadata": {
        "id": "l6VasVssHY8K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "239fff05-9784-46b7-e045-e99f6296ec71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jsonlines\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines) (23.2.0)\n",
            "Installing collected packages: jsonlines\n",
            "Successfully installed jsonlines-4.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --user -e fairseq/"
      ],
      "metadata": {
        "id": "epCedCjJHa83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "5482d95f-27b8-45b6-a304-de210127b53b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/fairseq\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+aa2b468) (1.16.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+aa2b468) (3.0.8)\n",
            "Collecting hydra-core<1.1,>=1.0.7 (from fairseq==1.0.0a0+aa2b468)\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf<2.1 (from fairseq==1.0.0a0+aa2b468)\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+aa2b468) (2023.12.25)\n",
            "Collecting sacrebleu>=1.4.12 (from fairseq==1.0.0a0+aa2b468)\n",
            "  Downloading sacrebleu-2.4.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+aa2b468) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+aa2b468) (4.66.2)\n",
            "Collecting bitarray (from fairseq==1.0.0a0+aa2b468)\n",
            "  Downloading bitarray-2.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.3/288.3 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+aa2b468) (1.25.2)\n",
            "Collecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq==1.0.0a0+aa2b468)\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq==1.0.0a0+aa2b468) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq==1.0.0a0+aa2b468) (4.10.0)\n",
            "Collecting portalocker (from sacrebleu>=1.4.12->fairseq==1.0.0a0+aa2b468)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+aa2b468) (0.9.0)\n",
            "Collecting colorama (from sacrebleu>=1.4.12->fairseq==1.0.0a0+aa2b468)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+aa2b468) (4.9.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->fairseq==1.0.0a0+aa2b468) (2.21)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->fairseq==1.0.0a0+aa2b468) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->fairseq==1.0.0a0+aa2b468) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->fairseq==1.0.0a0+aa2b468) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq==1.0.0a0+aa2b468) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->fairseq==1.0.0a0+aa2b468) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq==1.0.0a0+aa2b468) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->fairseq==1.0.0a0+aa2b468) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->fairseq==1.0.0a0+aa2b468) (1.3.0)\n",
            "Building wheels for collected packages: fairseq, antlr4-python3-runtime\n",
            "  Building editable for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-1.0.0a0+aa2b468-0.editable-cp310-cp310-linux_x86_64.whl size=9271 sha256=de899c6a9cee850daf79a8806af54995e445ba0bd3154dd2c7149cf5bf6983db\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-kljsqwuw/wheels/dc/d8/89/b6943c8a524270e63d8d42da684c0510d91b2023d984f53941\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141210 sha256=207a1adefe4586a0e7bd76b5b933eab0864db919ebba69f34f17358c2bb085c1\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\n",
            "Successfully built fairseq antlr4-python3-runtime\n",
            "Installing collected packages: bitarray, antlr4-python3-runtime, portalocker, omegaconf, colorama, sacrebleu, hydra-core, fairseq\n",
            "\u001b[33m  WARNING: The script sacrebleu is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The scripts fairseq-eval-lm, fairseq-generate, fairseq-hydra-train, fairseq-interactive, fairseq-preprocess, fairseq-score, fairseq-train and fairseq-validate are installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed antlr4-python3-runtime-4.8 bitarray-2.9.2 colorama-0.4.6 fairseq-1.0.0a0+aa2b468 hydra-core-1.0.7 omegaconf-2.0.6 portalocker-2.8.2 sacrebleu-2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboardX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lh-oQc9ukrTh",
        "outputId": "9a40519b-4635-47bb-85c6-c5fb7ffecc5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/101.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (23.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GIaDw9K3VjNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json\" -nc -P \"{gpt_icl_dir}\""
      ],
      "metadata": {
        "id": "8I3_qXItW-M4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "a1e7753f-4f19-4d9a-d694-dee17df98850"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File ‘/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json’ already there; not retrieving.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe\" -nc -P \"{gpt_icl_dir}\""
      ],
      "metadata": {
        "id": "dLbOPoaROuQk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "5027329e-5648-4463-fc5b-49db54b76d86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File ‘/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe’ already there; not retrieving.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://dl.fbaipublicfiles.com/fairseq/models/lm/en_dense_lm_1_3b.tar.gz\" -nc -P \"{gpt_icl_dir}\""
      ],
      "metadata": {
        "id": "w0RVqXvdqcg_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "a94ce267-8f0f-4ab1-f6dd-3085b49658e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File ‘/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b.tar.gz’ already there; not retrieving.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xvfk \"{base_dir}/gpt_icl/en_dense_lm_1_3b.tar.gz\" -C \"{gpt_icl_dir}\""
      ],
      "metadata": {
        "id": "-2GiCGpIqm0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "bf4e3b86-f591-482d-c783-136dbd7e41dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tar: k: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash run.sh en_dense_lm_1_3b gptmodel_large sst2 32 2 0 \"{icl_base_dir}/output\" \"{icl_base_dir}\" 0.0005"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGtk_vzWawIo",
        "outputId": "5385ab15-4608-4286-ba0d-e15f972f0cd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst2/ft/record_info.jsonl': No such file or directory\n",
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst2/en_dense_lm_1_3b/0.0005': No such file or directory\n",
            "+ SEED=2\n",
            "+ TASK=sst2\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt\n",
            "+ ARCH=gptmodel_large\n",
            "+ K=32\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst2\n",
            "+ ana_setting=ft\n",
            "+ lr=0.0005\n",
            "+ max_epoch=1\n",
            "+ save_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst2/en_dense_lm_1_3b/0.0005\n",
            "+ optim_group=attn_kv\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' sst2 = agnews ']'\n",
            "+ '[' sst2 = trec ']'\n",
            "+ '[' sst2 = sst5 ']'\n",
            "+ '[' sst2 = dbpedia ']'\n",
            "+ '[' sst2 = cb ']'\n",
            "+ '[' sst2 = arce ']'\n",
            "+ '[' sst2 = arcc ']'\n",
            "+ '[' sst2 = obqa ']'\n",
            "+ '[' sst2 = hellaswag ']'\n",
            "+ '[' sst2 = storycloze ']'\n",
            "+ '[' sst2 = raceh ']'\n",
            "+ '[' sst2 = racem ']'\n",
            "+ '[' sst2 = nq ']'\n",
            "+ '[' sst2 = webqs ']'\n",
            "+ '[' sst2 = triviaqa ']'\n",
            "+ '[' sst2 = sq2 ']'\n",
            "+ '[' sst2 = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ORI_BSZ=1\n",
            "+ BSZ=2\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_ft --arch gptmodel_large --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --lr 0.0005 --max-epoch 1 --curriculum 1000000 --max-update 1000000 --fp16 --eval-data sst2 --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 2 --reset-dataloader --k 32 --batch-size 1 --batch-size-valid 1 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst2 --ana-setting ft --save-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst2/en_dense_lm_1_3b/0.0005 --save-interval 1 --save-interval-updates 1000000 --validate-interval 1000000 --disable-validation --optim-group attn_kv --permut-index 0\n",
            "+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output//train_log_ft.txt\n",
            "2024-03-01 14:22:41 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-01 14:22:42 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-01 14:22:42 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-01 14:22:43.748988: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-01 14:22:43.749037: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-01 14:22:43.750881: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-01 14:22:44.985982: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-01 14:22:47 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 2, 'eval_data': 'sst2', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst2', 'ana_setting': 'ft', 'optim_group': 'attn_kv', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 32, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_large', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2048, 'decoder_output_dim': 2048, 'decoder_input_dim': 2048, 'decoder_ffn_embed_dim': 8192, 'decoder_layers': 24, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt'}, 'criterion': {'_name': 'fs_ft', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.0005]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 2, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1000000, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': None, 'batch_size_valid': 1, 'max_valid_steps': None, 'curriculum': 1000000, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 1000000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst2/en_dense_lm_1_3b/0.0005', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 1000000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=2, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_ft', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=1, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1000000, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=True, max_tokens_valid=None, batch_size_valid='1', max_valid_steps=None, curriculum=1000000, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_large', max_epoch=1, max_update=1000000, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.0005], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst2/en_dense_lm_1_3b/0.0005', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=1000000, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='sst2', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst2', ana_setting='ft', optim_group='attn_kv', tokens_per_sample=2048, max_target_positions=None, k=32, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt', no_seed_provided=False, decoder_layers=24, decoder_embed_dim=2048, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2048, decoder_output_dim=2048, decoder_ffn_embed_dim=8192, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-01 14:22:47 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "Downloading builder script: 28.8kB [00:00, 35.4MB/s]                   \n",
            "Downloading metadata: 28.7kB [00:00, 44.8MB/s]                   \n",
            "Downloading and preparing dataset glue/sst2 (download: 7.09 MiB, generated: 4.81 MiB, post-processed: Unknown size, total: 11.90 MiB) to /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...\n",
            "Downloading data: 100%|██████████| 7.44M/7.44M [00:00<00:00, 75.1MB/s]\n",
            "Dataset glue downloaded and prepared to /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.\n",
            "100%|██████████| 3/3 [00:00<00:00, 845.97it/s]\n",
            "2024-03-01 14:23:26 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-01 14:23:27 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2048, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-23): 24 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
            "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2048, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-01 14:23:27 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-01 14:23:27 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-01 14:23:27 | INFO | fairseq_cli.train | criterion: FewshotFTCriterion\n",
            "2024-03-01 14:23:27 | INFO | fairseq_cli.train | num. shared model params: 1,313,460,224 (num. trained: 1,313,460,224)\n",
            "2024-03-01 14:23:27 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-01 14:23:29 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-01 14:23:29 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 14:23:29 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-01 14:23:29 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 14:23:29 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-01 14:23:29 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 1\n",
            "2024-03-01 14:23:29 | INFO | fairseq.trainer | Preparing to load checkpoint /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst2/en_dense_lm_1_3b/0.0005/checkpoint_last.pt\n",
            "2024-03-01 14:23:29 | INFO | fairseq.trainer | No existing checkpoint found /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst2/en_dense_lm_1_3b/0.0005/checkpoint_last.pt\n",
            "2024-03-01 14:23:29 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-01 14:23:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 32\n",
            "2024-03-01 14:23:29 | INFO | fairseq.trainer | begin training epoch 1\n",
            "2024-03-01 14:23:29 | INFO | fairseq_cli.train | Start fine-tuning\n",
            "------------ example 0 input str train is ['Sentence: is a remarkably accessible and haunting film .  Label:', 'Sentence: is a remarkably accessible and haunting film .  Label:']\n",
            "------------ example 0 label str train is [' Negative', ' Positive']\n",
            "------------ example 1 input str train is ['Sentence: shines  Label:', 'Sentence: shines  Label:']\n",
            "------------ example 1 label str train is [' Negative', ' Positive']\n",
            "------------ example 0 input str valid is [\"Sentence: add yet another hat to a talented head , clooney 's a good director .  Label:\", \"Sentence: add yet another hat to a talented head , clooney 's a good director .  Label:\"]\n",
            "------------ example 0 label str valid is [' Negative', ' Positive']\n",
            "------------ example 1 input str valid is ['Sentence: an unclassifiably awful study in self - and audience-abuse .  Label:', 'Sentence: an unclassifiably awful study in self - and audience-abuse .  Label:']\n",
            "------------ example 1 label str valid is [' Negative', ' Positive']\n",
            "NOTE: true K of baseline is 32, max valid len is 68\n",
            "------------ example 0 input str train is ['Sentence: is a remarkably accessible and haunting film .  Label:', 'Sentence: is a remarkably accessible and haunting film .  Label:']\n",
            "------------ example 0 label str train is [' Negative', ' Positive']\n",
            "------------ example 1 input str train is ['Sentence: shines  Label:', 'Sentence: shines  Label:']\n",
            "------------ example 1 label str train is [' Negative', ' Positive']\n",
            "NOTE: true K of baseline is 32\n",
            "| Loaded valid with 1744 samples\n",
            "| Loaded train with 32 samples\n",
            "2024-03-01 14:23:31 | INFO | train_inner | epoch 001:      1 / 32 loss=9.734, sample_size=15, ntokens=16, wps=0, ups=0, wpb=16, bsz=1, num_updates=1, lr=0.0005, gnorm=16.675, loss_scale=4, train_wall=2, gb_free=32.8, wall=2\n",
            "2024-03-01 14:23:31 | INFO | train_inner | epoch 001:      2 / 32 loss=11.352, sample_size=8, ntokens=9, wps=19.4, ups=2.16, wpb=9, bsz=1, num_updates=2, lr=0.0005, gnorm=22.302, loss_scale=4, train_wall=0, gb_free=32.6, wall=3\n",
            "2024-03-01 14:23:32 | INFO | train_inner | epoch 001:      3 / 32 loss=10.059, sample_size=13, ntokens=14, wps=22.6, ups=1.61, wpb=14, bsz=1, num_updates=3, lr=0.0005, gnorm=17.97, loss_scale=4, train_wall=1, gb_free=32.6, wall=3\n",
            "2024-03-01 14:23:33 | INFO | train_inner | epoch 001:      4 / 32 loss=11.674, sample_size=9, ntokens=10, wps=22.5, ups=2.25, wpb=10, bsz=1, num_updates=4, lr=0.0005, gnorm=20.972, loss_scale=4, train_wall=0, gb_free=32.6, wall=4\n",
            "2024-03-01 14:23:33 | INFO | train_inner | epoch 001:      5 / 32 loss=10.782, sample_size=12, ntokens=13, wps=23.2, ups=1.78, wpb=13, bsz=1, num_updates=5, lr=0.0005, gnorm=18.297, loss_scale=4, train_wall=1, gb_free=32.6, wall=4\n",
            "2024-03-01 14:23:34 | INFO | train_inner | epoch 001:      6 / 32 loss=8.167, sample_size=13, ntokens=14, wps=23.9, ups=1.71, wpb=14, bsz=1, num_updates=6, lr=0.0005, gnorm=14.577, loss_scale=4, train_wall=1, gb_free=32.6, wall=5\n",
            "2024-03-01 14:23:35 | INFO | train_inner | epoch 001:      7 / 32 loss=8.35, sample_size=22, ntokens=23, wps=24.7, ups=1.08, wpb=23, bsz=1, num_updates=7, lr=0.0005, gnorm=11.593, loss_scale=4, train_wall=1, gb_free=32.6, wall=6\n",
            "2024-03-01 14:23:35 | INFO | train_inner | epoch 001:      8 / 32 loss=9.751, sample_size=12, ntokens=13, wps=23.7, ups=1.82, wpb=13, bsz=1, num_updates=8, lr=0.0005, gnorm=15.668, loss_scale=4, train_wall=1, gb_free=32.6, wall=6\n",
            "2024-03-01 14:23:36 | INFO | train_inner | epoch 001:      9 / 32 loss=7.555, sample_size=14, ntokens=15, wps=24.2, ups=1.61, wpb=15, bsz=1, num_updates=9, lr=0.0005, gnorm=13.788, loss_scale=4, train_wall=1, gb_free=32.6, wall=7\n",
            "2024-03-01 14:23:36 | INFO | train_inner | epoch 001:     10 / 32 loss=9.388, sample_size=11, ntokens=12, wps=23.8, ups=1.98, wpb=12, bsz=1, num_updates=10, lr=0.0005, gnorm=17.603, loss_scale=4, train_wall=1, gb_free=32.6, wall=7\n",
            "2024-03-01 14:23:38 | INFO | train_inner | epoch 001:     11 / 32 loss=5.944, sample_size=31, ntokens=32, wps=25.7, ups=0.8, wpb=32, bsz=1, num_updates=11, lr=0.0005, gnorm=8.797, loss_scale=4, train_wall=1, gb_free=32.6, wall=9\n",
            "2024-03-01 14:23:38 | INFO | train_inner | epoch 001:     12 / 32 loss=10.518, sample_size=10, ntokens=11, wps=23.1, ups=2.1, wpb=11, bsz=1, num_updates=12, lr=0.0005, gnorm=17.894, loss_scale=4, train_wall=0, gb_free=32.6, wall=9\n",
            "2024-03-01 14:23:39 | INFO | train_inner | epoch 001:     13 / 32 loss=7.387, sample_size=22, ntokens=23, wps=25.6, ups=1.11, wpb=23, bsz=1, num_updates=13, lr=0.0005, gnorm=13.388, loss_scale=4, train_wall=1, gb_free=32.6, wall=10\n",
            "2024-03-01 14:23:39 | INFO | train_inner | epoch 001:     14 / 32 loss=7.873, sample_size=10, ntokens=11, wps=23.3, ups=2.12, wpb=11, bsz=1, num_updates=14, lr=0.0005, gnorm=17.133, loss_scale=4, train_wall=0, gb_free=32.6, wall=10\n",
            "2024-03-01 14:23:40 | INFO | train_inner | epoch 001:     15 / 32 loss=8.122, sample_size=18, ntokens=19, wps=25.4, ups=1.34, wpb=19, bsz=1, num_updates=15, lr=0.0005, gnorm=13.102, loss_scale=4, train_wall=1, gb_free=32.6, wall=11\n",
            "2024-03-01 14:23:41 | INFO | train_inner | epoch 001:     16 / 32 loss=7.391, sample_size=14, ntokens=15, wps=24.3, ups=1.62, wpb=15, bsz=1, num_updates=16, lr=0.0005, gnorm=14.356, loss_scale=4, train_wall=1, gb_free=32.6, wall=12\n",
            "2024-03-01 14:23:41 | INFO | train_inner | epoch 001:     17 / 32 loss=8.033, sample_size=11, ntokens=12, wps=23.8, ups=1.98, wpb=12, bsz=1, num_updates=17, lr=0.0005, gnorm=17.672, loss_scale=4, train_wall=1, gb_free=32.6, wall=12\n",
            "2024-03-01 14:23:42 | INFO | train_inner | epoch 001:     18 / 32 loss=6.515, sample_size=23, ntokens=24, wps=25.7, ups=1.07, wpb=24, bsz=1, num_updates=18, lr=0.0005, gnorm=13.446, loss_scale=4, train_wall=1, gb_free=32.6, wall=13\n",
            "2024-03-01 14:23:43 | INFO | train_inner | epoch 001:     19 / 32 loss=5.092, sample_size=28, ntokens=29, wps=26.6, ups=0.92, wpb=29, bsz=1, num_updates=19, lr=0.0005, gnorm=9.265, loss_scale=4, train_wall=1, gb_free=32.6, wall=14\n",
            "2024-03-01 14:23:44 | INFO | train_inner | epoch 001:     20 / 32 loss=5.978, sample_size=22, ntokens=23, wps=26.2, ups=1.14, wpb=23, bsz=1, num_updates=20, lr=0.0005, gnorm=10.33, loss_scale=4, train_wall=1, gb_free=32.6, wall=15\n",
            "2024-03-01 14:23:45 | INFO | train_inner | epoch 001:     21 / 32 loss=8.303, sample_size=9, ntokens=10, wps=23.3, ups=2.33, wpb=10, bsz=1, num_updates=21, lr=0.0005, gnorm=20.597, loss_scale=4, train_wall=0, gb_free=32.6, wall=16\n",
            "2024-03-01 14:23:45 | INFO | train_inner | epoch 001:     22 / 32 loss=7.455, sample_size=14, ntokens=15, wps=24.6, ups=1.64, wpb=15, bsz=1, num_updates=22, lr=0.0005, gnorm=12.74, loss_scale=4, train_wall=1, gb_free=32.6, wall=16\n",
            "2024-03-01 14:23:47 | INFO | train_inner | epoch 001:     23 / 32 loss=5.912, sample_size=38, ntokens=39, wps=26.5, ups=0.68, wpb=39, bsz=1, num_updates=23, lr=0.0005, gnorm=9.927, loss_scale=4, train_wall=1, gb_free=32.6, wall=18\n",
            "2024-03-01 14:23:48 | INFO | train_inner | epoch 001:     24 / 32 loss=6.064, sample_size=26, ntokens=27, wps=26.6, ups=0.98, wpb=27, bsz=1, num_updates=24, lr=0.0005, gnorm=10.059, loss_scale=4, train_wall=1, gb_free=32.6, wall=19\n",
            "2024-03-01 14:23:48 | INFO | train_inner | epoch 001:     25 / 32 loss=7.712, sample_size=8, ntokens=9, wps=22.9, ups=2.55, wpb=9, bsz=1, num_updates=25, lr=0.0005, gnorm=18.711, loss_scale=4, train_wall=0, gb_free=32.6, wall=19\n",
            "2024-03-01 14:23:49 | INFO | train_inner | epoch 001:     26 / 32 loss=6.745, sample_size=17, ntokens=18, wps=25.2, ups=1.4, wpb=18, bsz=1, num_updates=26, lr=0.0005, gnorm=11.37, loss_scale=4, train_wall=1, gb_free=32.6, wall=20\n",
            "2024-03-01 14:23:49 | INFO | train_inner | epoch 001:     27 / 32 loss=8.138, sample_size=9, ntokens=10, wps=23.3, ups=2.33, wpb=10, bsz=1, num_updates=27, lr=0.0005, gnorm=16.234, loss_scale=4, train_wall=0, gb_free=32.6, wall=20\n",
            "2024-03-01 14:23:50 | INFO | train_inner | epoch 001:     28 / 32 loss=6.844, sample_size=17, ntokens=18, wps=24.9, ups=1.38, wpb=18, bsz=1, num_updates=28, lr=0.0005, gnorm=21.484, loss_scale=4, train_wall=1, gb_free=32.6, wall=21\n",
            "2024-03-01 14:23:50 | INFO | train_inner | epoch 001:     29 / 32 loss=7.187, sample_size=9, ntokens=10, wps=23, ups=2.3, wpb=10, bsz=1, num_updates=29, lr=0.0005, gnorm=17.007, loss_scale=4, train_wall=0, gb_free=32.6, wall=21\n",
            "2024-03-01 14:23:51 | INFO | train_inner | epoch 001:     30 / 32 loss=6.184, sample_size=16, ntokens=17, wps=24.5, ups=1.44, wpb=17, bsz=1, num_updates=30, lr=0.0005, gnorm=14.256, loss_scale=4, train_wall=1, gb_free=32.6, wall=22\n",
            "2024-03-01 14:23:52 | INFO | train_inner | epoch 001:     31 / 32 loss=7.427, sample_size=24, ntokens=25, wps=26.4, ups=1.06, wpb=25, bsz=1, num_updates=31, lr=0.0005, gnorm=11.216, loss_scale=4, train_wall=1, gb_free=32.6, wall=23\n",
            "2024-03-01 14:23:53 | INFO | train_inner | epoch 001:     32 / 32 loss=7.015, sample_size=16, ntokens=17, wps=25.3, ups=1.49, wpb=17, bsz=1, num_updates=32, lr=0.0005, gnorm=12.154, loss_scale=4, train_wall=1, gb_free=32.6, wall=24\n",
            "2024-03-01 14:23:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 32 updates\n",
            "2024-03-01 14:23:53 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst2/en_dense_lm_1_3b/0.0005/checkpoint1.pt\n",
            "2024-03-01 14:24:13 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst2/en_dense_lm_1_3b/0.0005/checkpoint1.pt\n",
            "2024-03-01 14:24:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst2/en_dense_lm_1_3b/0.0005/checkpoint1.pt (epoch 1 @ 32 updates, score None) (writing took 40.13576238699898 seconds)\n",
            "2024-03-01 14:24:33 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
            "2024-03-01 14:24:33 | INFO | train | epoch 001 | loss 7.47 | sample_size 16.281 | ntokens 17.281 | wps 8.7 | ups 0.5 | wpb 17.3 | bsz 1 | num_updates 32 | lr 0.0005 | gnorm 15.018 | loss_scale 4 | train_wall 23 | gb_free 32.6 | wall 64\n",
            "2024-03-01 14:24:33 | INFO | fairseq_cli.train | done training in 63.7 seconds\n",
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst2/ftzs/record_info.jsonl': No such file or directory\n",
            "+ SEED=2\n",
            "+ TASK=sst2\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst2/en_dense_lm_1_3b/0.0005/checkpoint_last.pt\n",
            "+ ARCH=gptmodel_large\n",
            "+ K=0\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst2\n",
            "+ ana_setting=ftzs\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' sst2 = agnews ']'\n",
            "+ '[' sst2 = trec ']'\n",
            "+ '[' sst2 = sst5 ']'\n",
            "+ '[' sst2 = dbpedia ']'\n",
            "+ '[' sst2 = cb ']'\n",
            "+ '[' sst2 = arce ']'\n",
            "+ '[' sst2 = arcc ']'\n",
            "+ '[' sst2 = obqa ']'\n",
            "+ '[' sst2 = hellaswag ']'\n",
            "+ '[' sst2 = storycloze ']'\n",
            "+ '[' sst2 = raceh ']'\n",
            "+ '[' sst2 = racem ']'\n",
            "+ '[' sst2 = nq ']'\n",
            "+ '[' sst2 = webqs ']'\n",
            "+ '[' sst2 = triviaqa ']'\n",
            "+ '[' sst2 = sq2 ']'\n",
            "+ '[' sst2 = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ BSZ=2\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_eval --arch gptmodel_large --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --max-epoch 1 --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --max-update 0 --fp16 --eval-data sst2 --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 2 --reset-dataloader --no-save --k 0 --batch-size 2 --batch-size-valid 2 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst2/en_dense_lm_1_3b/0.0005/checkpoint_last.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst2 --ana-setting ftzs --permut-index 0\n",
            "+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output//train_log_ftzs.txt\n",
            "2024-03-01 14:24:41 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-01 14:24:42 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-01 14:24:42 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-01 14:24:43.288800: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-01 14:24:43.288848: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-01 14:24:43.290416: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-01 14:24:44.547594: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-01 14:24:46 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 2, 'eval_data': 'sst2', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst2', 'ana_setting': 'ftzs', 'optim_group': 'all', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 0, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_large', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2048, 'decoder_output_dim': 2048, 'decoder_input_dim': 2048, 'decoder_ffn_embed_dim': 8192, 'decoder_layers': 24, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst2/en_dense_lm_1_3b/0.0005/checkpoint_last.pt'}, 'criterion': {'_name': 'fs_eval', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 2, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 2, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 2, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': True, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=2, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_eval', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=2, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid='2', max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_large', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.25], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=True, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='sst2', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst2', ana_setting='ftzs', optim_group='all', tokens_per_sample=2048, max_target_positions=None, k=0, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst2/en_dense_lm_1_3b/0.0005/checkpoint_last.pt', no_seed_provided=False, decoder_layers=24, decoder_embed_dim=2048, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2048, decoder_output_dim=2048, decoder_ffn_embed_dim=8192, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-01 14:24:46 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-01 14:24:48 | WARNING | datasets.builder | Reusing dataset glue (/root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
            "100%|██████████| 3/3 [00:00<00:00, 735.24it/s]\n",
            "2024-03-01 14:24:48 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-9ef161031528915a.arrow\n",
            "2024-03-01 14:24:48 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-97f779923451a5e1.arrow\n",
            "2024-03-01 14:25:25 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-01 14:25:27 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2048, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-23): 24 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
            "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2048, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-01 14:25:27 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-01 14:25:27 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-01 14:25:27 | INFO | fairseq_cli.train | criterion: FewshotEvalCriterion\n",
            "2024-03-01 14:25:27 | INFO | fairseq_cli.train | num. shared model params: 1,313,460,224 (num. trained: 2,048)\n",
            "2024-03-01 14:25:27 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-01 14:25:30 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-01 14:25:30 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 14:25:30 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-01 14:25:30 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 14:25:30 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-01 14:25:30 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 2\n",
            "2024-03-01 14:25:30 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt\n",
            "2024-03-01 14:25:30 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last.pt\n",
            "2024-03-01 14:25:30 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-01 14:25:30 | INFO | fairseq_cli.train | Start validating\n",
            "2024-03-01 14:25:30 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "------------ example 0 input str valid is [\"Sentence: add yet another hat to a talented head , clooney 's a good director .  Label:\", \"Sentence: add yet another hat to a talented head , clooney 's a good director .  Label:\"]\n",
            "------------ example 0 label str valid is [' Negative', ' Positive']\n",
            "------------ example 1 input str valid is ['Sentence: an unclassifiably awful study in self - and audience-abuse .  Label:', 'Sentence: an unclassifiably awful study in self - and audience-abuse .  Label:']\n",
            "------------ example 1 label str valid is [' Negative', ' Positive']\n",
            "NOTE: true K of baseline is 0, max valid len is 68\n",
            "| Loaded valid with 1744 samples\n",
            "| Loaded train with 1744 samples\n",
            "2024-03-01 14:27:12 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 12.629 | nll_loss 0.205 | accuracy 73.9 | f1 0 | pos_proportion 49.1 | neg_proportion 50.9 | wps 532.6 | wpb 61.7 | bsz 1 | num_updates 0\n",
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst2/zs/record_info.jsonl': No such file or directory\n",
            "+ SEED=2\n",
            "+ TASK=sst2\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt\n",
            "+ ARCH=gptmodel_large\n",
            "+ K=0\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst2\n",
            "+ ana_setting=zs\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' sst2 = agnews ']'\n",
            "+ '[' sst2 = trec ']'\n",
            "+ '[' sst2 = sst5 ']'\n",
            "+ '[' sst2 = dbpedia ']'\n",
            "+ '[' sst2 = cb ']'\n",
            "+ '[' sst2 = arce ']'\n",
            "+ '[' sst2 = arcc ']'\n",
            "+ '[' sst2 = obqa ']'\n",
            "+ '[' sst2 = hellaswag ']'\n",
            "+ '[' sst2 = storycloze ']'\n",
            "+ '[' sst2 = raceh ']'\n",
            "+ '[' sst2 = racem ']'\n",
            "+ '[' sst2 = nq ']'\n",
            "+ '[' sst2 = webqs ']'\n",
            "+ '[' sst2 = triviaqa ']'\n",
            "+ '[' sst2 = sq2 ']'\n",
            "+ '[' sst2 = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ BSZ=2\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_eval --arch gptmodel_large --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --max-epoch 1 --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --max-update 0 --fp16 --eval-data sst2 --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 2 --reset-dataloader --no-save --k 0 --batch-size 2 --batch-size-valid 2 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst2 --ana-setting zs --permut-index 0\n",
            "+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output//train_log_zs.txt\n",
            "2024-03-01 14:27:23 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-01 14:27:24 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-01 14:27:24 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-01 14:27:25.535489: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-01 14:27:25.535531: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-01 14:27:25.537115: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-01 14:27:26.791792: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-01 14:27:28 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 2, 'eval_data': 'sst2', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst2', 'ana_setting': 'zs', 'optim_group': 'all', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 0, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_large', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2048, 'decoder_output_dim': 2048, 'decoder_input_dim': 2048, 'decoder_ffn_embed_dim': 8192, 'decoder_layers': 24, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt'}, 'criterion': {'_name': 'fs_eval', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 2, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 2, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 2, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': True, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=2, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_eval', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=2, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid='2', max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_large', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.25], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=True, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='sst2', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst2', ana_setting='zs', optim_group='all', tokens_per_sample=2048, max_target_positions=None, k=0, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt', no_seed_provided=False, decoder_layers=24, decoder_embed_dim=2048, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2048, decoder_output_dim=2048, decoder_ffn_embed_dim=8192, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-01 14:27:29 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-01 14:27:30 | WARNING | datasets.builder | Reusing dataset glue (/root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
            "100%|██████████| 3/3 [00:00<00:00, 775.53it/s]\n",
            "2024-03-01 14:27:30 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-9ef161031528915a.arrow\n",
            "2024-03-01 14:27:30 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-97f779923451a5e1.arrow\n",
            "2024-03-01 14:28:04 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-01 14:28:05 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2048, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-23): 24 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
            "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2048, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-01 14:28:05 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-01 14:28:05 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-01 14:28:05 | INFO | fairseq_cli.train | criterion: FewshotEvalCriterion\n",
            "2024-03-01 14:28:05 | INFO | fairseq_cli.train | num. shared model params: 1,313,460,224 (num. trained: 2,048)\n",
            "2024-03-01 14:28:05 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-01 14:28:07 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-01 14:28:07 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 14:28:07 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-01 14:28:07 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 14:28:07 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-01 14:28:07 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 2\n",
            "2024-03-01 14:28:07 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt\n",
            "2024-03-01 14:28:07 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last.pt\n",
            "2024-03-01 14:28:07 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-01 14:28:07 | INFO | fairseq_cli.train | Start validating\n",
            "2024-03-01 14:28:07 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "------------ example 0 input str valid is [\"Sentence: add yet another hat to a talented head , clooney 's a good director .  Label:\", \"Sentence: add yet another hat to a talented head , clooney 's a good director .  Label:\"]\n",
            "------------ example 0 label str valid is [' Negative', ' Positive']\n",
            "------------ example 1 input str valid is ['Sentence: an unclassifiably awful study in self - and audience-abuse .  Label:', 'Sentence: an unclassifiably awful study in self - and audience-abuse .  Label:']\n",
            "------------ example 1 label str valid is [' Negative', ' Positive']\n",
            "NOTE: true K of baseline is 0, max valid len is 68\n",
            "| Loaded valid with 1744 samples\n",
            "| Loaded train with 1744 samples\n",
            "2024-03-01 14:29:18 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 15.003 | nll_loss 0.243 | accuracy 70.5 | f1 0 | pos_proportion 49.1 | neg_proportion 50.9 | wps 775.2 | wpb 61.7 | bsz 1 | num_updates 0\n",
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst2/icl/record_info.jsonl': No such file or directory\n",
            "+ SEED=2\n",
            "+ TASK=sst2\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt\n",
            "+ ARCH=gptmodel_large\n",
            "+ K=32\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst2\n",
            "+ ana_setting=icl\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' sst2 = agnews ']'\n",
            "+ '[' sst2 = trec ']'\n",
            "+ '[' sst2 = sst5 ']'\n",
            "+ '[' sst2 = dbpedia ']'\n",
            "+ '[' sst2 = cb ']'\n",
            "+ '[' sst2 = arce ']'\n",
            "+ '[' sst2 = arcc ']'\n",
            "+ '[' sst2 = obqa ']'\n",
            "+ '[' sst2 = hellaswag ']'\n",
            "+ '[' sst2 = storycloze ']'\n",
            "+ '[' sst2 = raceh ']'\n",
            "+ '[' sst2 = racem ']'\n",
            "+ '[' sst2 = nq ']'\n",
            "+ '[' sst2 = webqs ']'\n",
            "+ '[' sst2 = triviaqa ']'\n",
            "+ '[' sst2 = sq2 ']'\n",
            "+ '[' sst2 = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ BSZ=2\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_eval --arch gptmodel_large --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --max-epoch 1 --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --max-update 0 --fp16 --eval-data sst2 --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 2 --reset-dataloader --no-save --k 32 --batch-size 2 --batch-size-valid 2 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst2 --ana-setting icl --permut-index 0\n",
            "+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output//train_log_icl.txt\n",
            "2024-03-01 14:29:26 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-01 14:29:27 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-01 14:29:27 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-01 14:29:28.267610: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-01 14:29:28.267653: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-01 14:29:28.269181: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-01 14:29:29.548095: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-01 14:29:31 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 2, 'eval_data': 'sst2', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst2', 'ana_setting': 'icl', 'optim_group': 'all', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 32, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_large', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2048, 'decoder_output_dim': 2048, 'decoder_input_dim': 2048, 'decoder_ffn_embed_dim': 8192, 'decoder_layers': 24, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt'}, 'criterion': {'_name': 'fs_eval', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 2, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 2, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 2, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': True, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=2, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_eval', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=2, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid='2', max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_large', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.25], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=True, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='sst2', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst2', ana_setting='icl', optim_group='all', tokens_per_sample=2048, max_target_positions=None, k=32, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt', no_seed_provided=False, decoder_layers=24, decoder_embed_dim=2048, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2048, decoder_output_dim=2048, decoder_ffn_embed_dim=8192, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-01 14:29:31 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-01 14:29:33 | WARNING | datasets.builder | Reusing dataset glue (/root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
            "100%|██████████| 3/3 [00:00<00:00, 744.82it/s]\n",
            "2024-03-01 14:29:33 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-9ef161031528915a.arrow\n",
            "2024-03-01 14:29:33 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-97f779923451a5e1.arrow\n",
            "2024-03-01 14:30:07 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-01 14:30:08 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2048, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-23): 24 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
            "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2048, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-01 14:30:08 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-01 14:30:08 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-01 14:30:08 | INFO | fairseq_cli.train | criterion: FewshotEvalCriterion\n",
            "2024-03-01 14:30:08 | INFO | fairseq_cli.train | num. shared model params: 1,313,460,224 (num. trained: 2,048)\n",
            "2024-03-01 14:30:08 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-01 14:30:10 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-01 14:30:10 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 14:30:10 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-01 14:30:10 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 14:30:10 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-01 14:30:10 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 2\n",
            "2024-03-01 14:30:10 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt\n",
            "2024-03-01 14:30:10 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last.pt\n",
            "2024-03-01 14:30:10 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-01 14:30:10 | INFO | fairseq_cli.train | Start validating\n",
            "2024-03-01 14:30:10 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "------------ example 0 input str train is ['Sentence: is a remarkably accessible and haunting film .  Label:', 'Sentence: is a remarkably accessible and haunting film .  Label:']\n",
            "------------ example 0 label str train is [' Negative', ' Positive']\n",
            "------------ example 1 input str train is ['Sentence: shines  Label:', 'Sentence: shines  Label:']\n",
            "------------ example 1 label str train is [' Negative', ' Positive']\n",
            "------------ example 0 input str valid is [\"Sentence: add yet another hat to a talented head , clooney 's a good director .  Label:\", \"Sentence: add yet another hat to a talented head , clooney 's a good director .  Label:\"]\n",
            "------------ example 0 label str valid is [' Negative', ' Positive']\n",
            "------------ example 1 input str valid is ['Sentence: an unclassifiably awful study in self - and audience-abuse .  Label:', 'Sentence: an unclassifiably awful study in self - and audience-abuse .  Label:']\n",
            "------------ example 1 label str valid is [' Negative', ' Positive']\n",
            "NOTE: true K of baseline is 32, max valid len is 68\n",
            "| Loaded valid with 1744 samples\n",
            "| Loaded train with 1744 samples\n",
            "2024-03-01 14:31:29 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 0.501 | nll_loss 0 | accuracy 92.5 | f1 0 | pos_proportion 49.1 | neg_proportion 50.9 | wps 13000.8 | wpb 1167.7 | bsz 1 | num_updates 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash run.sh en_dense_lm_1_3b gptmodel_large sst5 32 5 0 \"{icl_base_dir}/output\" \"{icl_base_dir}\" 0.00016"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncYYJjbPb9mC",
        "outputId": "750cf59c-63f2-4a7b-ba09-0ec51e352d2f",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst5/ft/record_info.jsonl': No such file or directory\n",
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst5/en_dense_lm_1_3b/0.00016': No such file or directory\n",
            "+ SEED=5\n",
            "+ TASK=sst5\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt\n",
            "+ ARCH=gptmodel_large\n",
            "+ K=32\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst5\n",
            "+ ana_setting=ft\n",
            "+ lr=0.00016\n",
            "+ max_epoch=1\n",
            "+ save_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst5/en_dense_lm_1_3b/0.00016\n",
            "+ optim_group=attn_kv\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' sst5 = agnews ']'\n",
            "+ '[' sst5 = trec ']'\n",
            "+ '[' sst5 = sst5 ']'\n",
            "+ N_CLASSES=5\n",
            "+ '[' sst5 = dbpedia ']'\n",
            "+ '[' sst5 = cb ']'\n",
            "+ '[' sst5 = arce ']'\n",
            "+ '[' sst5 = arcc ']'\n",
            "+ '[' sst5 = obqa ']'\n",
            "+ '[' sst5 = hellaswag ']'\n",
            "+ '[' sst5 = storycloze ']'\n",
            "+ '[' sst5 = raceh ']'\n",
            "+ '[' sst5 = racem ']'\n",
            "+ '[' sst5 = nq ']'\n",
            "+ '[' sst5 = webqs ']'\n",
            "+ '[' sst5 = triviaqa ']'\n",
            "+ '[' sst5 = sq2 ']'\n",
            "+ '[' sst5 = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ORI_BSZ=1\n",
            "+ BSZ=5\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_ft --arch gptmodel_large --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --lr 0.00016 --max-epoch 1 --curriculum 1000000 --max-update 1000000 --fp16 --eval-data sst5 --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 5 --reset-dataloader --k 32 --batch-size 1 --batch-size-valid 1 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Cola+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output//train_log_ft.txt\n",
            "b-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst5 --ana-setting ft --save-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst5/en_dense_lm_1_3b/0.00016 --save-interval 1 --save-interval-updates 1000000 --validate-interval 1000000 --disable-validation --optim-group attn_kv --permut-index 0\n",
            "2024-03-01 14:31:41 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-01 14:31:41 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-01 14:31:41 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-01 14:31:43.018232: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-01 14:31:43.018285: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-01 14:31:43.019982: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-01 14:31:44.254936: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-01 14:31:46 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 5, 'eval_data': 'sst5', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst5', 'ana_setting': 'ft', 'optim_group': 'attn_kv', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 32, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_large', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2048, 'decoder_output_dim': 2048, 'decoder_input_dim': 2048, 'decoder_ffn_embed_dim': 8192, 'decoder_layers': 24, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt'}, 'criterion': {'_name': 'fs_ft', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.00016]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 5, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1000000, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': None, 'batch_size_valid': 1, 'max_valid_steps': None, 'curriculum': 1000000, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 1000000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.00016], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst5/en_dense_lm_1_3b/0.00016', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 1000000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=5, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_ft', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=1, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1000000, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=True, max_tokens_valid=None, batch_size_valid='1', max_valid_steps=None, curriculum=1000000, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_large', max_epoch=1, max_update=1000000, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.00016], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst5/en_dense_lm_1_3b/0.00016', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=1000000, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='sst5', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst5', ana_setting='ft', optim_group='attn_kv', tokens_per_sample=2048, max_target_positions=None, k=32, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt', no_seed_provided=False, decoder_layers=24, decoder_embed_dim=2048, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2048, decoder_output_dim=2048, decoder_ffn_embed_dim=8192, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-01 14:31:47 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-01 14:31:49 | WARNING | datasets.builder | Using custom data configuration SetFit--sst5-0c891184cb873f87\n",
            "Downloading and preparing dataset json/SetFit--sst5 to /root/.cache/huggingface/datasets/SetFit___json/SetFit--sst5-0c891184cb873f87/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253...\n",
            "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]\n",
            "Downloading data:   0%|          | 0.00/1.32M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   9%|▊         | 116k/1.32M [00:00<00:02, 550kB/s]\u001b[A\n",
            "Downloading data:  29%|██▊       | 379k/1.32M [00:00<00:00, 961kB/s]\u001b[A\n",
            "Downloading data: 100%|██████████| 1.32M/1.32M [00:00<00:00, 2.03MB/s]\n",
            "Downloading data files:  33%|███▎      | 1/3 [00:01<00:03,  1.56s/it]\n",
            "Downloading data:   0%|          | 0.00/343k [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:  10%|▉         | 33.8k/343k [00:00<00:01, 165kB/s]\u001b[A\n",
            "Downloading data:  29%|██▉       | 99.3k/343k [00:00<00:00, 247kB/s]\u001b[A\n",
            "Downloading data: 100%|██████████| 343k/343k [00:00<00:00, 541kB/s]\n",
            "Downloading data files:  67%|██████▋   | 2/3 [00:04<00:02,  2.27s/it]\n",
            "Downloading data:   0%|          | 0.00/171k [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:  20%|█▉        | 33.8k/171k [00:00<00:00, 161kB/s]\u001b[A\n",
            "Downloading data: 100%|██████████| 171k/171k [00:00<00:00, 406kB/s]\n",
            "Downloading data files: 100%|██████████| 3/3 [00:05<00:00,  1.88s/it]\n",
            "Extracting data files: 100%|██████████| 3/3 [00:00<00:00, 1789.12it/s]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/SetFit___json/SetFit--sst5-0c891184cb873f87/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253. Subsequent calls will reuse this data.\n",
            "100%|██████████| 3/3 [00:00<00:00, 933.87it/s]\n",
            "2024-03-01 14:32:31 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-01 14:32:32 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2048, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-23): 24 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
            "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2048, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-01 14:32:32 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-01 14:32:32 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-01 14:32:32 | INFO | fairseq_cli.train | criterion: FewshotFTCriterion\n",
            "2024-03-01 14:32:32 | INFO | fairseq_cli.train | num. shared model params: 1,313,460,224 (num. trained: 1,313,460,224)\n",
            "2024-03-01 14:32:32 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-01 14:32:33 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-01 14:32:33 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 14:32:33 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-01 14:32:33 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 14:32:33 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-01 14:32:33 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 1\n",
            "2024-03-01 14:32:33 | INFO | fairseq.trainer | Preparing to load checkpoint /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst5/en_dense_lm_1_3b/0.00016/checkpoint_last.pt\n",
            "2024-03-01 14:32:33 | INFO | fairseq.trainer | No existing checkpoint found /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst5/en_dense_lm_1_3b/0.00016/checkpoint_last.pt\n",
            "2024-03-01 14:32:33 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-01 14:32:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 32\n",
            "2024-03-01 14:32:34 | INFO | fairseq.trainer | begin training epoch 1\n",
            "2024-03-01 14:32:34 | INFO | fairseq_cli.train | Start fine-tuning\n",
            "------------ example 0 input str train is [\"Sentence: an unintentionally surreal kid 's picture ... in which actors in bad bear suits enact a sort of inter-species parody of a vh1 behind the music episode . Label:\", \"Sentence: an unintentionally surreal kid 's picture ... in which actors in bad bear suits enact a sort of inter-species parody of a vh1 behind the music episode . Label:\", \"Sentence: an unintentionally surreal kid 's picture ... in which actors in bad bear suits enact a sort of inter-species parody of a vh1 behind the music episode . Label:\", \"Sentence: an unintentionally surreal kid 's picture ... in which actors in bad bear suits enact a sort of inter-species parody of a vh1 behind the music episode . Label:\", \"Sentence: an unintentionally surreal kid 's picture ... in which actors in bad bear suits enact a sort of inter-species parody of a vh1 behind the music episode . Label:\"]\n",
            "------------ example 0 label str train is [' terrible', ' bad', ' neutral', ' good', ' great']\n",
            "------------ example 1 input str train is [\"Sentence: twenty-three movies into a mostly magnificent directorial career , clint eastwood 's efficiently minimalist style finally has failed him . Label:\", \"Sentence: twenty-three movies into a mostly magnificent directorial career , clint eastwood 's efficiently minimalist style finally has failed him . Label:\", \"Sentence: twenty-three movies into a mostly magnificent directorial career , clint eastwood 's efficiently minimalist style finally has failed him . Label:\", \"Sentence: twenty-three movies into a mostly magnificent directorial career , clint eastwood 's efficiently minimalist style finally has failed him . Label:\", \"Sentence: twenty-three movies into a mostly magnificent directorial career , clint eastwood 's efficiently minimalist style finally has failed him . Label:\"]\n",
            "------------ example 1 label str train is [' terrible', ' bad', ' neutral', ' good', ' great']\n",
            "------------ example 0 input str valid is ['Sentence: no one goes unindicted here , which is probably for the best . Label:', 'Sentence: no one goes unindicted here , which is probably for the best . Label:', 'Sentence: no one goes unindicted here , which is probably for the best . Label:', 'Sentence: no one goes unindicted here , which is probably for the best . Label:', 'Sentence: no one goes unindicted here , which is probably for the best . Label:']\n",
            "------------ example 0 label str valid is [' terrible', ' bad', ' neutral', ' good', ' great']\n",
            "------------ example 1 input str valid is ['Sentence: pumpkin wants to have it both ways . Label:', 'Sentence: pumpkin wants to have it both ways . Label:', 'Sentence: pumpkin wants to have it both ways . Label:', 'Sentence: pumpkin wants to have it both ways . Label:', 'Sentence: pumpkin wants to have it both ways . Label:']\n",
            "------------ example 1 label str valid is [' terrible', ' bad', ' neutral', ' good', ' great']\n",
            "NOTE: true K of baseline is 32, max valid len is 67\n",
            "------------ example 0 input str train is [\"Sentence: an unintentionally surreal kid 's picture ... in which actors in bad bear suits enact a sort of inter-species parody of a vh1 behind the music episode . Label:\", \"Sentence: an unintentionally surreal kid 's picture ... in which actors in bad bear suits enact a sort of inter-species parody of a vh1 behind the music episode . Label:\", \"Sentence: an unintentionally surreal kid 's picture ... in which actors in bad bear suits enact a sort of inter-species parody of a vh1 behind the music episode . Label:\", \"Sentence: an unintentionally surreal kid 's picture ... in which actors in bad bear suits enact a sort of inter-species parody of a vh1 behind the music episode . Label:\", \"Sentence: an unintentionally surreal kid 's picture ... in which actors in bad bear suits enact a sort of inter-species parody of a vh1 behind the music episode . Label:\"]\n",
            "------------ example 0 label str train is [' terrible', ' bad', ' neutral', ' good', ' great']\n",
            "------------ example 1 input str train is [\"Sentence: twenty-three movies into a mostly magnificent directorial career , clint eastwood 's efficiently minimalist style finally has failed him . Label:\", \"Sentence: twenty-three movies into a mostly magnificent directorial career , clint eastwood 's efficiently minimalist style finally has failed him . Label:\", \"Sentence: twenty-three movies into a mostly magnificent directorial career , clint eastwood 's efficiently minimalist style finally has failed him . Label:\", \"Sentence: twenty-three movies into a mostly magnificent directorial career , clint eastwood 's efficiently minimalist style finally has failed him . Label:\", \"Sentence: twenty-three movies into a mostly magnificent directorial career , clint eastwood 's efficiently minimalist style finally has failed him . Label:\"]\n",
            "------------ example 1 label str train is [' terrible', ' bad', ' neutral', ' good', ' great']\n",
            "NOTE: true K of baseline is 32\n",
            "| Loaded valid with 5505 samples\n",
            "| Loaded train with 32 samples\n",
            "2024-03-01 14:32:36 | INFO | train_inner | epoch 001:      1 / 32 loss=8.006, sample_size=39, ntokens=40, wps=0, ups=0, wpb=40, bsz=1, num_updates=1, lr=0.00016, gnorm=11.27, loss_scale=4, train_wall=2, gb_free=32.8, wall=3\n",
            "2024-03-01 14:32:38 | INFO | train_inner | epoch 001:      2 / 32 loss=8.179, sample_size=32, ntokens=33, wps=24.7, ups=0.75, wpb=33, bsz=1, num_updates=2, lr=0.00016, gnorm=13.456, loss_scale=4, train_wall=1, gb_free=32.6, wall=4\n",
            "2024-03-01 14:32:38 | INFO | train_inner | epoch 001:      3 / 32 loss=8.605, sample_size=15, ntokens=16, wps=22.8, ups=1.43, wpb=16, bsz=1, num_updates=3, lr=0.00016, gnorm=17.353, loss_scale=4, train_wall=1, gb_free=32.6, wall=5\n",
            "2024-03-01 14:32:40 | INFO | train_inner | epoch 001:      4 / 32 loss=7.052, sample_size=54, ntokens=55, wps=26.3, ups=0.48, wpb=55, bsz=1, num_updates=4, lr=0.00016, gnorm=10.484, loss_scale=4, train_wall=2, gb_free=32.6, wall=7\n",
            "2024-03-01 14:32:41 | INFO | train_inner | epoch 001:      5 / 32 loss=7.773, sample_size=23, ntokens=24, wps=24.9, ups=1.04, wpb=24, bsz=1, num_updates=5, lr=0.00016, gnorm=11.804, loss_scale=4, train_wall=1, gb_free=32.6, wall=8\n",
            "2024-03-01 14:32:42 | INFO | train_inner | epoch 001:      6 / 32 loss=7.527, sample_size=27, ntokens=28, wps=26, ups=0.93, wpb=28, bsz=1, num_updates=6, lr=0.00016, gnorm=11.462, loss_scale=4, train_wall=1, gb_free=32.6, wall=9\n",
            "2024-03-01 14:32:43 | INFO | train_inner | epoch 001:      7 / 32 loss=8.836, sample_size=17, ntokens=18, wps=24.5, ups=1.36, wpb=18, bsz=1, num_updates=7, lr=0.00016, gnorm=14.392, loss_scale=4, train_wall=1, gb_free=32.6, wall=10\n",
            "2024-03-01 14:32:44 | INFO | train_inner | epoch 001:      8 / 32 loss=8.427, sample_size=21, ntokens=22, wps=25.4, ups=1.15, wpb=22, bsz=1, num_updates=8, lr=0.00016, gnorm=15.025, loss_scale=4, train_wall=1, gb_free=32.6, wall=11\n",
            "2024-03-01 14:32:46 | INFO | train_inner | epoch 001:      9 / 32 loss=5.891, sample_size=50, ntokens=51, wps=26.9, ups=0.53, wpb=51, bsz=1, num_updates=9, lr=0.00016, gnorm=8.427, loss_scale=4, train_wall=2, gb_free=32.6, wall=13\n",
            "2024-03-01 14:32:47 | INFO | train_inner | epoch 001:     10 / 32 loss=6.51, sample_size=32, ntokens=33, wps=23.8, ups=0.72, wpb=33, bsz=1, num_updates=10, lr=0.00016, gnorm=12.773, loss_scale=4, train_wall=1, gb_free=32.6, wall=14\n",
            "2024-03-01 14:32:49 | INFO | train_inner | epoch 001:     11 / 32 loss=6.259, sample_size=35, ntokens=36, wps=26.8, ups=0.74, wpb=36, bsz=1, num_updates=11, lr=0.00016, gnorm=8.859, loss_scale=4, train_wall=1, gb_free=32.6, wall=15\n",
            "2024-03-01 14:32:50 | INFO | train_inner | epoch 001:     12 / 32 loss=6.069, sample_size=43, ntokens=44, wps=27.1, ups=0.61, wpb=44, bsz=1, num_updates=12, lr=0.00016, gnorm=9.885, loss_scale=4, train_wall=2, gb_free=32.6, wall=17\n",
            "2024-03-01 14:32:52 | INFO | train_inner | epoch 001:     13 / 32 loss=7.143, sample_size=37, ntokens=38, wps=26.2, ups=0.69, wpb=38, bsz=1, num_updates=13, lr=0.00016, gnorm=11.044, loss_scale=4, train_wall=1, gb_free=32.6, wall=18\n",
            "2024-03-01 14:32:53 | INFO | train_inner | epoch 001:     14 / 32 loss=7.381, sample_size=27, ntokens=28, wps=25.5, ups=0.91, wpb=28, bsz=1, num_updates=14, lr=0.00016, gnorm=11.715, loss_scale=4, train_wall=1, gb_free=32.6, wall=19\n",
            "2024-03-01 14:32:54 | INFO | train_inner | epoch 001:     15 / 32 loss=6.146, sample_size=35, ntokens=36, wps=27.1, ups=0.75, wpb=36, bsz=1, num_updates=15, lr=0.00016, gnorm=8.95, loss_scale=4, train_wall=1, gb_free=32.6, wall=21\n",
            "2024-03-01 14:32:55 | INFO | train_inner | epoch 001:     16 / 32 loss=6.013, sample_size=34, ntokens=35, wps=26.1, ups=0.75, wpb=35, bsz=1, num_updates=16, lr=0.00016, gnorm=11.006, loss_scale=4, train_wall=1, gb_free=32.6, wall=22\n",
            "2024-03-01 14:32:57 | INFO | train_inner | epoch 001:     17 / 32 loss=8.304, sample_size=33, ntokens=34, wps=26.8, ups=0.79, wpb=34, bsz=1, num_updates=17, lr=0.00016, gnorm=14.767, loss_scale=4, train_wall=1, gb_free=32.6, wall=23\n",
            "2024-03-01 14:32:57 | INFO | train_inner | epoch 001:     18 / 32 loss=8.957, sample_size=15, ntokens=16, wps=23.9, ups=1.49, wpb=16, bsz=1, num_updates=18, lr=0.00016, gnorm=16.544, loss_scale=4, train_wall=1, gb_free=32.6, wall=24\n",
            "2024-03-01 14:32:58 | INFO | train_inner | epoch 001:     19 / 32 loss=7.054, sample_size=25, ntokens=26, wps=26.1, ups=1, wpb=26, bsz=1, num_updates=19, lr=0.00016, gnorm=13.128, loss_scale=4, train_wall=1, gb_free=32.6, wall=25\n",
            "2024-03-01 14:32:59 | INFO | train_inner | epoch 001:     20 / 32 loss=7.146, sample_size=19, ntokens=20, wps=25.5, ups=1.27, wpb=20, bsz=1, num_updates=20, lr=0.00016, gnorm=14.23, loss_scale=4, train_wall=1, gb_free=32.6, wall=26\n",
            "2024-03-01 14:33:00 | INFO | train_inner | epoch 001:     21 / 32 loss=6.875, sample_size=22, ntokens=23, wps=26.2, ups=1.14, wpb=23, bsz=1, num_updates=21, lr=0.00016, gnorm=10.233, loss_scale=4, train_wall=1, gb_free=32.6, wall=27\n",
            "2024-03-01 14:33:01 | INFO | train_inner | epoch 001:     22 / 32 loss=6.573, sample_size=35, ntokens=36, wps=26.9, ups=0.75, wpb=36, bsz=1, num_updates=22, lr=0.00016, gnorm=9.63, loss_scale=4, train_wall=1, gb_free=32.6, wall=28\n",
            "2024-03-01 14:33:02 | INFO | train_inner | epoch 001:     23 / 32 loss=7.626, sample_size=16, ntokens=17, wps=25.1, ups=1.48, wpb=17, bsz=1, num_updates=23, lr=0.00016, gnorm=14.939, loss_scale=4, train_wall=1, gb_free=32.6, wall=29\n",
            "2024-03-01 14:33:03 | INFO | train_inner | epoch 001:     24 / 32 loss=7.084, sample_size=32, ntokens=33, wps=27, ups=0.82, wpb=33, bsz=1, num_updates=24, lr=0.00016, gnorm=11.399, loss_scale=4, train_wall=1, gb_free=32.6, wall=30\n",
            "2024-03-01 14:33:04 | INFO | train_inner | epoch 001:     25 / 32 loss=7.109, sample_size=28, ntokens=29, wps=26.7, ups=0.92, wpb=29, bsz=1, num_updates=25, lr=0.00016, gnorm=12.221, loss_scale=4, train_wall=1, gb_free=32.6, wall=31\n",
            "2024-03-01 14:33:06 | INFO | train_inner | epoch 001:     26 / 32 loss=7.77, sample_size=29, ntokens=30, wps=26.2, ups=0.87, wpb=30, bsz=1, num_updates=26, lr=0.00016, gnorm=11.687, loss_scale=4, train_wall=1, gb_free=32.6, wall=32\n",
            "2024-03-01 14:33:07 | INFO | train_inner | epoch 001:     27 / 32 loss=7.626, sample_size=25, ntokens=26, wps=26.4, ups=1.02, wpb=26, bsz=1, num_updates=27, lr=0.00016, gnorm=13.347, loss_scale=4, train_wall=1, gb_free=32.6, wall=33\n",
            "2024-03-01 14:33:07 | INFO | train_inner | epoch 001:     28 / 32 loss=6.799, sample_size=23, ntokens=24, wps=26, ups=1.08, wpb=24, bsz=1, num_updates=28, lr=0.00016, gnorm=14.074, loss_scale=4, train_wall=1, gb_free=32.6, wall=34\n",
            "2024-03-01 14:33:09 | INFO | train_inner | epoch 001:     29 / 32 loss=7.555, sample_size=47, ntokens=48, wps=27.5, ups=0.57, wpb=48, bsz=1, num_updates=29, lr=0.00016, gnorm=10.144, loss_scale=4, train_wall=2, gb_free=32.6, wall=36\n",
            "2024-03-01 14:33:10 | INFO | train_inner | epoch 001:     30 / 32 loss=7.893, sample_size=26, ntokens=27, wps=26.6, ups=0.99, wpb=27, bsz=1, num_updates=30, lr=0.00016, gnorm=12.402, loss_scale=4, train_wall=1, gb_free=32.6, wall=37\n",
            "2024-03-01 14:33:13 | INFO | train_inner | epoch 001:     31 / 32 loss=6.588, sample_size=64, ntokens=65, wps=28, ups=0.43, wpb=65, bsz=1, num_updates=31, lr=0.00016, gnorm=8.435, loss_scale=4, train_wall=2, gb_free=32.6, wall=39\n",
            "2024-03-01 14:33:14 | INFO | train_inner | epoch 001:     32 / 32 loss=7.443, sample_size=31, ntokens=32, wps=26.9, ups=0.84, wpb=32, bsz=1, num_updates=32, lr=0.00016, gnorm=10.09, loss_scale=4, train_wall=1, gb_free=32.6, wall=40\n",
            "2024-03-01 14:33:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 32 updates\n",
            "2024-03-01 14:33:14 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst5/en_dense_lm_1_3b/0.00016/checkpoint1.pt\n",
            "2024-03-01 14:33:32 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst5/en_dense_lm_1_3b/0.00016/checkpoint1.pt\n",
            "2024-03-01 14:33:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst5/en_dense_lm_1_3b/0.00016/checkpoint1.pt (epoch 1 @ 32 updates, score None) (writing took 41.07814521600085 seconds)\n",
            "2024-03-01 14:33:55 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
            "2024-03-01 14:33:55 | INFO | train | epoch 001 | loss 7.158 | sample_size 30.969 | ntokens 31.969 | wps 12.5 | ups 0.39 | wpb 32 | bsz 1 | num_updates 32 | lr 0.00016 | gnorm 12.037 | loss_scale 4 | train_wall 40 | gb_free 32.6 | wall 81\n",
            "2024-03-01 14:33:55 | INFO | fairseq_cli.train | done training in 81.2 seconds\n",
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst5/ftzs/record_info.jsonl': No such file or directory\n",
            "+ SEED=5\n",
            "+ TASK=sst5\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst5/en_dense_lm_1_3b/0.00016/checkpoint_last.pt\n",
            "+ ARCH=gptmodel_large\n",
            "+ K=0\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst5\n",
            "+ ana_setting=ftzs\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' sst5 = agnews ']'\n",
            "+ '[' sst5 = trec ']'\n",
            "+ '[' sst5 = sst5 ']'\n",
            "+ N_CLASSES=5\n",
            "+ '[' sst5 = dbpedia ']'\n",
            "+ '[' sst5 = cb ']'\n",
            "+ '[' sst5 = arce ']'\n",
            "+ '[' sst5 = arcc ']'\n",
            "+ '[' sst5 = obqa ']'\n",
            "+ '[' sst5 = hellaswag ']'\n",
            "+ '[' sst5 = storycloze ']'\n",
            "+ '[' sst5 = raceh ']'\n",
            "+ '[' sst5 = racem ']'\n",
            "+ '[' sst5 = nq ']'\n",
            "+ '[' sst5 = webqs ']'\n",
            "+ '[' sst5 = triviaqa ']'\n",
            "+ '[' sst5 = sq2 ']'\n",
            "+ '[' sst5 = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ BSZ=5\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_eval --arch gptmodel_large --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --max-epoch 1 --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --max-update 0 --fp16 --eval-data sst5 --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 5 --reset-dataloader --no-save --k 0 --batch-size 5 --batch-size-valid 5 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst5/en_dense_lm_1_3b/0.00016/checkpoint_last.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst5 --ana-setting ftzs --permut-index 0\n",
            "+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output//train_log_ftzs.txt\n",
            "2024-03-01 14:34:04 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-01 14:34:05 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-01 14:34:05 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-01 14:34:06.447630: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-01 14:34:06.447674: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-01 14:34:06.449254: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-01 14:34:07.698568: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-01 14:34:09 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 5, 'eval_data': 'sst5', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst5', 'ana_setting': 'ftzs', 'optim_group': 'all', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 0, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_large', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2048, 'decoder_output_dim': 2048, 'decoder_input_dim': 2048, 'decoder_ffn_embed_dim': 8192, 'decoder_layers': 24, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst5/en_dense_lm_1_3b/0.00016/checkpoint_last.pt'}, 'criterion': {'_name': 'fs_eval', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 5, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 5, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 5, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': True, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=5, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_eval', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=5, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid='5', max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_large', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.25], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=True, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='sst5', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst5', ana_setting='ftzs', optim_group='all', tokens_per_sample=2048, max_target_positions=None, k=0, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst5/en_dense_lm_1_3b/0.00016/checkpoint_last.pt', no_seed_provided=False, decoder_layers=24, decoder_embed_dim=2048, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2048, decoder_output_dim=2048, decoder_ffn_embed_dim=8192, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-01 14:34:10 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-01 14:34:12 | WARNING | datasets.builder | Using custom data configuration SetFit--sst5-0c891184cb873f87\n",
            "2024-03-01 14:34:12 | WARNING | datasets.builder | Reusing dataset json (/root/.cache/huggingface/datasets/SetFit___json/SetFit--sst5-0c891184cb873f87/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253)\n",
            "100%|██████████| 3/3 [00:00<00:00, 535.69it/s]\n",
            "2024-03-01 14:34:12 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/SetFit___json/SetFit--sst5-0c891184cb873f87/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-085d282a8e30d5e1.arrow\n",
            "2024-03-01 14:34:12 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/SetFit___json/SetFit--sst5-0c891184cb873f87/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-f1a26c00e694c55c.arrow\n",
            "2024-03-01 14:34:51 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-01 14:34:53 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2048, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-23): 24 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
            "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2048, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-01 14:34:53 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-01 14:34:53 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-01 14:34:53 | INFO | fairseq_cli.train | criterion: FewshotEvalCriterion\n",
            "2024-03-01 14:34:53 | INFO | fairseq_cli.train | num. shared model params: 1,313,460,224 (num. trained: 2,048)\n",
            "2024-03-01 14:34:53 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-01 14:34:55 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-01 14:34:55 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 14:34:55 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-01 14:34:55 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 14:34:55 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-01 14:34:55 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 5\n",
            "2024-03-01 14:34:55 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt\n",
            "2024-03-01 14:34:55 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last.pt\n",
            "2024-03-01 14:34:55 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-01 14:34:55 | INFO | fairseq_cli.train | Start validating\n",
            "2024-03-01 14:34:55 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "------------ example 0 input str valid is ['Sentence: no one goes unindicted here , which is probably for the best . Label:', 'Sentence: no one goes unindicted here , which is probably for the best . Label:', 'Sentence: no one goes unindicted here , which is probably for the best . Label:', 'Sentence: no one goes unindicted here , which is probably for the best . Label:', 'Sentence: no one goes unindicted here , which is probably for the best . Label:']\n",
            "------------ example 0 label str valid is [' terrible', ' bad', ' neutral', ' good', ' great']\n",
            "------------ example 1 input str valid is ['Sentence: pumpkin wants to have it both ways . Label:', 'Sentence: pumpkin wants to have it both ways . Label:', 'Sentence: pumpkin wants to have it both ways . Label:', 'Sentence: pumpkin wants to have it both ways . Label:', 'Sentence: pumpkin wants to have it both ways . Label:']\n",
            "------------ example 1 label str valid is [' terrible', ' bad', ' neutral', ' good', ' great']\n",
            "NOTE: true K of baseline is 0, max valid len is 67\n",
            "| Loaded valid with 5505 samples\n",
            "| Loaded train with 5505 samples\n",
            "2024-03-01 14:37:05 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 11.135 | nll_loss 0.074 | accuracy 39.3 | f1 0 | pos_proportion 12.6 | neg_proportion 26.2 | wps 1285.8 | wpb 149.7 | bsz 1 | num_updates 0\n",
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst5/zs/record_info.jsonl': No such file or directory\n",
            "+ SEED=5\n",
            "+ TASK=sst5\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt\n",
            "+ ARCH=gptmodel_large\n",
            "+ K=0\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst5\n",
            "+ ana_setting=zs\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' sst5 = agnews ']'\n",
            "+ '[' sst5 = trec ']'\n",
            "+ '[' sst5 = sst5 ']'\n",
            "+ N_CLASSES=5\n",
            "+ '[' sst5 = dbpedia ']'\n",
            "+ '[' sst5 = cb ']'\n",
            "+ '[' sst5 = arce ']'\n",
            "+ '[' sst5 = arcc ']'\n",
            "+ '[' sst5 = obqa ']'\n",
            "+ '[' sst5 = hellaswag ']'\n",
            "+ '[' sst5 = storycloze ']'\n",
            "+ '[' sst5 = raceh ']'\n",
            "+ '[' sst5 = racem ']'\n",
            "+ '[' sst5 = nq ']'\n",
            "+ '[' sst5 = webqs ']'\n",
            "+ '[' sst5 = triviaqa ']'\n",
            "+ '[' sst5 = sq2 ']'\n",
            "+ '[' sst5 = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ BSZ=5\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_eval --arch gptmodel_large --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --max-epoch 1 --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --max-update 0 --fp16 --eval-data sst5 --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 5 --reset-dataloader --no-save --k 0 --batch-size 5 --batch-size-valid 5 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst5 --ana-setting zs --permut-index 0\n",
            "+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output//train_log_zs.txt\n",
            "2024-03-01 14:37:17 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-01 14:37:18 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-01 14:37:18 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-01 14:37:19.312006: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-01 14:37:19.312056: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-01 14:37:19.313580: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-01 14:37:20.572289: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-01 14:37:22 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 5, 'eval_data': 'sst5', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst5', 'ana_setting': 'zs', 'optim_group': 'all', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 0, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_large', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2048, 'decoder_output_dim': 2048, 'decoder_input_dim': 2048, 'decoder_ffn_embed_dim': 8192, 'decoder_layers': 24, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt'}, 'criterion': {'_name': 'fs_eval', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 5, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 5, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 5, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': True, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=5, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_eval', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=5, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid='5', max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_large', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.25], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=True, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='sst5', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst5', ana_setting='zs', optim_group='all', tokens_per_sample=2048, max_target_positions=None, k=0, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt', no_seed_provided=False, decoder_layers=24, decoder_embed_dim=2048, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2048, decoder_output_dim=2048, decoder_ffn_embed_dim=8192, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-01 14:37:22 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-01 14:37:25 | WARNING | datasets.builder | Using custom data configuration SetFit--sst5-0c891184cb873f87\n",
            "2024-03-01 14:37:25 | WARNING | datasets.builder | Reusing dataset json (/root/.cache/huggingface/datasets/SetFit___json/SetFit--sst5-0c891184cb873f87/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253)\n",
            "100%|██████████| 3/3 [00:00<00:00, 482.01it/s]\n",
            "2024-03-01 14:37:25 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/SetFit___json/SetFit--sst5-0c891184cb873f87/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-085d282a8e30d5e1.arrow\n",
            "2024-03-01 14:37:25 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/SetFit___json/SetFit--sst5-0c891184cb873f87/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-f1a26c00e694c55c.arrow\n",
            "2024-03-01 14:38:01 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-01 14:38:02 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2048, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-23): 24 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
            "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2048, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-01 14:38:02 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-01 14:38:02 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-01 14:38:02 | INFO | fairseq_cli.train | criterion: FewshotEvalCriterion\n",
            "2024-03-01 14:38:02 | INFO | fairseq_cli.train | num. shared model params: 1,313,460,224 (num. trained: 2,048)\n",
            "2024-03-01 14:38:02 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-01 14:38:03 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-01 14:38:03 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 14:38:03 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-01 14:38:03 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 14:38:03 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-01 14:38:03 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 5\n",
            "2024-03-01 14:38:03 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt\n",
            "2024-03-01 14:38:03 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last.pt\n",
            "2024-03-01 14:38:03 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-01 14:38:04 | INFO | fairseq_cli.train | Start validating\n",
            "2024-03-01 14:38:04 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "------------ example 0 input str valid is ['Sentence: no one goes unindicted here , which is probably for the best . Label:', 'Sentence: no one goes unindicted here , which is probably for the best . Label:', 'Sentence: no one goes unindicted here , which is probably for the best . Label:', 'Sentence: no one goes unindicted here , which is probably for the best . Label:', 'Sentence: no one goes unindicted here , which is probably for the best . Label:']\n",
            "------------ example 0 label str valid is [' terrible', ' bad', ' neutral', ' good', ' great']\n",
            "------------ example 1 input str valid is ['Sentence: pumpkin wants to have it both ways . Label:', 'Sentence: pumpkin wants to have it both ways . Label:', 'Sentence: pumpkin wants to have it both ways . Label:', 'Sentence: pumpkin wants to have it both ways . Label:', 'Sentence: pumpkin wants to have it both ways . Label:']\n",
            "------------ example 1 label str valid is [' terrible', ' bad', ' neutral', ' good', ' great']\n",
            "NOTE: true K of baseline is 0, max valid len is 67\n",
            "| Loaded valid with 5505 samples\n",
            "| Loaded train with 5505 samples\n",
            "2024-03-01 14:39:33 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 11.753 | nll_loss 0.079 | accuracy 39.3 | f1 0 | pos_proportion 12.6 | neg_proportion 26.2 | wps 1876.1 | wpb 149.7 | bsz 1 | num_updates 0\n",
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst5/icl/record_info.jsonl': No such file or directory\n",
            "+ SEED=5\n",
            "+ TASK=sst5\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt\n",
            "+ ARCH=gptmodel_large\n",
            "+ K=32\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst5\n",
            "+ ana_setting=icl\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' sst5 = agnews ']'\n",
            "+ '[' sst5 = trec ']'\n",
            "+ '[' sst5 = sst5 ']'\n",
            "+ N_CLASSES=5\n",
            "+ '[' sst5 = dbpedia ']'\n",
            "+ '[' sst5 = cb ']'\n",
            "+ '[' sst5 = arce ']'\n",
            "+ '[' sst5 = arcc ']'\n",
            "+ '[' sst5 = obqa ']'\n",
            "+ '[' sst5 = hellaswag ']'\n",
            "+ '[' sst5 = storycloze ']'\n",
            "+ '[' sst5 = raceh ']'\n",
            "+ '[' sst5 = racem ']'\n",
            "+ '[' sst5 = nq ']'\n",
            "+ '[' sst5 = webqs ']'\n",
            "+ '[' sst5 = triviaqa ']'\n",
            "+ '[' sst5 = sq2 ']'\n",
            "+ '[' sst5 = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ BSZ=5\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_eval --arch gptmodel_large --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --max-epoch 1 --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --max-update 0 --fp16 --eval-data sst5 --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 5 --reset-dataloader --no-save --k 32 --batch-size 5 --batch-size-valid 5 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst5 --ana-setting icl --permut-index 0\n",
            "+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output//train_log_icl.txt\n",
            "2024-03-01 14:39:42 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-01 14:39:43 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-01 14:39:43 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-01 14:39:44.671162: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-01 14:39:44.671211: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-01 14:39:44.672825: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-01 14:39:45.870199: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-01 14:39:48 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 5, 'eval_data': 'sst5', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst5', 'ana_setting': 'icl', 'optim_group': 'all', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 32, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_large', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2048, 'decoder_output_dim': 2048, 'decoder_input_dim': 2048, 'decoder_ffn_embed_dim': 8192, 'decoder_layers': 24, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt'}, 'criterion': {'_name': 'fs_eval', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 5, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 5, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 5, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': True, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=5, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_eval', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=5, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid='5', max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_large', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.25], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=True, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='sst5', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst5', ana_setting='icl', optim_group='all', tokens_per_sample=2048, max_target_positions=None, k=32, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt', no_seed_provided=False, decoder_layers=24, decoder_embed_dim=2048, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2048, decoder_output_dim=2048, decoder_ffn_embed_dim=8192, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-01 14:39:48 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-01 14:39:49 | WARNING | datasets.builder | Using custom data configuration SetFit--sst5-0c891184cb873f87\n",
            "2024-03-01 14:39:49 | WARNING | datasets.builder | Reusing dataset json (/root/.cache/huggingface/datasets/SetFit___json/SetFit--sst5-0c891184cb873f87/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253)\n",
            "100%|██████████| 3/3 [00:00<00:00, 512.46it/s]\n",
            "2024-03-01 14:39:49 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/SetFit___json/SetFit--sst5-0c891184cb873f87/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-085d282a8e30d5e1.arrow\n",
            "2024-03-01 14:39:49 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/SetFit___json/SetFit--sst5-0c891184cb873f87/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-f1a26c00e694c55c.arrow\n",
            "2024-03-01 14:40:24 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-01 14:40:25 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2048, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-23): 24 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
            "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2048, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-01 14:40:25 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-01 14:40:25 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-01 14:40:25 | INFO | fairseq_cli.train | criterion: FewshotEvalCriterion\n",
            "2024-03-01 14:40:25 | INFO | fairseq_cli.train | num. shared model params: 1,313,460,224 (num. trained: 2,048)\n",
            "2024-03-01 14:40:25 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-01 14:40:27 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-01 14:40:27 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 14:40:27 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-01 14:40:27 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 14:40:27 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-01 14:40:27 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 5\n",
            "2024-03-01 14:40:27 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt\n",
            "2024-03-01 14:40:27 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last.pt\n",
            "2024-03-01 14:40:27 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-01 14:40:28 | INFO | fairseq_cli.train | Start validating\n",
            "2024-03-01 14:40:28 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "------------ example 0 input str train is [\"Sentence: an unintentionally surreal kid 's picture ... in which actors in bad bear suits enact a sort of inter-species parody of a vh1 behind the music episode . Label:\", \"Sentence: an unintentionally surreal kid 's picture ... in which actors in bad bear suits enact a sort of inter-species parody of a vh1 behind the music episode . Label:\", \"Sentence: an unintentionally surreal kid 's picture ... in which actors in bad bear suits enact a sort of inter-species parody of a vh1 behind the music episode . Label:\", \"Sentence: an unintentionally surreal kid 's picture ... in which actors in bad bear suits enact a sort of inter-species parody of a vh1 behind the music episode . Label:\", \"Sentence: an unintentionally surreal kid 's picture ... in which actors in bad bear suits enact a sort of inter-species parody of a vh1 behind the music episode . Label:\"]\n",
            "------------ example 0 label str train is [' terrible', ' bad', ' neutral', ' good', ' great']\n",
            "------------ example 1 input str train is [\"Sentence: twenty-three movies into a mostly magnificent directorial career , clint eastwood 's efficiently minimalist style finally has failed him . Label:\", \"Sentence: twenty-three movies into a mostly magnificent directorial career , clint eastwood 's efficiently minimalist style finally has failed him . Label:\", \"Sentence: twenty-three movies into a mostly magnificent directorial career , clint eastwood 's efficiently minimalist style finally has failed him . Label:\", \"Sentence: twenty-three movies into a mostly magnificent directorial career , clint eastwood 's efficiently minimalist style finally has failed him . Label:\", \"Sentence: twenty-three movies into a mostly magnificent directorial career , clint eastwood 's efficiently minimalist style finally has failed him . Label:\"]\n",
            "------------ example 1 label str train is [' terrible', ' bad', ' neutral', ' good', ' great']\n",
            "------------ example 0 input str valid is ['Sentence: no one goes unindicted here , which is probably for the best . Label:', 'Sentence: no one goes unindicted here , which is probably for the best . Label:', 'Sentence: no one goes unindicted here , which is probably for the best . Label:', 'Sentence: no one goes unindicted here , which is probably for the best . Label:', 'Sentence: no one goes unindicted here , which is probably for the best . Label:']\n",
            "------------ example 0 label str valid is [' terrible', ' bad', ' neutral', ' good', ' great']\n",
            "------------ example 1 input str valid is ['Sentence: pumpkin wants to have it both ways . Label:', 'Sentence: pumpkin wants to have it both ways . Label:', 'Sentence: pumpkin wants to have it both ways . Label:', 'Sentence: pumpkin wants to have it both ways . Label:', 'Sentence: pumpkin wants to have it both ways . Label:']\n",
            "------------ example 1 label str valid is [' terrible', ' bad', ' neutral', ' good', ' great']\n",
            "NOTE: true K of baseline is 32, max valid len is 67\n",
            "| Loaded valid with 5505 samples\n",
            "| Loaded train with 5505 samples\n",
            "2024-03-01 14:42:41 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 2.602 | nll_loss 0 | accuracy 45 | f1 0 | pos_proportion 12.6 | neg_proportion 26.2 | wps 43751.5 | wpb 5264.7 | bsz 1 | num_updates 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash run.sh en_dense_lm_1_3b gptmodel_large mr 32 5 0 \"{icl_base_dir}/output\" \"{icl_base_dir}\" 0.003"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cn-24Fipb-SB",
        "outputId": "ded401ce-a53d-4502-91ce-fd38593759e7",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/mr/ft/record_info.jsonl': No such file or directory\n",
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/mr/en_dense_lm_1_3b/0.003': No such file or directory\n",
            "+ SEED=5\n",
            "+ TASK=mr\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt\n",
            "+ ARCH=gptmodel_large\n",
            "+ K=32\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/mr\n",
            "+ ana_setting=ft\n",
            "+ lr=0.003\n",
            "+ max_epoch=1\n",
            "+ save_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/mr/en_dense_lm_1_3b/0.003\n",
            "+ optim_group=attn_kv\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' mr = agnews ']'\n",
            "+ '[' mr = trec ']'\n",
            "+ '[' mr = sst5 ']'\n",
            "+ '[' mr = dbpedia ']'\n",
            "+ '[' mr = cb ']'\n",
            "+ '[' mr = arce ']'\n",
            "+ '[' mr = arcc ']'\n",
            "+ '[' mr = obqa ']'\n",
            "+ '[' mr = hellaswag ']'\n",
            "+ '[' mr = storycloze ']'\n",
            "+ '[' mr = raceh ']'\n",
            "+ '[' mr = racem ']'\n",
            "+ '[' mr = nq ']'\n",
            "+ '[' mr = webqs ']'\n",
            "+ '[' mr = triviaqa ']'\n",
            "+ '[' mr = sq2 ']'\n",
            "+ '[' mr = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ORI_BSZ=1\n",
            "+ BSZ=2\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_ft --arch gptmodel_large --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --lr 0.003 --max-epoch 1 --curriculum 1000000 --max-update 1000000 --fp16 --eval-data mr --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 5 --reset-dataloader --k 32 --batch-size 1 --batch-size-valid 1 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/mr --ana-setting ft --save-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/mr/en_dense_lm_1_3b/0.003 --save-interval 1 --save-interval-updates 1000000 --validate-interval 1000000 --disable-validation --optim-group attn_kv --permut-index 0\n",
            "+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output//train_log_ft.txt\n",
            "2024-03-01 14:42:52 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-01 14:42:52 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-01 14:42:52 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-01 14:42:54.059389: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-01 14:42:54.059444: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-01 14:42:54.061431: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-01 14:42:55.423398: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-01 14:42:57 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 5, 'eval_data': 'mr', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/mr', 'ana_setting': 'ft', 'optim_group': 'attn_kv', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 32, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_large', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2048, 'decoder_output_dim': 2048, 'decoder_input_dim': 2048, 'decoder_ffn_embed_dim': 8192, 'decoder_layers': 24, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt'}, 'criterion': {'_name': 'fs_ft', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.003]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 5, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1000000, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': None, 'batch_size_valid': 1, 'max_valid_steps': None, 'curriculum': 1000000, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 1000000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.003], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/mr/en_dense_lm_1_3b/0.003', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 1000000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=5, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_ft', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=1, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1000000, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=True, max_tokens_valid=None, batch_size_valid='1', max_valid_steps=None, curriculum=1000000, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_large', max_epoch=1, max_update=1000000, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.003], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/mr/en_dense_lm_1_3b/0.003', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=1000000, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='mr', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/mr', ana_setting='ft', optim_group='attn_kv', tokens_per_sample=2048, max_target_positions=None, k=32, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt', no_seed_provided=False, decoder_layers=24, decoder_embed_dim=2048, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2048, decoder_output_dim=2048, decoder_ffn_embed_dim=8192, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-01 14:42:57 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "Downloading builder script: 5.03kB [00:00, 13.6MB/s]                   \n",
            "Downloading metadata: 2.02kB [00:00, 6.50MB/s]                 \n",
            "2024-03-01 14:42:59 | WARNING | datasets.builder | Using custom data configuration default\n",
            "Downloading and preparing dataset rotten_tomatoes/default (download: 476.34 KiB, generated: 1.28 MiB, post-processed: Unknown size, total: 1.75 MiB) to /root/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46...\n",
            "Downloading data: 100%|██████████| 488k/488k [00:01<00:00, 358kB/s]\n",
            "Dataset rotten_tomatoes downloaded and prepared to /root/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46. Subsequent calls will reuse this data.\n",
            "100%|██████████| 3/3 [00:00<00:00, 823.87it/s]\n",
            "2024-03-01 14:43:40 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-01 14:43:41 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2048, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-23): 24 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
            "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2048, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-01 14:43:41 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-01 14:43:41 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-01 14:43:41 | INFO | fairseq_cli.train | criterion: FewshotFTCriterion\n",
            "2024-03-01 14:43:41 | INFO | fairseq_cli.train | num. shared model params: 1,313,460,224 (num. trained: 1,313,460,224)\n",
            "2024-03-01 14:43:41 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-01 14:43:43 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-01 14:43:43 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 14:43:43 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-01 14:43:43 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 14:43:43 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-01 14:43:43 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 1\n",
            "2024-03-01 14:43:43 | INFO | fairseq.trainer | Preparing to load checkpoint /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/mr/en_dense_lm_1_3b/0.003/checkpoint_last.pt\n",
            "2024-03-01 14:43:43 | INFO | fairseq.trainer | No existing checkpoint found /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/mr/en_dense_lm_1_3b/0.003/checkpoint_last.pt\n",
            "2024-03-01 14:43:43 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-01 14:43:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 32\n",
            "2024-03-01 14:43:43 | INFO | fairseq.trainer | begin training epoch 1\n",
            "2024-03-01 14:43:43 | INFO | fairseq_cli.train | Start fine-tuning\n",
            "------------ example 0 input str train is ['Review: . . . salaciously simplistic . Sentiment:', 'Review: . . . salaciously simplistic . Sentiment:']\n",
            "------------ example 0 label str train is [' Negative', ' Positive']\n",
            "------------ example 1 input str train is ['Review: birthday girl is an amusing joy ride , with some surprisingly violent moments . Sentiment:', 'Review: birthday girl is an amusing joy ride , with some surprisingly violent moments . Sentiment:']\n",
            "------------ example 1 label str train is [' Negative', ' Positive']\n",
            "------------ example 0 input str valid is ['Review: i liked a lot of the smaller scenes . Sentiment:', 'Review: i liked a lot of the smaller scenes . Sentiment:']\n",
            "------------ example 0 label str valid is [' Negative', ' Positive']\n",
            "------------ example 1 input str valid is ['Review: what happens when something goes bump in the night and nobody cares ? Sentiment:', 'Review: what happens when something goes bump in the night and nobody cares ? Sentiment:']\n",
            "------------ example 1 label str valid is [' Negative', ' Positive']\n",
            "NOTE: true K of baseline is 32, max valid len is 84\n",
            "------------ example 0 input str train is ['Review: . . . salaciously simplistic . Sentiment:', 'Review: . . . salaciously simplistic . Sentiment:']\n",
            "------------ example 0 label str train is [' Negative', ' Positive']\n",
            "------------ example 1 input str train is ['Review: birthday girl is an amusing joy ride , with some surprisingly violent moments . Sentiment:', 'Review: birthday girl is an amusing joy ride , with some surprisingly violent moments . Sentiment:']\n",
            "------------ example 1 label str train is [' Negative', ' Positive']\n",
            "NOTE: true K of baseline is 32\n",
            "| Loaded valid with 2132 samples\n",
            "| Loaded train with 32 samples\n",
            "2024-03-01 14:43:45 | INFO | train_inner | epoch 001:      1 / 32 loss=9.75, sample_size=13, ntokens=14, wps=0, ups=0, wpb=14, bsz=1, num_updates=1, lr=0.003, gnorm=18.576, loss_scale=4, train_wall=2, gb_free=32.8, wall=2\n",
            "2024-03-01 14:43:46 | INFO | train_inner | epoch 001:      2 / 32 loss=8.168, sample_size=20, ntokens=21, wps=23, ups=1.1, wpb=21, bsz=1, num_updates=2, lr=0.003, gnorm=14.27, loss_scale=4, train_wall=1, gb_free=32.6, wall=3\n",
            "2024-03-01 14:43:47 | INFO | train_inner | epoch 001:      3 / 32 loss=8.175, sample_size=14, ntokens=15, wps=23.6, ups=1.57, wpb=15, bsz=1, num_updates=3, lr=0.003, gnorm=16.406, loss_scale=4, train_wall=1, gb_free=32.6, wall=4\n",
            "2024-03-01 14:43:48 | INFO | train_inner | epoch 001:      4 / 32 loss=7.864, sample_size=45, ntokens=46, wps=26.2, ups=0.57, wpb=46, bsz=1, num_updates=4, lr=0.003, gnorm=10.325, loss_scale=4, train_wall=2, gb_free=32.6, wall=6\n",
            "2024-03-01 14:43:50 | INFO | train_inner | epoch 001:      5 / 32 loss=5.702, sample_size=37, ntokens=38, wps=26.2, ups=0.69, wpb=38, bsz=1, num_updates=5, lr=0.003, gnorm=9.787, loss_scale=4, train_wall=1, gb_free=32.6, wall=7\n",
            "2024-03-01 14:43:51 | INFO | train_inner | epoch 001:      6 / 32 loss=6.968, sample_size=26, ntokens=27, wps=26.1, ups=0.97, wpb=27, bsz=1, num_updates=6, lr=0.003, gnorm=12.084, loss_scale=4, train_wall=1, gb_free=32.6, wall=8\n",
            "2024-03-01 14:43:52 | INFO | train_inner | epoch 001:      7 / 32 loss=5.844, sample_size=41, ntokens=42, wps=27.6, ups=0.66, wpb=42, bsz=1, num_updates=7, lr=0.003, gnorm=8.784, loss_scale=4, train_wall=2, gb_free=32.6, wall=10\n",
            "2024-03-01 14:43:53 | INFO | train_inner | epoch 001:      8 / 32 loss=6.555, sample_size=20, ntokens=21, wps=26, ups=1.24, wpb=21, bsz=1, num_updates=8, lr=0.003, gnorm=10.369, loss_scale=4, train_wall=1, gb_free=32.6, wall=10\n",
            "2024-03-01 14:43:54 | INFO | train_inner | epoch 001:      9 / 32 loss=6.006, sample_size=18, ntokens=19, wps=25.4, ups=1.34, wpb=19, bsz=1, num_updates=9, lr=0.003, gnorm=11.637, loss_scale=4, train_wall=1, gb_free=32.6, wall=11\n",
            "2024-03-01 14:43:55 | INFO | train_inner | epoch 001:     10 / 32 loss=5.989, sample_size=34, ntokens=35, wps=26.3, ups=0.75, wpb=35, bsz=1, num_updates=10, lr=0.003, gnorm=11.904, loss_scale=4, train_wall=1, gb_free=32.6, wall=12\n",
            "2024-03-01 14:43:56 | INFO | train_inner | epoch 001:     11 / 32 loss=6.351, sample_size=26, ntokens=27, wps=25.6, ups=0.95, wpb=27, bsz=1, num_updates=11, lr=0.003, gnorm=10.774, loss_scale=4, train_wall=1, gb_free=32.6, wall=13\n",
            "2024-03-01 14:43:57 | INFO | train_inner | epoch 001:     12 / 32 loss=5.858, sample_size=18, ntokens=19, wps=25.3, ups=1.33, wpb=19, bsz=1, num_updates=12, lr=0.003, gnorm=13.149, loss_scale=4, train_wall=1, gb_free=32.6, wall=14\n",
            "2024-03-01 14:43:58 | INFO | train_inner | epoch 001:     13 / 32 loss=6.585, sample_size=30, ntokens=31, wps=26.9, ups=0.87, wpb=31, bsz=1, num_updates=13, lr=0.003, gnorm=14.004, loss_scale=4, train_wall=1, gb_free=32.6, wall=15\n",
            "2024-03-01 14:43:59 | INFO | train_inner | epoch 001:     14 / 32 loss=6.177, sample_size=29, ntokens=30, wps=26.3, ups=0.88, wpb=30, bsz=1, num_updates=14, lr=0.003, gnorm=11.204, loss_scale=4, train_wall=1, gb_free=32.6, wall=17\n",
            "2024-03-01 14:44:01 | INFO | train_inner | epoch 001:     15 / 32 loss=4.379, sample_size=33, ntokens=34, wps=26.7, ups=0.78, wpb=34, bsz=1, num_updates=15, lr=0.003, gnorm=11.118, loss_scale=4, train_wall=1, gb_free=32.6, wall=18\n",
            "2024-03-01 14:44:02 | INFO | train_inner | epoch 001:     16 / 32 loss=6.248, sample_size=36, ntokens=37, wps=26.6, ups=0.72, wpb=37, bsz=1, num_updates=16, lr=0.003, gnorm=11.068, loss_scale=4, train_wall=1, gb_free=32.6, wall=19\n",
            "2024-03-01 14:44:03 | INFO | train_inner | epoch 001:     17 / 32 loss=4.277, sample_size=19, ntokens=20, wps=25, ups=1.25, wpb=20, bsz=1, num_updates=17, lr=0.003, gnorm=10.218, loss_scale=4, train_wall=1, gb_free=32.6, wall=20\n",
            "2024-03-01 14:44:04 | INFO | train_inner | epoch 001:     18 / 32 loss=4.655, sample_size=16, ntokens=17, wps=24.7, ups=1.46, wpb=17, bsz=1, num_updates=18, lr=0.003, gnorm=12.361, loss_scale=4, train_wall=1, gb_free=32.6, wall=21\n",
            "2024-03-01 14:44:05 | INFO | train_inner | epoch 001:     19 / 32 loss=4.317, sample_size=39, ntokens=40, wps=27.5, ups=0.69, wpb=40, bsz=1, num_updates=19, lr=0.003, gnorm=12.544, loss_scale=4, train_wall=1, gb_free=32.6, wall=22\n",
            "2024-03-01 14:44:06 | INFO | train_inner | epoch 001:     20 / 32 loss=4.194, sample_size=25, ntokens=26, wps=26.2, ups=1.01, wpb=26, bsz=1, num_updates=20, lr=0.003, gnorm=11.494, loss_scale=4, train_wall=1, gb_free=32.6, wall=23\n",
            "2024-03-01 14:44:07 | INFO | train_inner | epoch 001:     21 / 32 loss=5.608, sample_size=36, ntokens=37, wps=26.9, ups=0.73, wpb=37, bsz=1, num_updates=21, lr=0.003, gnorm=10.281, loss_scale=4, train_wall=1, gb_free=32.6, wall=25\n",
            "2024-03-01 14:44:09 | INFO | train_inner | epoch 001:     22 / 32 loss=5.588, sample_size=39, ntokens=40, wps=27, ups=0.68, wpb=40, bsz=1, num_updates=22, lr=0.003, gnorm=9.984, loss_scale=4, train_wall=1, gb_free=32.6, wall=26\n",
            "2024-03-01 14:44:12 | INFO | train_inner | epoch 001:     23 / 32 loss=6.162, sample_size=52, ntokens=53, wps=19.7, ups=0.37, wpb=53, bsz=1, num_updates=23, lr=0.003, gnorm=35.959, loss_scale=4, train_wall=3, gb_free=32.6, wall=29\n",
            "2024-03-01 14:44:13 | INFO | train_inner | epoch 001:     24 / 32 loss=4.703, sample_size=27, ntokens=28, wps=26.8, ups=0.96, wpb=28, bsz=1, num_updates=24, lr=0.003, gnorm=13.976, loss_scale=4, train_wall=1, gb_free=32.6, wall=30\n",
            "2024-03-01 14:44:14 | INFO | train_inner | epoch 001:     25 / 32 loss=4.874, sample_size=31, ntokens=32, wps=26.9, ups=0.84, wpb=32, bsz=1, num_updates=25, lr=0.003, gnorm=8.127, loss_scale=4, train_wall=1, gb_free=32.6, wall=31\n",
            "2024-03-01 14:44:15 | INFO | train_inner | epoch 001:     26 / 32 loss=5.158, sample_size=16, ntokens=17, wps=25.2, ups=1.48, wpb=17, bsz=1, num_updates=26, lr=0.003, gnorm=12.539, loss_scale=4, train_wall=1, gb_free=32.6, wall=32\n",
            "2024-03-01 14:44:16 | INFO | train_inner | epoch 001:     27 / 32 loss=4.768, sample_size=39, ntokens=40, wps=27.8, ups=0.69, wpb=40, bsz=1, num_updates=27, lr=0.003, gnorm=10.178, loss_scale=4, train_wall=1, gb_free=32.6, wall=33\n",
            "2024-03-01 14:44:17 | INFO | train_inner | epoch 001:     28 / 32 loss=6.239, sample_size=32, ntokens=33, wps=26.9, ups=0.82, wpb=33, bsz=1, num_updates=28, lr=0.003, gnorm=9.845, loss_scale=4, train_wall=1, gb_free=32.6, wall=34\n",
            "2024-03-01 14:44:19 | INFO | train_inner | epoch 001:     29 / 32 loss=4.908, sample_size=47, ntokens=48, wps=27.7, ups=0.58, wpb=48, bsz=1, num_updates=29, lr=0.003, gnorm=7.999, loss_scale=4, train_wall=2, gb_free=32.6, wall=36\n",
            "2024-03-01 14:44:20 | INFO | train_inner | epoch 001:     30 / 32 loss=5.251, sample_size=39, ntokens=40, wps=27.6, ups=0.69, wpb=40, bsz=1, num_updates=30, lr=0.003, gnorm=9.928, loss_scale=4, train_wall=1, gb_free=32.6, wall=37\n",
            "2024-03-01 14:44:22 | INFO | train_inner | epoch 001:     31 / 32 loss=5.193, sample_size=53, ntokens=54, wps=27.6, ups=0.51, wpb=54, bsz=1, num_updates=31, lr=0.003, gnorm=7.613, loss_scale=4, train_wall=2, gb_free=32.6, wall=39\n",
            "2024-03-01 14:44:24 | INFO | train_inner | epoch 001:     32 / 32 loss=4.668, sample_size=47, ntokens=48, wps=27.7, ups=0.58, wpb=48, bsz=1, num_updates=32, lr=0.003, gnorm=11.495, loss_scale=4, train_wall=2, gb_free=32.6, wall=41\n",
            "2024-03-01 14:44:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 32 updates\n",
            "2024-03-01 14:44:24 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/mr/en_dense_lm_1_3b/0.003/checkpoint1.pt\n",
            "2024-03-01 14:44:42 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/mr/en_dense_lm_1_3b/0.003/checkpoint1.pt\n",
            "2024-03-01 14:45:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/mr/en_dense_lm_1_3b/0.003/checkpoint1.pt (epoch 1 @ 32 updates, score None) (writing took 38.35032729200066 seconds)\n",
            "2024-03-01 14:45:02 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
            "2024-03-01 14:45:02 | INFO | train | epoch 001 | loss 5.712 | sample_size 31.156 | ntokens 32.156 | wps 13.1 | ups 0.4 | wpb 32.2 | bsz 1 | num_updates 32 | lr 0.003 | gnorm 12.188 | loss_scale 4 | train_wall 41 | gb_free 32.6 | wall 79\n",
            "2024-03-01 14:45:02 | INFO | fairseq_cli.train | done training in 79.2 seconds\n",
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/mr/ftzs/record_info.jsonl': No such file or directory\n",
            "+ SEED=5\n",
            "+ TASK=mr\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/mr/en_dense_lm_1_3b/0.003/checkpoint_last.pt\n",
            "+ ARCH=gptmodel_large\n",
            "+ K=0\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/mr\n",
            "+ ana_setting=ftzs\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' mr = agnews ']'\n",
            "+ '[' mr = trec ']'\n",
            "+ '[' mr = sst5 ']'\n",
            "+ '[' mr = dbpedia ']'\n",
            "+ '[' mr = cb ']'\n",
            "+ '[' mr = arce ']'\n",
            "+ '[' mr = arcc ']'\n",
            "+ '[' mr = obqa ']'\n",
            "+ '[' mr = hellaswag ']'\n",
            "+ '[' mr = storycloze ']'\n",
            "+ '[' mr = raceh ']'\n",
            "+ '[' mr = racem ']'\n",
            "+ '[' mr = nq ']'\n",
            "+ '[' mr = webqs ']'\n",
            "+ '[' mr = triviaqa ']'\n",
            "+ '[' mr = sq2 ']'\n",
            "+ '[' mr = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ BSZ=2\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_eval --arch gptmodel_large --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --max-epoch 1 --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --max-update 0 --fp16 --eval-data mr --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 5 --reset-dataloader --no-save --k 0 --batch-size 2 --batch-size-valid 2 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/mr/en_dense_lm_1_3b/0.003/checkpoint_last.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/mr --ana-setting ftzs --permut-index 0\n",
            "+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output//train_log_ftzs.txt\n",
            "2024-03-01 14:45:12 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-01 14:45:12 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-01 14:45:12 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-01 14:45:13.973106: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-01 14:45:13.973161: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-01 14:45:13.974781: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-01 14:45:15.233382: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-01 14:45:17 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 5, 'eval_data': 'mr', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/mr', 'ana_setting': 'ftzs', 'optim_group': 'all', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 0, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_large', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2048, 'decoder_output_dim': 2048, 'decoder_input_dim': 2048, 'decoder_ffn_embed_dim': 8192, 'decoder_layers': 24, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/mr/en_dense_lm_1_3b/0.003/checkpoint_last.pt'}, 'criterion': {'_name': 'fs_eval', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 5, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 2, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 2, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': True, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=5, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_eval', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=2, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid='2', max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_large', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.25], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=True, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='mr', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/mr', ana_setting='ftzs', optim_group='all', tokens_per_sample=2048, max_target_positions=None, k=0, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/mr/en_dense_lm_1_3b/0.003/checkpoint_last.pt', no_seed_provided=False, decoder_layers=24, decoder_embed_dim=2048, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2048, decoder_output_dim=2048, decoder_ffn_embed_dim=8192, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-01 14:45:17 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-01 14:45:18 | WARNING | datasets.builder | Using custom data configuration default\n",
            "2024-03-01 14:45:18 | WARNING | datasets.builder | Reusing dataset rotten_tomatoes (/root/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46)\n",
            "100%|██████████| 3/3 [00:00<00:00, 618.66it/s]\n",
            "2024-03-01 14:45:18 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-4ddeb248d6cad166.arrow\n",
            "2024-03-01 14:45:18 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-3299f20b13103dcc.arrow\n",
            "2024-03-01 14:45:56 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-01 14:45:58 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2048, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-23): 24 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
            "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2048, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-01 14:45:58 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-01 14:45:58 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-01 14:45:58 | INFO | fairseq_cli.train | criterion: FewshotEvalCriterion\n",
            "2024-03-01 14:45:58 | INFO | fairseq_cli.train | num. shared model params: 1,313,460,224 (num. trained: 2,048)\n",
            "2024-03-01 14:45:58 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-01 14:45:59 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-01 14:45:59 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 14:45:59 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-01 14:45:59 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 14:45:59 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-01 14:45:59 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 2\n",
            "2024-03-01 14:45:59 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt\n",
            "2024-03-01 14:45:59 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last.pt\n",
            "2024-03-01 14:45:59 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-01 14:46:00 | INFO | fairseq_cli.train | Start validating\n",
            "2024-03-01 14:46:00 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "------------ example 0 input str valid is ['Review: i liked a lot of the smaller scenes . Sentiment:', 'Review: i liked a lot of the smaller scenes . Sentiment:']\n",
            "------------ example 0 label str valid is [' Negative', ' Positive']\n",
            "------------ example 1 input str valid is ['Review: what happens when something goes bump in the night and nobody cares ? Sentiment:', 'Review: what happens when something goes bump in the night and nobody cares ? Sentiment:']\n",
            "------------ example 1 label str valid is [' Negative', ' Positive']\n",
            "NOTE: true K of baseline is 0, max valid len is 84\n",
            "| Loaded valid with 2132 samples\n",
            "| Loaded train with 2132 samples\n",
            "2024-03-01 14:48:06 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 1.267 | nll_loss 0.02 | accuracy 73 | f1 0 | pos_proportion 50 | neg_proportion 50 | wps 547.6 | wpb 64 | bsz 1 | num_updates 0\n",
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/mr/zs/record_info.jsonl': No such file or directory\n",
            "+ SEED=5\n",
            "+ TASK=mr\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt\n",
            "+ ARCH=gptmodel_large\n",
            "+ K=0\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/mr\n",
            "+ ana_setting=zs\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' mr = agnews ']'\n",
            "+ '[' mr = trec ']'\n",
            "+ '[' mr = sst5 ']'\n",
            "+ '[' mr = dbpedia ']'\n",
            "+ '[' mr = cb ']'\n",
            "+ '[' mr = arce ']'\n",
            "+ '[' mr = arcc ']'\n",
            "+ '[' mr = obqa ']'\n",
            "+ '[' mr = hellaswag ']'\n",
            "+ '[' mr = storycloze ']'\n",
            "+ '[' mr = raceh ']'\n",
            "+ '[' mr = racem ']'\n",
            "+ '[' mr = nq ']'\n",
            "+ '[' mr = webqs ']'\n",
            "+ '[' mr = triviaqa ']'\n",
            "+ '[' mr = sq2 ']'\n",
            "+ '[' mr = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ BSZ=2\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_eval --arch gptmodel_large --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --max-epoch 1 --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --max-update 0 --fp16 --eval-data mr --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 5 --reset-dataloader --no-save --k 0 --batch-size 2 --batch-size-valid 2 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/mr --ana-setting zs --permut-index 0\n",
            "+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output//train_log_zs.txt\n",
            "2024-03-01 14:48:18 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-01 14:48:19 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-01 14:48:19 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-01 14:48:20.649422: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-01 14:48:20.649463: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-01 14:48:20.651347: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-01 14:48:22.001630: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-01 14:48:24 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 5, 'eval_data': 'mr', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/mr', 'ana_setting': 'zs', 'optim_group': 'all', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 0, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_large', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2048, 'decoder_output_dim': 2048, 'decoder_input_dim': 2048, 'decoder_ffn_embed_dim': 8192, 'decoder_layers': 24, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt'}, 'criterion': {'_name': 'fs_eval', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 5, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 2, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 2, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': True, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=5, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_eval', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=2, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid='2', max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_large', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.25], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=True, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='mr', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/mr', ana_setting='zs', optim_group='all', tokens_per_sample=2048, max_target_positions=None, k=0, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt', no_seed_provided=False, decoder_layers=24, decoder_embed_dim=2048, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2048, decoder_output_dim=2048, decoder_ffn_embed_dim=8192, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-01 14:48:24 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-01 14:48:26 | WARNING | datasets.builder | Using custom data configuration default\n",
            "2024-03-01 14:48:26 | WARNING | datasets.builder | Reusing dataset rotten_tomatoes (/root/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46)\n",
            "100%|██████████| 3/3 [00:00<00:00, 744.68it/s]\n",
            "2024-03-01 14:48:26 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-4ddeb248d6cad166.arrow\n",
            "2024-03-01 14:48:26 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-3299f20b13103dcc.arrow\n",
            "2024-03-01 14:49:02 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-01 14:49:03 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2048, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-23): 24 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
            "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2048, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-01 14:49:03 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-01 14:49:03 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-01 14:49:03 | INFO | fairseq_cli.train | criterion: FewshotEvalCriterion\n",
            "2024-03-01 14:49:03 | INFO | fairseq_cli.train | num. shared model params: 1,313,460,224 (num. trained: 2,048)\n",
            "2024-03-01 14:49:03 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-01 14:49:05 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-01 14:49:05 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 14:49:05 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-01 14:49:05 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 14:49:05 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-01 14:49:05 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 2\n",
            "2024-03-01 14:49:05 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt\n",
            "2024-03-01 14:49:05 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last.pt\n",
            "2024-03-01 14:49:05 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-01 14:49:05 | INFO | fairseq_cli.train | Start validating\n",
            "2024-03-01 14:49:05 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "------------ example 0 input str valid is ['Review: i liked a lot of the smaller scenes . Sentiment:', 'Review: i liked a lot of the smaller scenes . Sentiment:']\n",
            "------------ example 0 label str valid is [' Negative', ' Positive']\n",
            "------------ example 1 input str valid is ['Review: what happens when something goes bump in the night and nobody cares ? Sentiment:', 'Review: what happens when something goes bump in the night and nobody cares ? Sentiment:']\n",
            "------------ example 1 label str valid is [' Negative', ' Positive']\n",
            "NOTE: true K of baseline is 0, max valid len is 84\n",
            "| Loaded valid with 2132 samples\n",
            "| Loaded train with 2132 samples\n",
            "2024-03-01 14:50:33 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 13.027 | nll_loss 0.204 | accuracy 65.9 | f1 0 | pos_proportion 50 | neg_proportion 50 | wps 787.6 | wpb 64 | bsz 1 | num_updates 0\n",
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/mr/icl/record_info.jsonl': No such file or directory\n",
            "+ SEED=5\n",
            "+ TASK=mr\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt\n",
            "+ ARCH=gptmodel_large\n",
            "+ K=32\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/mr\n",
            "+ ana_setting=icl\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' mr = agnews ']'\n",
            "+ '[' mr = trec ']'\n",
            "+ '[' mr = sst5 ']'\n",
            "+ '[' mr = dbpedia ']'\n",
            "+ '[' mr = cb ']'\n",
            "+ '[' mr = arce ']'\n",
            "+ '[' mr = arcc ']'\n",
            "+ '[' mr = obqa ']'\n",
            "+ '[' mr = hellaswag ']'\n",
            "+ '[' mr = storycloze ']'\n",
            "+ '[' mr = raceh ']'\n",
            "+ '[' mr = racem ']'\n",
            "+ '[' mr = nq ']'\n",
            "+ '[' mr = webqs ']'\n",
            "+ '[' mr = triviaqa ']'\n",
            "+ '[' mr = sq2 ']'\n",
            "+ '[' mr = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ BSZ=2\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_eval --arch gptmodel_large --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --max-epoch 1 --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --max-update 0 --fp16 --eval-data mr --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 5 --reset-dataloader --no-save --k 32 --batch-size 2 --batch-size-valid 2 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output//train_log_icl.txt\n",
            "LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/mr --ana-setting icl --permut-index 0\n",
            "2024-03-01 14:50:41 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-01 14:50:42 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-01 14:50:42 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-01 14:50:43.719067: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-01 14:50:43.719115: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-01 14:50:43.720716: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-01 14:50:44.946795: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-01 14:50:47 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 5, 'eval_data': 'mr', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/mr', 'ana_setting': 'icl', 'optim_group': 'all', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 32, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_large', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2048, 'decoder_output_dim': 2048, 'decoder_input_dim': 2048, 'decoder_ffn_embed_dim': 8192, 'decoder_layers': 24, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt'}, 'criterion': {'_name': 'fs_eval', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 5, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 2, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 2, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': True, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=5, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_eval', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=2, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid='2', max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_large', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.25], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=True, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='mr', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/mr', ana_setting='icl', optim_group='all', tokens_per_sample=2048, max_target_positions=None, k=32, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt', no_seed_provided=False, decoder_layers=24, decoder_embed_dim=2048, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2048, decoder_output_dim=2048, decoder_ffn_embed_dim=8192, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-01 14:50:47 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-01 14:50:48 | WARNING | datasets.builder | Using custom data configuration default\n",
            "2024-03-01 14:50:48 | WARNING | datasets.builder | Reusing dataset rotten_tomatoes (/root/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46)\n",
            "100%|██████████| 3/3 [00:00<00:00, 743.32it/s]\n",
            "2024-03-01 14:50:48 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-4ddeb248d6cad166.arrow\n",
            "2024-03-01 14:50:48 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-3299f20b13103dcc.arrow\n",
            "2024-03-01 14:51:22 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-01 14:51:23 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2048, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-23): 24 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
            "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2048, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-01 14:51:23 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-01 14:51:23 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-01 14:51:23 | INFO | fairseq_cli.train | criterion: FewshotEvalCriterion\n",
            "2024-03-01 14:51:23 | INFO | fairseq_cli.train | num. shared model params: 1,313,460,224 (num. trained: 2,048)\n",
            "2024-03-01 14:51:23 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-01 14:51:25 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-01 14:51:25 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 14:51:25 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-01 14:51:25 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 14:51:25 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-01 14:51:25 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 2\n",
            "2024-03-01 14:51:25 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt\n",
            "2024-03-01 14:51:25 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last.pt\n",
            "2024-03-01 14:51:25 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-01 14:51:25 | INFO | fairseq_cli.train | Start validating\n",
            "2024-03-01 14:51:25 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "------------ example 0 input str train is ['Review: . . . salaciously simplistic . Sentiment:', 'Review: . . . salaciously simplistic . Sentiment:']\n",
            "------------ example 0 label str train is [' Negative', ' Positive']\n",
            "------------ example 1 input str train is ['Review: birthday girl is an amusing joy ride , with some surprisingly violent moments . Sentiment:', 'Review: birthday girl is an amusing joy ride , with some surprisingly violent moments . Sentiment:']\n",
            "------------ example 1 label str train is [' Negative', ' Positive']\n",
            "------------ example 0 input str valid is ['Review: i liked a lot of the smaller scenes . Sentiment:', 'Review: i liked a lot of the smaller scenes . Sentiment:']\n",
            "------------ example 0 label str valid is [' Negative', ' Positive']\n",
            "------------ example 1 input str valid is ['Review: what happens when something goes bump in the night and nobody cares ? Sentiment:', 'Review: what happens when something goes bump in the night and nobody cares ? Sentiment:']\n",
            "------------ example 1 label str valid is [' Negative', ' Positive']\n",
            "NOTE: true K of baseline is 32, max valid len is 84\n",
            "| Loaded valid with 2132 samples\n",
            "| Loaded train with 2132 samples\n",
            "2024-03-01 14:53:31 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 0.528 | nll_loss 0 | accuracy 89 | f1 0 | pos_proportion 50 | neg_proportion 50 | wps 18087.4 | wpb 2122 | bsz 1 | num_updates 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash run.sh en_dense_lm_1_3b gptmodel_large subj 32 4 0 \"{icl_base_dir}/output\" \"{icl_base_dir}\" 0.003"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DU1rtw-Tb-sa",
        "outputId": "7f686af6-b7cc-46c7-bca1-75a2fac00f51",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/subj/ft/record_info.jsonl': No such file or directory\n",
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/subj/en_dense_lm_1_3b/0.003': No such file or directory\n",
            "+ SEED=4\n",
            "+ TASK=subj\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt\n",
            "+ ARCH=gptmodel_large\n",
            "+ K=32\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/subj\n",
            "+ ana_setting=ft\n",
            "+ lr=0.003\n",
            "+ max_epoch=1\n",
            "+ save_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/subj/en_dense_lm_1_3b/0.003\n",
            "+ optim_group=attn_kv\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' subj = agnews ']'\n",
            "+ '[' subj = trec ']'\n",
            "+ '[' subj = sst5 ']'\n",
            "+ '[' subj = dbpedia ']'\n",
            "+ '[' subj = cb ']'\n",
            "+ '[' subj = arce ']'\n",
            "+ '[' subj = arcc ']'\n",
            "+ '[' subj = obqa ']'\n",
            "+ '[' subj = hellaswag ']'\n",
            "+ '[' subj = storycloze ']'\n",
            "+ '[' subj = raceh ']'\n",
            "+ '[' subj = racem ']'\n",
            "+ '[' subj = nq ']'\n",
            "+ '[' subj = webqs ']'\n",
            "+ '[' subj = triviaqa ']'\n",
            "+ '[' subj = sq2 ']'\n",
            "+ '[' subj = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ORI_BSZ=1\n",
            "+ BSZ=2\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_ft --arch gptmodel_large --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --lr 0.003 --max-epoch 1 --curriculum 1000000 --max-update 1000000 --fp16 --eval-data subj --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 4 --reset-dataloader --k 32 --batch-size 1 --batch-size-valid 1 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/subj --ana-setting ft --save-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/subj/en_dense_lm_1_3b/0.003 --save-interval 1 --save-interval-updates 1000000 --validate-interval 1000000 --disable-validation --optim-group attn_kv --permut-index 0\n",
            "+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output//train_log_ft.txt\n",
            "2024-03-01 14:53:40 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-01 14:53:41 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-01 14:53:41 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-01 14:53:42.722926: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-01 14:53:42.722986: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-01 14:53:42.724875: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-01 14:53:43.975515: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-01 14:53:46 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 4, 'eval_data': 'subj', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/subj', 'ana_setting': 'ft', 'optim_group': 'attn_kv', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 32, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_large', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2048, 'decoder_output_dim': 2048, 'decoder_input_dim': 2048, 'decoder_ffn_embed_dim': 8192, 'decoder_layers': 24, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt'}, 'criterion': {'_name': 'fs_ft', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.003]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 4, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1000000, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': None, 'batch_size_valid': 1, 'max_valid_steps': None, 'curriculum': 1000000, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 1000000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.003], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/subj/en_dense_lm_1_3b/0.003', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 1000000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=4, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_ft', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=1, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1000000, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=True, max_tokens_valid=None, batch_size_valid='1', max_valid_steps=None, curriculum=1000000, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_large', max_epoch=1, max_update=1000000, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.003], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/subj/en_dense_lm_1_3b/0.003', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=1000000, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='subj', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/subj', ana_setting='ft', optim_group='attn_kv', tokens_per_sample=2048, max_target_positions=None, k=32, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt', no_seed_provided=False, decoder_layers=24, decoder_embed_dim=2048, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2048, decoder_output_dim=2048, decoder_ffn_embed_dim=8192, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-01 14:53:46 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-01 14:53:48 | WARNING | datasets.builder | Using custom data configuration SetFit--subj-693a635c625bebac\n",
            "Downloading and preparing dataset json/SetFit--subj to /root/.cache/huggingface/datasets/SetFit___json/SetFit--subj-693a635c625bebac/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253...\n",
            "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]\n",
            "Downloading data:   0%|          | 0.00/1.45M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   5%|▍         | 66.6k/1.45M [00:00<00:05, 274kB/s]\u001b[A\n",
            "Downloading data:  14%|█▎        | 198k/1.45M [00:00<00:02, 427kB/s] \u001b[A\n",
            "Downloading data:  34%|███▍      | 493k/1.45M [00:00<00:01, 782kB/s]\u001b[A\n",
            "Downloading data: 100%|██████████| 1.45M/1.45M [00:01<00:00, 1.41MB/s]\n",
            "Downloading data files:  50%|█████     | 1/2 [00:01<00:01,  1.78s/it]\n",
            "Downloading data:   0%|          | 0.00/364k [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   9%|▉         | 33.8k/364k [00:00<00:02, 136kB/s]\u001b[A\n",
            "Downloading data:  27%|██▋       | 99.3k/364k [00:00<00:01, 211kB/s]\u001b[A\n",
            "Downloading data: 100%|██████████| 364k/364k [00:00<00:00, 488kB/s]\n",
            "Downloading data files: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]\n",
            "Extracting data files: 100%|██████████| 2/2 [00:00<00:00, 1283.64it/s]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/SetFit___json/SetFit--subj-693a635c625bebac/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253. Subsequent calls will reuse this data.\n",
            "100%|██████████| 2/2 [00:00<00:00, 806.21it/s]\n",
            "2024-03-01 14:54:28 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-01 14:54:29 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2048, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-23): 24 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
            "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2048, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-01 14:54:29 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-01 14:54:29 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-01 14:54:29 | INFO | fairseq_cli.train | criterion: FewshotFTCriterion\n",
            "2024-03-01 14:54:29 | INFO | fairseq_cli.train | num. shared model params: 1,313,460,224 (num. trained: 1,313,460,224)\n",
            "2024-03-01 14:54:29 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-01 14:54:31 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-01 14:54:31 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 14:54:31 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-01 14:54:31 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 14:54:31 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-01 14:54:31 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 1\n",
            "2024-03-01 14:54:31 | INFO | fairseq.trainer | Preparing to load checkpoint /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/subj/en_dense_lm_1_3b/0.003/checkpoint_last.pt\n",
            "2024-03-01 14:54:31 | INFO | fairseq.trainer | No existing checkpoint found /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/subj/en_dense_lm_1_3b/0.003/checkpoint_last.pt\n",
            "2024-03-01 14:54:31 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-01 14:54:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 32\n",
            "2024-03-01 14:54:31 | INFO | fairseq.trainer | begin training epoch 1\n",
            "2024-03-01 14:54:31 | INFO | fairseq_cli.train | Start fine-tuning\n",
            "------------ example 0 input str train is ['Input: a spellbinding african film about the modern condition of rootlessness , a state experienced by millions around the globe . Type:', 'Input: a spellbinding african film about the modern condition of rootlessness , a state experienced by millions around the globe . Type:']\n",
            "------------ example 0 label str train is [' objective', ' subjective']\n",
            "------------ example 1 input str train is [\"Input: and if she 's lucky , she may find love along the way . Type:\", \"Input: and if she 's lucky , she may find love along the way . Type:\"]\n",
            "------------ example 1 label str train is [' objective', ' subjective']\n",
            "------------ example 0 input str valid is ['Input: never giving up the fight to win the war , mcnamara is silently planning , waiting for his moment to strike back at the enemy . Type:', 'Input: never giving up the fight to win the war , mcnamara is silently planning , waiting for his moment to strike back at the enemy . Type:']\n",
            "------------ example 0 label str valid is [' objective', ' subjective']\n",
            "------------ example 1 input str valid is ['Input: if the story lacks bite , the performances are never less than affectionate . Type:', 'Input: if the story lacks bite , the performances are never less than affectionate . Type:']\n",
            "------------ example 1 label str valid is [' objective', ' subjective']\n",
            "NOTE: true K of baseline is 32, max valid len is 174\n",
            "------------ example 0 input str train is ['Input: a spellbinding african film about the modern condition of rootlessness , a state experienced by millions around the globe . Type:', 'Input: a spellbinding african film about the modern condition of rootlessness , a state experienced by millions around the globe . Type:']\n",
            "------------ example 0 label str train is [' objective', ' subjective']\n",
            "------------ example 1 input str train is [\"Input: and if she 's lucky , she may find love along the way . Type:\", \"Input: and if she 's lucky , she may find love along the way . Type:\"]\n",
            "------------ example 1 label str train is [' objective', ' subjective']\n",
            "NOTE: true K of baseline is 32\n",
            "| Loaded valid with 4000 samples\n",
            "| Loaded train with 32 samples\n",
            "2024-03-01 14:54:34 | INFO | train_inner | epoch 001:      1 / 32 loss=7.688, sample_size=28, ntokens=29, wps=0, ups=0, wpb=29, bsz=1, num_updates=1, lr=0.003, gnorm=13.101, loss_scale=4, train_wall=2, gb_free=32.8, wall=3\n",
            "2024-03-01 14:54:34 | INFO | train_inner | epoch 001:      2 / 32 loss=7.153, sample_size=20, ntokens=21, wps=24, ups=1.14, wpb=21, bsz=1, num_updates=2, lr=0.003, gnorm=11.635, loss_scale=4, train_wall=1, gb_free=32.6, wall=3\n",
            "2024-03-01 14:54:36 | INFO | train_inner | epoch 001:      3 / 32 loss=6.388, sample_size=32, ntokens=33, wps=26.1, ups=0.79, wpb=33, bsz=1, num_updates=3, lr=0.003, gnorm=10.738, loss_scale=4, train_wall=1, gb_free=32.6, wall=5\n",
            "2024-03-01 14:54:38 | INFO | train_inner | epoch 001:      4 / 32 loss=5.948, sample_size=48, ntokens=49, wps=26.5, ups=0.54, wpb=49, bsz=1, num_updates=4, lr=0.003, gnorm=9.857, loss_scale=4, train_wall=2, gb_free=32.6, wall=7\n",
            "2024-03-01 14:54:38 | INFO | train_inner | epoch 001:      5 / 32 loss=7.044, sample_size=21, ntokens=22, wps=25.5, ups=1.16, wpb=22, bsz=1, num_updates=5, lr=0.003, gnorm=12.782, loss_scale=4, train_wall=1, gb_free=32.6, wall=7\n",
            "2024-03-01 14:54:39 | INFO | train_inner | epoch 001:      6 / 32 loss=8.881, sample_size=19, ntokens=20, wps=24.8, ups=1.24, wpb=20, bsz=1, num_updates=6, lr=0.003, gnorm=14.212, loss_scale=4, train_wall=1, gb_free=32.6, wall=8\n",
            "2024-03-01 14:54:41 | INFO | train_inner | epoch 001:      7 / 32 loss=7.236, sample_size=45, ntokens=46, wps=26.7, ups=0.58, wpb=46, bsz=1, num_updates=7, lr=0.003, gnorm=9.07, loss_scale=4, train_wall=2, gb_free=32.6, wall=10\n",
            "2024-03-01 14:54:43 | INFO | train_inner | epoch 001:      8 / 32 loss=6.88, sample_size=44, ntokens=45, wps=26.6, ups=0.59, wpb=45, bsz=1, num_updates=8, lr=0.003, gnorm=11.556, loss_scale=4, train_wall=2, gb_free=32.6, wall=12\n",
            "2024-03-01 14:54:44 | INFO | train_inner | epoch 001:      9 / 32 loss=5.433, sample_size=39, ntokens=40, wps=26.4, ups=0.66, wpb=40, bsz=1, num_updates=9, lr=0.003, gnorm=7.829, loss_scale=4, train_wall=2, gb_free=32.6, wall=13\n",
            "2024-03-01 14:54:45 | INFO | train_inner | epoch 001:     10 / 32 loss=5.31, sample_size=28, ntokens=29, wps=26.6, ups=0.92, wpb=29, bsz=1, num_updates=10, lr=0.003, gnorm=9.787, loss_scale=4, train_wall=1, gb_free=32.6, wall=14\n",
            "2024-03-01 14:54:46 | INFO | train_inner | epoch 001:     11 / 32 loss=5.604, sample_size=29, ntokens=30, wps=26.8, ups=0.89, wpb=30, bsz=1, num_updates=11, lr=0.003, gnorm=11.149, loss_scale=4, train_wall=1, gb_free=32.6, wall=15\n",
            "2024-03-01 14:54:48 | INFO | train_inner | epoch 001:     12 / 32 loss=4.97, sample_size=59, ntokens=60, wps=27.9, ups=0.46, wpb=60, bsz=1, num_updates=12, lr=0.003, gnorm=8.142, loss_scale=4, train_wall=2, gb_free=32.6, wall=18\n",
            "2024-03-01 14:54:50 | INFO | train_inner | epoch 001:     13 / 32 loss=5.581, sample_size=46, ntokens=47, wps=27.2, ups=0.58, wpb=47, bsz=1, num_updates=13, lr=0.003, gnorm=8.216, loss_scale=4, train_wall=2, gb_free=32.6, wall=19\n",
            "2024-03-01 14:54:51 | INFO | train_inner | epoch 001:     14 / 32 loss=7.891, sample_size=30, ntokens=31, wps=26.7, ups=0.86, wpb=31, bsz=1, num_updates=14, lr=0.003, gnorm=31.937, loss_scale=4, train_wall=1, gb_free=32.6, wall=20\n",
            "2024-03-01 14:54:52 | INFO | train_inner | epoch 001:     15 / 32 loss=6.458, sample_size=29, ntokens=30, wps=26.6, ups=0.89, wpb=30, bsz=1, num_updates=15, lr=0.003, gnorm=10.217, loss_scale=4, train_wall=1, gb_free=32.6, wall=22\n",
            "2024-03-01 14:54:53 | INFO | train_inner | epoch 001:     16 / 32 loss=5.592, sample_size=20, ntokens=21, wps=25.7, ups=1.23, wpb=21, bsz=1, num_updates=16, lr=0.003, gnorm=11.347, loss_scale=4, train_wall=1, gb_free=32.6, wall=22\n",
            "2024-03-01 14:54:55 | INFO | train_inner | epoch 001:     17 / 32 loss=5.782, sample_size=31, ntokens=32, wps=26.7, ups=0.83, wpb=32, bsz=1, num_updates=17, lr=0.003, gnorm=12.925, loss_scale=4, train_wall=1, gb_free=32.6, wall=24\n",
            "2024-03-01 14:54:56 | INFO | train_inner | epoch 001:     18 / 32 loss=7.427, sample_size=31, ntokens=32, wps=26.6, ups=0.83, wpb=32, bsz=1, num_updates=18, lr=0.003, gnorm=9.612, loss_scale=4, train_wall=1, gb_free=32.6, wall=25\n",
            "2024-03-01 14:54:58 | INFO | train_inner | epoch 001:     19 / 32 loss=5.519, sample_size=60, ntokens=61, wps=27.4, ups=0.45, wpb=61, bsz=1, num_updates=19, lr=0.003, gnorm=7.585, loss_scale=4, train_wall=2, gb_free=32.6, wall=27\n",
            "2024-03-01 14:54:59 | INFO | train_inner | epoch 001:     20 / 32 loss=5.894, sample_size=41, ntokens=42, wps=27.1, ups=0.65, wpb=42, bsz=1, num_updates=20, lr=0.003, gnorm=11.511, loss_scale=4, train_wall=2, gb_free=32.6, wall=29\n",
            "2024-03-01 14:55:01 | INFO | train_inner | epoch 001:     21 / 32 loss=5.162, sample_size=46, ntokens=47, wps=27, ups=0.58, wpb=47, bsz=1, num_updates=21, lr=0.003, gnorm=8.01, loss_scale=4, train_wall=2, gb_free=32.6, wall=30\n",
            "2024-03-01 14:55:02 | INFO | train_inner | epoch 001:     22 / 32 loss=5.926, sample_size=21, ntokens=22, wps=25.8, ups=1.17, wpb=22, bsz=1, num_updates=22, lr=0.003, gnorm=15.361, loss_scale=4, train_wall=1, gb_free=32.6, wall=31\n",
            "2024-03-01 14:55:05 | INFO | train_inner | epoch 001:     23 / 32 loss=5.598, sample_size=68, ntokens=69, wps=27.3, ups=0.4, wpb=69, bsz=1, num_updates=23, lr=0.003, gnorm=7.548, loss_scale=4, train_wall=3, gb_free=32.6, wall=34\n",
            "2024-03-01 14:55:05 | INFO | train_inner | epoch 001:     24 / 32 loss=6.157, sample_size=18, ntokens=19, wps=25.2, ups=1.33, wpb=19, bsz=1, num_updates=24, lr=0.003, gnorm=10.912, loss_scale=4, train_wall=1, gb_free=32.6, wall=34\n",
            "2024-03-01 14:55:07 | INFO | train_inner | epoch 001:     25 / 32 loss=6.171, sample_size=32, ntokens=33, wps=27.2, ups=0.82, wpb=33, bsz=1, num_updates=25, lr=0.003, gnorm=12.575, loss_scale=4, train_wall=1, gb_free=32.6, wall=36\n",
            "2024-03-01 14:55:08 | INFO | train_inner | epoch 001:     26 / 32 loss=4.847, sample_size=26, ntokens=27, wps=26.2, ups=0.97, wpb=27, bsz=1, num_updates=26, lr=0.003, gnorm=10.164, loss_scale=4, train_wall=1, gb_free=32.6, wall=37\n",
            "2024-03-01 14:55:09 | INFO | train_inner | epoch 001:     27 / 32 loss=6.398, sample_size=25, ntokens=26, wps=26.8, ups=1.03, wpb=26, bsz=1, num_updates=27, lr=0.003, gnorm=11.916, loss_scale=4, train_wall=1, gb_free=32.6, wall=38\n",
            "2024-03-01 14:55:10 | INFO | train_inner | epoch 001:     28 / 32 loss=5.831, sample_size=27, ntokens=28, wps=26.8, ups=0.96, wpb=28, bsz=1, num_updates=28, lr=0.003, gnorm=11.11, loss_scale=4, train_wall=1, gb_free=32.6, wall=39\n",
            "2024-03-01 14:55:11 | INFO | train_inner | epoch 001:     29 / 32 loss=5.502, sample_size=38, ntokens=39, wps=27.3, ups=0.7, wpb=39, bsz=1, num_updates=29, lr=0.003, gnorm=11.979, loss_scale=4, train_wall=1, gb_free=32.6, wall=40\n",
            "2024-03-01 14:55:12 | INFO | train_inner | epoch 001:     30 / 32 loss=5.634, sample_size=32, ntokens=33, wps=27.5, ups=0.83, wpb=33, bsz=1, num_updates=30, lr=0.003, gnorm=11.032, loss_scale=4, train_wall=1, gb_free=32.6, wall=41\n",
            "2024-03-01 14:55:13 | INFO | train_inner | epoch 001:     31 / 32 loss=5.029, sample_size=25, ntokens=26, wps=26.9, ups=1.03, wpb=26, bsz=1, num_updates=31, lr=0.003, gnorm=12.336, loss_scale=4, train_wall=1, gb_free=32.6, wall=42\n",
            "2024-03-01 14:55:14 | INFO | train_inner | epoch 001:     32 / 32 loss=4.53, sample_size=25, ntokens=26, wps=27, ups=1.04, wpb=26, bsz=1, num_updates=32, lr=0.003, gnorm=13.42, loss_scale=4, train_wall=1, gb_free=32.6, wall=43\n",
            "2024-03-01 14:55:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 32 updates\n",
            "2024-03-01 14:55:14 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/subj/en_dense_lm_1_3b/0.003/checkpoint1.pt\n",
            "2024-03-01 14:55:34 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/subj/en_dense_lm_1_3b/0.003/checkpoint1.pt\n",
            "2024-03-01 14:55:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/subj/en_dense_lm_1_3b/0.003/checkpoint1.pt (epoch 1 @ 32 updates, score None) (writing took 40.94911259800028 seconds)\n",
            "2024-03-01 14:55:55 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
            "2024-03-01 14:55:55 | INFO | train | epoch 001 | loss 6.008 | sample_size 33.844 | ntokens 34.844 | wps 13.3 | ups 0.38 | wpb 34.8 | bsz 1 | num_updates 32 | lr 0.003 | gnorm 11.549 | loss_scale 4 | train_wall 43 | gb_free 32.6 | wall 84\n",
            "2024-03-01 14:55:55 | INFO | fairseq_cli.train | done training in 83.9 seconds\n",
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/subj/ftzs/record_info.jsonl': No such file or directory\n",
            "+ SEED=4\n",
            "+ TASK=subj\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/subj/en_dense_lm_1_3b/0.003/checkpoint_last.pt\n",
            "+ ARCH=gptmodel_large\n",
            "+ K=0\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/subj\n",
            "+ ana_setting=ftzs\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' subj = agnews ']'\n",
            "+ '[' subj = trec ']'\n",
            "+ '[' subj = sst5 ']'\n",
            "+ '[' subj = dbpedia ']'\n",
            "+ '[' subj = cb ']'\n",
            "+ '[' subj = arce ']'\n",
            "+ '[' subj = arcc ']'\n",
            "+ '[' subj = obqa ']'\n",
            "+ '[' subj = hellaswag ']'\n",
            "+ '[' subj = storycloze ']'\n",
            "+ '[' subj = raceh ']'\n",
            "+ '[' subj = racem ']'\n",
            "+ '[' subj = nq ']'\n",
            "+ '[' subj = webqs ']'\n",
            "+ '[' subj = triviaqa ']'\n",
            "+ '[' subj = sq2 ']'\n",
            "+ '[' subj = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ BSZ=2\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_eval --arch gptmodel_large --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --max-epoch 1 --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --max-update 0 --fp16 --eval-data subj --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 4 --reset-dataloader --no-save --k 0 --batch-size 2 --batch-size-valid 2 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/subj/en_dense_lm_1_3b/0.003/checkpoint_last.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/subj --ana-setting ftzs --permut-index 0\n",
            "+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output//train_log_ftzs.txt\n",
            "2024-03-01 14:56:05 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-01 14:56:06 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-01 14:56:06 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-01 14:56:07.341536: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-01 14:56:07.341589: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-01 14:56:07.343149: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-01 14:56:08.665204: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-01 14:56:11 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 4, 'eval_data': 'subj', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/subj', 'ana_setting': 'ftzs', 'optim_group': 'all', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 0, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_large', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2048, 'decoder_output_dim': 2048, 'decoder_input_dim': 2048, 'decoder_ffn_embed_dim': 8192, 'decoder_layers': 24, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/subj/en_dense_lm_1_3b/0.003/checkpoint_last.pt'}, 'criterion': {'_name': 'fs_eval', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 4, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 2, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 2, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': True, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=4, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_eval', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=2, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid='2', max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_large', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.25], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=True, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='subj', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/subj', ana_setting='ftzs', optim_group='all', tokens_per_sample=2048, max_target_positions=None, k=0, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/subj/en_dense_lm_1_3b/0.003/checkpoint_last.pt', no_seed_provided=False, decoder_layers=24, decoder_embed_dim=2048, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2048, decoder_output_dim=2048, decoder_ffn_embed_dim=8192, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-01 14:56:11 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-01 14:56:13 | WARNING | datasets.builder | Using custom data configuration SetFit--subj-693a635c625bebac\n",
            "2024-03-01 14:56:13 | WARNING | datasets.builder | Reusing dataset json (/root/.cache/huggingface/datasets/SetFit___json/SetFit--subj-693a635c625bebac/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253)\n",
            "100%|██████████| 2/2 [00:00<00:00, 406.52it/s]\n",
            "2024-03-01 14:56:13 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/SetFit___json/SetFit--subj-693a635c625bebac/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-41679576bb6cfc7c.arrow\n",
            "2024-03-01 14:56:13 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/SetFit___json/SetFit--subj-693a635c625bebac/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-6b58bb8b23415efd.arrow\n",
            "2024-03-01 14:56:51 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-01 14:56:53 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2048, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-23): 24 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
            "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2048, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-01 14:56:53 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-01 14:56:53 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-01 14:56:53 | INFO | fairseq_cli.train | criterion: FewshotEvalCriterion\n",
            "2024-03-01 14:56:53 | INFO | fairseq_cli.train | num. shared model params: 1,313,460,224 (num. trained: 2,048)\n",
            "2024-03-01 14:56:53 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-01 14:56:55 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-01 14:56:55 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 14:56:55 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-01 14:56:55 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 14:56:55 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-01 14:56:55 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 2\n",
            "2024-03-01 14:56:55 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt\n",
            "2024-03-01 14:56:55 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last.pt\n",
            "2024-03-01 14:56:55 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-01 14:56:55 | INFO | fairseq_cli.train | Start validating\n",
            "2024-03-01 14:56:55 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "------------ example 0 input str valid is ['Input: never giving up the fight to win the war , mcnamara is silently planning , waiting for his moment to strike back at the enemy . Type:', 'Input: never giving up the fight to win the war , mcnamara is silently planning , waiting for his moment to strike back at the enemy . Type:']\n",
            "------------ example 0 label str valid is [' objective', ' subjective']\n",
            "------------ example 1 input str valid is ['Input: if the story lacks bite , the performances are never less than affectionate . Type:', 'Input: if the story lacks bite , the performances are never less than affectionate . Type:']\n",
            "------------ example 1 label str valid is [' objective', ' subjective']\n",
            "NOTE: true K of baseline is 0, max valid len is 174\n",
            "| Loaded valid with 4000 samples\n",
            "| Loaded train with 4000 samples\n",
            "2024-03-01 15:00:46 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 2.056 | nll_loss 0.03 | accuracy 77.8 | f1 0 | pos_proportion 51.7 | neg_proportion 48.4 | wps 604.9 | wpb 69.7 | bsz 1 | num_updates 0\n",
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/subj/zs/record_info.jsonl': No such file or directory\n",
            "+ SEED=4\n",
            "+ TASK=subj\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt\n",
            "+ ARCH=gptmodel_large\n",
            "+ K=0\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/subj\n",
            "+ ana_setting=zs\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' subj = agnews ']'\n",
            "+ '[' subj = trec ']'\n",
            "+ '[' subj = sst5 ']'\n",
            "+ '[' subj = dbpedia ']'\n",
            "+ '[' subj = cb ']'\n",
            "+ '[' subj = arce ']'\n",
            "+ '[' subj = arcc ']'\n",
            "+ '[' subj = obqa ']'\n",
            "+ '[' subj = hellaswag ']'\n",
            "+ '[' subj = storycloze ']'\n",
            "+ '[' subj = raceh ']'\n",
            "+ '[' subj = racem ']'\n",
            "+ '[' subj = nq ']'\n",
            "+ '[' subj = webqs ']'\n",
            "+ '[' subj = triviaqa ']'\n",
            "+ '[' subj = sq2 ']'\n",
            "+ '[' subj = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ BSZ=2\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_eval --arch gptmodel_large --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --max-epoch 1 --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --max-update 0 --fp16 --eval-data subj --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 4 --reset-dataloader --no-save --k 0 --batch-size 2 --batch-size-valid 2 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/subj --ana-setting zs --permut-index 0\n",
            "+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output//train_log_zs.txt\n",
            "2024-03-01 15:01:05 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-01 15:01:06 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-01 15:01:06 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-01 15:01:08.306566: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-01 15:01:08.306623: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-01 15:01:08.308164: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-01 15:01:09.549420: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-01 15:01:11 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 4, 'eval_data': 'subj', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/subj', 'ana_setting': 'zs', 'optim_group': 'all', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 0, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_large', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2048, 'decoder_output_dim': 2048, 'decoder_input_dim': 2048, 'decoder_ffn_embed_dim': 8192, 'decoder_layers': 24, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt'}, 'criterion': {'_name': 'fs_eval', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 4, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 2, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 2, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': True, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=4, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_eval', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=2, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid='2', max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_large', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.25], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=True, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='subj', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/subj', ana_setting='zs', optim_group='all', tokens_per_sample=2048, max_target_positions=None, k=0, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt', no_seed_provided=False, decoder_layers=24, decoder_embed_dim=2048, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2048, decoder_output_dim=2048, decoder_ffn_embed_dim=8192, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-01 15:01:11 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-01 15:01:14 | WARNING | datasets.builder | Using custom data configuration SetFit--subj-693a635c625bebac\n",
            "2024-03-01 15:01:14 | WARNING | datasets.builder | Reusing dataset json (/root/.cache/huggingface/datasets/SetFit___json/SetFit--subj-693a635c625bebac/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253)\n",
            "100%|██████████| 2/2 [00:00<00:00, 417.12it/s]\n",
            "2024-03-01 15:01:14 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/SetFit___json/SetFit--subj-693a635c625bebac/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-41679576bb6cfc7c.arrow\n",
            "2024-03-01 15:01:14 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/SetFit___json/SetFit--subj-693a635c625bebac/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-6b58bb8b23415efd.arrow\n",
            "2024-03-01 15:01:49 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-01 15:01:50 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2048, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-23): 24 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
            "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2048, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-01 15:01:50 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-01 15:01:50 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-01 15:01:50 | INFO | fairseq_cli.train | criterion: FewshotEvalCriterion\n",
            "2024-03-01 15:01:50 | INFO | fairseq_cli.train | num. shared model params: 1,313,460,224 (num. trained: 2,048)\n",
            "2024-03-01 15:01:50 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-01 15:01:52 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-01 15:01:52 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 15:01:52 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-01 15:01:52 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 15:01:52 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-01 15:01:52 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 2\n",
            "2024-03-01 15:01:52 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt\n",
            "2024-03-01 15:01:52 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last.pt\n",
            "2024-03-01 15:01:52 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-01 15:01:53 | INFO | fairseq_cli.train | Start validating\n",
            "2024-03-01 15:01:53 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "------------ example 0 input str valid is ['Input: never giving up the fight to win the war , mcnamara is silently planning , waiting for his moment to strike back at the enemy . Type:', 'Input: never giving up the fight to win the war , mcnamara is silently planning , waiting for his moment to strike back at the enemy . Type:']\n",
            "------------ example 0 label str valid is [' objective', ' subjective']\n",
            "------------ example 1 input str valid is ['Input: if the story lacks bite , the performances are never less than affectionate . Type:', 'Input: if the story lacks bite , the performances are never less than affectionate . Type:']\n",
            "------------ example 1 label str valid is [' objective', ' subjective']\n",
            "NOTE: true K of baseline is 0, max valid len is 174\n",
            "| Loaded valid with 4000 samples\n",
            "| Loaded train with 4000 samples\n",
            "2024-03-01 15:04:39 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 14.538 | nll_loss 0.209 | accuracy 72.5 | f1 0 | pos_proportion 51.7 | neg_proportion 48.4 | wps 843.5 | wpb 69.7 | bsz 1 | num_updates 0\n",
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/subj/icl/record_info.jsonl': No such file or directory\n",
            "+ SEED=4\n",
            "+ TASK=subj\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt\n",
            "+ ARCH=gptmodel_large\n",
            "+ K=32\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/subj\n",
            "+ ana_setting=icl\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' subj = agnews ']'\n",
            "+ '[' subj = trec ']'\n",
            "+ '[' subj = sst5 ']'\n",
            "+ '[' subj = dbpedia ']'\n",
            "+ '[' subj = cb ']'\n",
            "+ '[' subj = arce ']'\n",
            "+ '[' subj = arcc ']'\n",
            "+ '[' subj = obqa ']'\n",
            "+ '[' subj = hellaswag ']'\n",
            "+ '[' subj = storycloze ']'\n",
            "+ '[' subj = raceh ']'\n",
            "+ '[' subj = racem ']'\n",
            "+ '[' subj = nq ']'\n",
            "+ '[' subj = webqs ']'\n",
            "+ '[' subj = triviaqa ']'\n",
            "+ '[' subj = sq2 ']'\n",
            "+ '[' subj = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ BSZ=2\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_eval --arch gptmodel_large --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --max-epoch 1 --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --max-update 0 --fp16 --eval-data subj --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 4 --reset-dataloader --no-save --k 32 --batch-size 2 --batch-size-valid 2 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/subj --ana-setting icl --permut-index 0\n",
            "+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output//train_log_icl.txt\n",
            "2024-03-01 15:04:51 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-01 15:04:52 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-01 15:04:52 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-01 15:04:53.534345: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-01 15:04:53.534394: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-01 15:04:53.535966: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-01 15:04:54.758244: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-01 15:04:56 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 4, 'eval_data': 'subj', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/subj', 'ana_setting': 'icl', 'optim_group': 'all', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 32, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_large', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2048, 'decoder_output_dim': 2048, 'decoder_input_dim': 2048, 'decoder_ffn_embed_dim': 8192, 'decoder_layers': 24, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt'}, 'criterion': {'_name': 'fs_eval', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 4, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 2, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 2, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': True, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=4, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_eval', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=2, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid='2', max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_large', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.25], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=True, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='subj', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/subj', ana_setting='icl', optim_group='all', tokens_per_sample=2048, max_target_positions=None, k=32, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt', no_seed_provided=False, decoder_layers=24, decoder_embed_dim=2048, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2048, decoder_output_dim=2048, decoder_ffn_embed_dim=8192, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-01 15:04:57 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-01 15:04:59 | WARNING | datasets.builder | Using custom data configuration SetFit--subj-693a635c625bebac\n",
            "2024-03-01 15:04:59 | WARNING | datasets.builder | Reusing dataset json (/root/.cache/huggingface/datasets/SetFit___json/SetFit--subj-693a635c625bebac/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253)\n",
            "100%|██████████| 2/2 [00:00<00:00, 349.38it/s]\n",
            "2024-03-01 15:04:59 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/SetFit___json/SetFit--subj-693a635c625bebac/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-41679576bb6cfc7c.arrow\n",
            "2024-03-01 15:04:59 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/SetFit___json/SetFit--subj-693a635c625bebac/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-6b58bb8b23415efd.arrow\n",
            "2024-03-01 15:05:35 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-01 15:05:36 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2048, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-23): 24 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
            "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2048, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-01 15:05:36 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-01 15:05:36 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-01 15:05:36 | INFO | fairseq_cli.train | criterion: FewshotEvalCriterion\n",
            "2024-03-01 15:05:36 | INFO | fairseq_cli.train | num. shared model params: 1,313,460,224 (num. trained: 2,048)\n",
            "2024-03-01 15:05:36 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-01 15:05:37 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-01 15:05:37 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 15:05:37 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-01 15:05:37 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 15:05:37 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-01 15:05:37 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 2\n",
            "2024-03-01 15:05:37 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt\n",
            "2024-03-01 15:05:37 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last.pt\n",
            "2024-03-01 15:05:37 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-01 15:05:38 | INFO | fairseq_cli.train | Start validating\n",
            "2024-03-01 15:05:38 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "------------ example 0 input str train is ['Input: a spellbinding african film about the modern condition of rootlessness , a state experienced by millions around the globe . Type:', 'Input: a spellbinding african film about the modern condition of rootlessness , a state experienced by millions around the globe . Type:']\n",
            "------------ example 0 label str train is [' objective', ' subjective']\n",
            "------------ example 1 input str train is [\"Input: and if she 's lucky , she may find love along the way . Type:\", \"Input: and if she 's lucky , she may find love along the way . Type:\"]\n",
            "------------ example 1 label str train is [' objective', ' subjective']\n",
            "------------ example 0 input str valid is ['Input: never giving up the fight to win the war , mcnamara is silently planning , waiting for his moment to strike back at the enemy . Type:', 'Input: never giving up the fight to win the war , mcnamara is silently planning , waiting for his moment to strike back at the enemy . Type:']\n",
            "------------ example 0 label str valid is [' objective', ' subjective']\n",
            "------------ example 1 input str valid is ['Input: if the story lacks bite , the performances are never less than affectionate . Type:', 'Input: if the story lacks bite , the performances are never less than affectionate . Type:']\n",
            "------------ example 1 label str valid is [' objective', ' subjective']\n",
            "NOTE: true K of baseline is 32, max valid len is 174\n",
            "| Loaded valid with 4000 samples\n",
            "| Loaded train with 4000 samples\n",
            "2024-03-01 15:09:50 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 0.631 | nll_loss 0 | accuracy 90 | f1 0 | pos_proportion 51.7 | neg_proportion 48.4 | wps 18287.9 | wpb 2299.7 | bsz 1 | num_updates 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash run.sh en_dense_lm_1_3b gptmodel_large agnews 32 3 0 \"{icl_base_dir}/output\" \"{icl_base_dir}\" 0.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MNofzl7cb_G",
        "outputId": "022bc17f-02c4-4810-9218-dff335edaf03",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/agnews/ft/record_info.jsonl': No such file or directory\n",
            "+ SEED=3\n",
            "+ TASK=agnews\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt\n",
            "+ ARCH=gptmodel_large\n",
            "+ K=32\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/agnews\n",
            "+ ana_setting=ft\n",
            "+ lr=0.2\n",
            "+ max_epoch=1\n",
            "+ save_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/agnews/en_dense_lm_1_3b/0.2\n",
            "+ optim_group=attn_kv\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' agnews = agnews ']'\n",
            "+ N_CLASSES=4\n",
            "+ '[' agnews = trec ']'\n",
            "+ '[' agnews = sst5 ']'\n",
            "+ '[' agnews = dbpedia ']'\n",
            "+ '[' agnews = cb ']'\n",
            "+ '[' agnews = arce ']'\n",
            "+ '[' agnews = arcc ']'\n",
            "+ '[' agnews = obqa ']'\n",
            "+ '[' agnews = hellaswag ']'\n",
            "+ '[' agnews = storycloze ']'\n",
            "+ '[' agnews = raceh ']'\n",
            "+ '[' agnews = racem ']'\n",
            "+ '[' agnews = nq ']'\n",
            "+ '[' agnews = webqs ']'\n",
            "+ '[' agnews = triviaqa ']'\n",
            "+ '[' agnews = sq2 ']'\n",
            "+ '[' agnews = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ ORI_BSZ=1\n",
            "+ BSZ=4\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_ft --arch gptmodel_large --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --lr 0.2 --max-epoch 1 --curriculum 1000000 --max-update 1000000 --fp16 --eval-data agnews --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 3 --reset-dataloader --k 32 --batch-size 1 --batch-size-valid 1 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/train_log_ft.txt\n",
            "Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/agnews --ana-setting ft --save-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/agnews/en_dense_lm_1_3b/0.2 --save-interval 1 --save-interval-updates 1000000 --validate-interval 1000000 --disable-validation --optim-group attn_kv --permut-index 0\n",
            "2024-03-02 19:27:59 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-02 19:27:59 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-02 19:28:00.634359: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-02 19:28:00.634424: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-02 19:28:00.636595: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-02 19:28:01.809434: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-02 19:28:03 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 3, 'eval_data': 'agnews', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/agnews', 'ana_setting': 'ft', 'optim_group': 'attn_kv', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 32, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_large', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2048, 'decoder_output_dim': 2048, 'decoder_input_dim': 2048, 'decoder_ffn_embed_dim': 8192, 'decoder_layers': 24, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt'}, 'criterion': {'_name': 'fs_ft', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.2]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 3, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1000000, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': None, 'batch_size_valid': 1, 'max_valid_steps': None, 'curriculum': 1000000, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 1000000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.2], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/agnews/en_dense_lm_1_3b/0.2', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 1000000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=3, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_ft', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=1, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1000000, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=True, max_tokens_valid=None, batch_size_valid='1', max_valid_steps=None, curriculum=1000000, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_large', max_epoch=1, max_update=1000000, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.2], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/agnews/en_dense_lm_1_3b/0.2', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=1000000, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='agnews', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/agnews', ana_setting='ft', optim_group='attn_kv', tokens_per_sample=2048, max_target_positions=None, k=32, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt', no_seed_provided=False, decoder_layers=24, decoder_embed_dim=2048, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2048, decoder_output_dim=2048, decoder_ffn_embed_dim=8192, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-02 19:28:03 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-02 19:28:05 | WARNING | datasets.builder | Using custom data configuration default\n",
            "2024-03-02 19:28:05 | WARNING | datasets.builder | Reusing dataset ag_news (/root/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n",
            "100%|██████████| 2/2 [00:00<00:00, 686.63it/s]\n",
            "2024-03-02 19:28:05 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548/cache-07b028a45ecfcdf7.arrow\n",
            "2024-03-02 19:28:05 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548/cache-f83bc7f828dbfa43.arrow\n",
            "------------ example 0 input str train is ['Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Can Klitschko Establish Himself as the Best against Williams? December 8, 2004. Vitali Klitschko is recognized by Ring Magazine as the Heavyweight Champion of the World. HBO Sports would also like you to believe it. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Can Klitschko Establish Himself as the Best against Williams? December 8, 2004. Vitali Klitschko is recognized by Ring Magazine as the Heavyweight Champion of the World. HBO Sports would also like you to believe it. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Can Klitschko Establish Himself as the Best against Williams? December 8, 2004. Vitali Klitschko is recognized by Ring Magazine as the Heavyweight Champion of the World. HBO Sports would also like you to believe it. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Can Klitschko Establish Himself as the Best against Williams? December 8, 2004. Vitali Klitschko is recognized by Ring Magazine as the Heavyweight Champion of the World. HBO Sports would also like you to believe it. Answer:']\n",
            "------------ example 0 label str train is [' World', ' Sports', ' Business', ' Technology']\n",
            "------------ example 1 input str train is ['Classify the news articles into the categories of World, Sports, Business, and Technology. Article: China to Introduce Anti-Secession Law, Eyes Taiwan  BEIJING (Reuters) - China is to introduce legislation  against secession, state media reported on Friday, a move  analysts have said is aimed at mandating eventual reunification  with rival Taiwan. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: China to Introduce Anti-Secession Law, Eyes Taiwan  BEIJING (Reuters) - China is to introduce legislation  against secession, state media reported on Friday, a move  analysts have said is aimed at mandating eventual reunification  with rival Taiwan. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: China to Introduce Anti-Secession Law, Eyes Taiwan  BEIJING (Reuters) - China is to introduce legislation  against secession, state media reported on Friday, a move  analysts have said is aimed at mandating eventual reunification  with rival Taiwan. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: China to Introduce Anti-Secession Law, Eyes Taiwan  BEIJING (Reuters) - China is to introduce legislation  against secession, state media reported on Friday, a move  analysts have said is aimed at mandating eventual reunification  with rival Taiwan. Answer:']\n",
            "------------ example 1 label str train is [' World', ' Sports', ' Business', ' Technology']\n",
            "------------ example 0 input str valid is ['Classify the news articles into the categories of World, Sports, Business, and Technology. Article: American Express sues credit card rivals American Express is suing Visa and MasterCard plus eight US banks, claiming anti-competitive tactics kept it out of the market. The litigation is the latest setback for Visa and MasterCard, which last month  Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: American Express sues credit card rivals American Express is suing Visa and MasterCard plus eight US banks, claiming anti-competitive tactics kept it out of the market. The litigation is the latest setback for Visa and MasterCard, which last month  Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: American Express sues credit card rivals American Express is suing Visa and MasterCard plus eight US banks, claiming anti-competitive tactics kept it out of the market. The litigation is the latest setback for Visa and MasterCard, which last month  Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: American Express sues credit card rivals American Express is suing Visa and MasterCard plus eight US banks, claiming anti-competitive tactics kept it out of the market. The litigation is the latest setback for Visa and MasterCard, which last month  Answer:']\n",
            "------------ example 0 label str valid is [' World', ' Sports', ' Business', ' Technology']\n",
            "------------ example 1 input str valid is ['Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Producer Price Surge Fuels Inflation Fears Producer prices surged 1.7 percent in October, their sharpest monthly increase in nearly 15 years. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Producer Price Surge Fuels Inflation Fears Producer prices surged 1.7 percent in October, their sharpest monthly increase in nearly 15 years. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Producer Price Surge Fuels Inflation Fears Producer prices surged 1.7 percent in October, their sharpest monthly increase in nearly 15 years. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Producer Price Surge Fuels Inflation Fears Producer prices surged 1.7 percent in October, their sharpest monthly increase in nearly 15 years. Answer:']\n",
            "------------ example 1 label str valid is [' World', ' Sports', ' Business', ' Technology']\n",
            "NOTE: true K of baseline is 22, max valid len is 237\n",
            "------------ example 0 input str train is ['Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Can Klitschko Establish Himself as the Best against Williams? December 8, 2004. Vitali Klitschko is recognized by Ring Magazine as the Heavyweight Champion of the World. HBO Sports would also like you to believe it. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Can Klitschko Establish Himself as the Best against Williams? December 8, 2004. Vitali Klitschko is recognized by Ring Magazine as the Heavyweight Champion of the World. HBO Sports would also like you to believe it. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Can Klitschko Establish Himself as the Best against Williams? December 8, 2004. Vitali Klitschko is recognized by Ring Magazine as the Heavyweight Champion of the World. HBO Sports would also like you to believe it. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Can Klitschko Establish Himself as the Best against Williams? December 8, 2004. Vitali Klitschko is recognized by Ring Magazine as the Heavyweight Champion of the World. HBO Sports would also like you to believe it. Answer:']\n",
            "------------ example 0 label str train is [' World', ' Sports', ' Business', ' Technology']\n",
            "2024-03-02 19:28:45 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-02 19:28:46 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2048, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-23): 24 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
            "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2048, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-02 19:28:46 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-02 19:28:46 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-02 19:28:46 | INFO | fairseq_cli.train | criterion: FewshotFTCriterion\n",
            "2024-03-02 19:28:46 | INFO | fairseq_cli.train | num. shared model params: 1,313,460,224 (num. trained: 1,313,460,224)\n",
            "2024-03-02 19:28:46 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-02 19:28:47 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-02 19:28:47 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-02 19:28:47 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-02 19:28:47 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-02 19:28:47 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-02 19:28:47 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 1\n",
            "2024-03-02 19:28:47 | INFO | fairseq.trainer | Preparing to load checkpoint /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/agnews/en_dense_lm_1_3b/0.2/checkpoint_last.pt\n",
            "2024-03-02 19:28:47 | INFO | fairseq.trainer | No existing checkpoint found /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/agnews/en_dense_lm_1_3b/0.2/checkpoint_last.pt\n",
            "2024-03-02 19:28:47 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-02 19:28:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 32\n",
            "2024-03-02 19:28:48 | INFO | fairseq.trainer | begin training epoch 1\n",
            "2024-03-02 19:28:48 | INFO | fairseq_cli.train | Start fine-tuning\n",
            "------------ example 1 input str train is ['Classify the news articles into the categories of World, Sports, Business, and Technology. Article: China to Introduce Anti-Secession Law, Eyes Taiwan  BEIJING (Reuters) - China is to introduce legislation  against secession, state media reported on Friday, a move  analysts have said is aimed at mandating eventual reunification  with rival Taiwan. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: China to Introduce Anti-Secession Law, Eyes Taiwan  BEIJING (Reuters) - China is to introduce legislation  against secession, state media reported on Friday, a move  analysts have said is aimed at mandating eventual reunification  with rival Taiwan. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: China to Introduce Anti-Secession Law, Eyes Taiwan  BEIJING (Reuters) - China is to introduce legislation  against secession, state media reported on Friday, a move  analysts have said is aimed at mandating eventual reunification  with rival Taiwan. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: China to Introduce Anti-Secession Law, Eyes Taiwan  BEIJING (Reuters) - China is to introduce legislation  against secession, state media reported on Friday, a move  analysts have said is aimed at mandating eventual reunification  with rival Taiwan. Answer:']\n",
            "------------ example 1 label str train is [' World', ' Sports', ' Business', ' Technology']\n",
            "NOTE: true K of baseline is 32\n",
            "| Loaded valid with 8000 samples\n",
            "| Loaded train with 32 samples\n",
            "2024-03-02 19:28:52 | INFO | train_inner | epoch 001:      1 / 32 loss=5.158, sample_size=70, ntokens=71, wps=0, ups=0, wpb=71, bsz=1, num_updates=1, lr=0.2, gnorm=7.921, loss_scale=4, train_wall=4, gb_free=32.8, wall=4\n",
            "2024-03-02 19:28:55 | INFO | train_inner | epoch 001:      2 / 32 loss=9.205, sample_size=77, ntokens=78, wps=26.8, ups=0.34, wpb=78, bsz=1, num_updates=2, lr=0.2, gnorm=16.001, loss_scale=4, train_wall=3, gb_free=32.6, wall=7\n",
            "2024-03-02 19:28:58 | INFO | train_inner | epoch 001:      3 / 32 loss=10.225, sample_size=89, ntokens=90, wps=28.2, ups=0.31, wpb=90, bsz=1, num_updates=3, lr=0.2, gnorm=6.938, loss_scale=4, train_wall=3, gb_free=32.6, wall=10\n",
            "2024-03-02 19:29:04 | INFO | train_inner | epoch 001:      4 / 32 loss=9.09, sample_size=159, ntokens=160, wps=27.8, ups=0.17, wpb=160, bsz=1, num_updates=4, lr=0.2, gnorm=6.989, loss_scale=4, train_wall=6, gb_free=32.6, wall=16\n",
            "2024-03-02 19:29:06 | INFO | train_inner | epoch 001:      5 / 32 loss=7.38, sample_size=72, ntokens=73, wps=27.6, ups=0.38, wpb=73, bsz=1, num_updates=5, lr=0.2, gnorm=10.637, loss_scale=4, train_wall=3, gb_free=32.6, wall=19\n",
            "2024-03-02 19:29:09 | INFO | train_inner | epoch 001:      6 / 32 loss=7.176, sample_size=60, ntokens=61, wps=27.3, ups=0.45, wpb=61, bsz=1, num_updates=6, lr=0.2, gnorm=4.539, loss_scale=4, train_wall=2, gb_free=32.6, wall=21\n",
            "2024-03-02 19:29:12 | INFO | train_inner | epoch 001:      7 / 32 loss=5.779, sample_size=84, ntokens=85, wps=27.7, ups=0.33, wpb=85, bsz=1, num_updates=7, lr=0.2, gnorm=5.236, loss_scale=4, train_wall=3, gb_free=32.6, wall=24\n",
            "2024-03-02 19:29:14 | INFO | train_inner | epoch 001:      8 / 32 loss=5.113, sample_size=50, ntokens=51, wps=26.9, ups=0.53, wpb=51, bsz=1, num_updates=8, lr=0.2, gnorm=4.295, loss_scale=4, train_wall=2, gb_free=32.6, wall=26\n",
            "2024-03-02 19:29:16 | INFO | train_inner | epoch 001:      9 / 32 loss=5.913, sample_size=81, ntokens=82, wps=27.7, ups=0.34, wpb=82, bsz=1, num_updates=9, lr=0.2, gnorm=7.34, loss_scale=4, train_wall=3, gb_free=32.6, wall=29\n",
            "2024-03-02 19:29:19 | INFO | train_inner | epoch 001:     10 / 32 loss=4.895, sample_size=77, ntokens=78, wps=27.6, ups=0.35, wpb=78, bsz=1, num_updates=10, lr=0.2, gnorm=8.527, loss_scale=4, train_wall=3, gb_free=32.6, wall=32\n",
            "2024-03-02 19:29:22 | INFO | train_inner | epoch 001:     11 / 32 loss=6.136, sample_size=75, ntokens=76, wps=27.5, ups=0.36, wpb=76, bsz=1, num_updates=11, lr=0.2, gnorm=5.199, loss_scale=4, train_wall=3, gb_free=32.6, wall=35\n",
            "2024-03-02 19:29:25 | INFO | train_inner | epoch 001:     12 / 32 loss=5.889, sample_size=70, ntokens=71, wps=27.5, ups=0.39, wpb=71, bsz=1, num_updates=12, lr=0.2, gnorm=6.671, loss_scale=4, train_wall=3, gb_free=32.6, wall=37\n",
            "2024-03-02 19:29:28 | INFO | train_inner | epoch 001:     13 / 32 loss=4.543, sample_size=91, ntokens=92, wps=28.3, ups=0.31, wpb=92, bsz=1, num_updates=13, lr=0.2, gnorm=3.29, loss_scale=4, train_wall=3, gb_free=32.6, wall=40\n",
            "2024-03-02 19:29:30 | INFO | train_inner | epoch 001:     14 / 32 loss=5.042, sample_size=60, ntokens=61, wps=27.7, ups=0.45, wpb=61, bsz=1, num_updates=14, lr=0.2, gnorm=4.293, loss_scale=4, train_wall=2, gb_free=32.6, wall=43\n",
            "2024-03-02 19:29:33 | INFO | train_inner | epoch 001:     15 / 32 loss=4.64, sample_size=92, ntokens=93, wps=28, ups=0.3, wpb=93, bsz=1, num_updates=15, lr=0.2, gnorm=4.815, loss_scale=4, train_wall=3, gb_free=32.6, wall=46\n",
            "2024-03-02 19:29:36 | INFO | train_inner | epoch 001:     16 / 32 loss=4.573, sample_size=74, ntokens=75, wps=27.6, ups=0.37, wpb=75, bsz=1, num_updates=16, lr=0.2, gnorm=4.794, loss_scale=4, train_wall=3, gb_free=32.6, wall=49\n",
            "2024-03-02 19:29:39 | INFO | train_inner | epoch 001:     17 / 32 loss=3.607, sample_size=64, ntokens=65, wps=27.7, ups=0.43, wpb=65, bsz=1, num_updates=17, lr=0.2, gnorm=5.771, loss_scale=4, train_wall=2, gb_free=32.6, wall=51\n",
            "2024-03-02 19:29:41 | INFO | train_inner | epoch 001:     18 / 32 loss=4.059, sample_size=76, ntokens=77, wps=27.9, ups=0.36, wpb=77, bsz=1, num_updates=18, lr=0.2, gnorm=4.978, loss_scale=4, train_wall=3, gb_free=32.6, wall=54\n",
            "2024-03-02 19:29:44 | INFO | train_inner | epoch 001:     19 / 32 loss=4.904, sample_size=71, ntokens=72, wps=27.8, ups=0.39, wpb=72, bsz=1, num_updates=19, lr=0.2, gnorm=6.596, loss_scale=4, train_wall=3, gb_free=32.6, wall=56\n",
            "2024-03-02 19:29:47 | INFO | train_inner | epoch 001:     20 / 32 loss=4.278, sample_size=85, ntokens=86, wps=28.1, ups=0.33, wpb=86, bsz=1, num_updates=20, lr=0.2, gnorm=3.72, loss_scale=4, train_wall=3, gb_free=32.6, wall=59\n",
            "2024-03-02 19:29:49 | INFO | train_inner | epoch 001:     21 / 32 loss=3.654, sample_size=66, ntokens=67, wps=27.7, ups=0.41, wpb=67, bsz=1, num_updates=21, lr=0.2, gnorm=5.352, loss_scale=4, train_wall=2, gb_free=32.6, wall=62\n",
            "2024-03-02 19:29:53 | INFO | train_inner | epoch 001:     22 / 32 loss=4.514, sample_size=93, ntokens=94, wps=27.7, ups=0.3, wpb=94, bsz=1, num_updates=22, lr=0.2, gnorm=4.481, loss_scale=4, train_wall=3, gb_free=32.6, wall=65\n",
            "2024-03-02 19:29:56 | INFO | train_inner | epoch 001:     23 / 32 loss=5.066, sample_size=80, ntokens=81, wps=27.8, ups=0.34, wpb=81, bsz=1, num_updates=23, lr=0.2, gnorm=5.278, loss_scale=4, train_wall=3, gb_free=32.6, wall=68\n",
            "2024-03-02 19:29:58 | INFO | train_inner | epoch 001:     24 / 32 loss=4.843, sample_size=64, ntokens=65, wps=27.7, ups=0.43, wpb=65, bsz=1, num_updates=24, lr=0.2, gnorm=6.157, loss_scale=4, train_wall=2, gb_free=32.6, wall=71\n",
            "2024-03-02 19:30:00 | INFO | train_inner | epoch 001:     25 / 32 loss=4.133, sample_size=63, ntokens=64, wps=27.1, ups=0.42, wpb=64, bsz=1, num_updates=25, lr=0.2, gnorm=5.297, loss_scale=4, train_wall=2, gb_free=32.6, wall=73\n",
            "2024-03-02 19:30:04 | INFO | train_inner | epoch 001:     26 / 32 loss=3.41, sample_size=88, ntokens=89, wps=27.9, ups=0.31, wpb=89, bsz=1, num_updates=26, lr=0.2, gnorm=3.383, loss_scale=4, train_wall=3, gb_free=32.6, wall=76\n",
            "2024-03-02 19:30:06 | INFO | train_inner | epoch 001:     27 / 32 loss=3.935, sample_size=71, ntokens=72, wps=27.6, ups=0.38, wpb=72, bsz=1, num_updates=27, lr=0.2, gnorm=4.234, loss_scale=4, train_wall=3, gb_free=32.6, wall=79\n",
            "2024-03-02 19:30:08 | INFO | train_inner | epoch 001:     28 / 32 loss=3.351, sample_size=55, ntokens=56, wps=27.7, ups=0.5, wpb=56, bsz=1, num_updates=28, lr=0.2, gnorm=3.794, loss_scale=4, train_wall=2, gb_free=32.6, wall=81\n",
            "2024-03-02 19:30:11 | INFO | train_inner | epoch 001:     29 / 32 loss=4.057, sample_size=80, ntokens=81, wps=27.9, ups=0.34, wpb=81, bsz=1, num_updates=29, lr=0.2, gnorm=4.373, loss_scale=4, train_wall=3, gb_free=32.6, wall=84\n",
            "2024-03-02 19:30:14 | INFO | train_inner | epoch 001:     30 / 32 loss=4.036, sample_size=66, ntokens=67, wps=27.3, ups=0.41, wpb=67, bsz=1, num_updates=30, lr=0.2, gnorm=4.92, loss_scale=4, train_wall=2, gb_free=32.6, wall=86\n",
            "2024-03-02 19:30:16 | INFO | train_inner | epoch 001:     31 / 32 loss=3.438, sample_size=68, ntokens=69, wps=27.9, ups=0.4, wpb=69, bsz=1, num_updates=31, lr=0.2, gnorm=4.232, loss_scale=4, train_wall=2, gb_free=32.6, wall=89\n",
            "2024-03-02 19:30:18 | INFO | train_inner | epoch 001:     32 / 32 loss=4.607, sample_size=56, ntokens=57, wps=27.5, ups=0.48, wpb=57, bsz=1, num_updates=32, lr=0.2, gnorm=5.722, loss_scale=4, train_wall=2, gb_free=32.6, wall=91\n",
            "2024-03-02 19:30:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 32 updates\n",
            "2024-03-02 19:30:18 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/agnews/en_dense_lm_1_3b/0.2/checkpoint1.pt\n",
            "2024-03-02 19:30:37 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/agnews/en_dense_lm_1_3b/0.2/checkpoint1.pt\n",
            "2024-03-02 19:30:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/agnews/en_dense_lm_1_3b/0.2/checkpoint1.pt (epoch 1 @ 32 updates, score None) (writing took 39.461978245999944 seconds)\n",
            "2024-03-02 19:30:58 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
            "2024-03-02 19:30:58 | INFO | train | epoch 001 | loss 5.386 | sample_size 75.844 | ntokens 76.844 | wps 19 | ups 0.25 | wpb 76.8 | bsz 1 | num_updates 32 | lr 0.2 | gnorm 5.805 | loss_scale 4 | train_wall 90 | gb_free 32.6 | wall 130\n",
            "2024-03-02 19:30:58 | INFO | fairseq_cli.train | done training in 129.8 seconds\n",
            "+ SEED=3\n",
            "+ TASK=agnews\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/agnews/en_dense_lm_1_3b/0.2/checkpoint_last.pt\n",
            "+ ARCH=gptmodel_large\n",
            "+ K=0\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/agnews\n",
            "+ ana_setting=ftzs\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' agnews = agnews ']'\n",
            "+ N_CLASSES=4\n",
            "+ '[' agnews = trec ']'\n",
            "+ '[' agnews = sst5 ']'\n",
            "+ '[' agnews = dbpedia ']'\n",
            "+ '[' agnews = cb ']'\n",
            "+ '[' agnews = arce ']'\n",
            "+ '[' agnews = arcc ']'\n",
            "+ '[' agnews = obqa ']'\n",
            "+ '[' agnews = hellaswag ']'\n",
            "+ '[' agnews = storycloze ']'\n",
            "+ '[' agnews = raceh ']'\n",
            "+ '[' agnews = racem ']'\n",
            "+ '[' agnews = nq ']'\n",
            "+ '[' agnews = webqs ']'\n",
            "+ '[' agnews = triviaqa ']'\n",
            "+ '[' agnews = sq2 ']'\n",
            "+ '[' agnews = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ BSZ=4\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_eval --arch gptmodel_large --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --max-epoch 1 --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --max-update 0 --fp16 --eval-data agnews --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 3 --reset-dataloader --no-save --k 0 --batch-size 4 --batch-size-valid 4 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/agnews/en_dense_lm_1_3b/0.2/checkpoint_last.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/agnews --ana-setting ftzs --permut-index 0\n",
            "+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/train_log_ftzs.txt\n",
            "2024-03-02 19:31:12 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-02 19:31:12 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-02 19:31:13.824607: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-02 19:31:13.824660: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-02 19:31:13.826579: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-02 19:31:15.170032: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-02 19:31:17 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 3, 'eval_data': 'agnews', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/agnews', 'ana_setting': 'ftzs', 'optim_group': 'all', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 0, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_large', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2048, 'decoder_output_dim': 2048, 'decoder_input_dim': 2048, 'decoder_ffn_embed_dim': 8192, 'decoder_layers': 24, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/agnews/en_dense_lm_1_3b/0.2/checkpoint_last.pt'}, 'criterion': {'_name': 'fs_eval', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 3, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 4, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 4, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': True, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=3, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_eval', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=4, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid='4', max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_large', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.25], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=True, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='agnews', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/agnews', ana_setting='ftzs', optim_group='all', tokens_per_sample=2048, max_target_positions=None, k=0, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/agnews/en_dense_lm_1_3b/0.2/checkpoint_last.pt', no_seed_provided=False, decoder_layers=24, decoder_embed_dim=2048, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2048, decoder_output_dim=2048, decoder_ffn_embed_dim=8192, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-02 19:31:17 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-02 19:31:19 | WARNING | datasets.builder | Using custom data configuration default\n",
            "2024-03-02 19:31:19 | WARNING | datasets.builder | Reusing dataset ag_news (/root/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n",
            "100%|██████████| 2/2 [00:00<00:00, 686.80it/s]\n",
            "2024-03-02 19:31:19 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548/cache-07b028a45ecfcdf7.arrow\n",
            "2024-03-02 19:31:19 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548/cache-f83bc7f828dbfa43.arrow\n",
            "2024-03-02 19:32:07 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-02 19:32:09 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2048, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-23): 24 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
            "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2048, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-02 19:32:09 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-02 19:32:09 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-02 19:32:09 | INFO | fairseq_cli.train | criterion: FewshotEvalCriterion\n",
            "2024-03-02 19:32:09 | INFO | fairseq_cli.train | num. shared model params: 1,313,460,224 (num. trained: 2,048)\n",
            "2024-03-02 19:32:09 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-02 19:32:10 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-02 19:32:10 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-02 19:32:10 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-02 19:32:10 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-02 19:32:10 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-02 19:32:10 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 4\n",
            "2024-03-02 19:32:10 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt\n",
            "2024-03-02 19:32:10 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last.pt\n",
            "2024-03-02 19:32:10 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-02 19:32:11 | INFO | fairseq_cli.train | Start validating\n",
            "2024-03-02 19:32:11 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "------------ example 0 input str valid is ['Classify the news articles into the categories of World, Sports, Business, and Technology. Article: American Express sues credit card rivals American Express is suing Visa and MasterCard plus eight US banks, claiming anti-competitive tactics kept it out of the market. The litigation is the latest setback for Visa and MasterCard, which last month  Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: American Express sues credit card rivals American Express is suing Visa and MasterCard plus eight US banks, claiming anti-competitive tactics kept it out of the market. The litigation is the latest setback for Visa and MasterCard, which last month  Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: American Express sues credit card rivals American Express is suing Visa and MasterCard plus eight US banks, claiming anti-competitive tactics kept it out of the market. The litigation is the latest setback for Visa and MasterCard, which last month  Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: American Express sues credit card rivals American Express is suing Visa and MasterCard plus eight US banks, claiming anti-competitive tactics kept it out of the market. The litigation is the latest setback for Visa and MasterCard, which last month  Answer:']\n",
            "------------ example 0 label str valid is [' World', ' Sports', ' Business', ' Technology']\n",
            "------------ example 1 input str valid is ['Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Producer Price Surge Fuels Inflation Fears Producer prices surged 1.7 percent in October, their sharpest monthly increase in nearly 15 years. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Producer Price Surge Fuels Inflation Fears Producer prices surged 1.7 percent in October, their sharpest monthly increase in nearly 15 years. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Producer Price Surge Fuels Inflation Fears Producer prices surged 1.7 percent in October, their sharpest monthly increase in nearly 15 years. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Producer Price Surge Fuels Inflation Fears Producer prices surged 1.7 percent in October, their sharpest monthly increase in nearly 15 years. Answer:']\n",
            "------------ example 1 label str valid is [' World', ' Sports', ' Business', ' Technology']\n",
            "NOTE: true K of baseline is 0, max valid len is 237\n",
            "| Loaded valid with 8000 samples\n",
            "| Loaded train with 8000 samples\n",
            "2024-03-02 19:36:40 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.604 | nll_loss 0.019 | accuracy 61.8 | f1 0 | pos_proportion 25.3 | neg_proportion 23.5 | wps 2238.3 | wpb 300 | bsz 1 | num_updates 0\n",
            "+ SEED=3\n",
            "+ TASK=agnews\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt\n",
            "+ ARCH=gptmodel_large\n",
            "+ K=0\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/agnews\n",
            "+ ana_setting=zs\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' agnews = agnews ']'\n",
            "+ N_CLASSES=4\n",
            "+ '[' agnews = trec ']'\n",
            "+ '[' agnews = sst5 ']'\n",
            "+ '[' agnews = dbpedia ']'\n",
            "+ '[' agnews = cb ']'\n",
            "+ '[' agnews = arce ']'\n",
            "+ '[' agnews = arcc ']'\n",
            "+ '[' agnews = obqa ']'\n",
            "+ '[' agnews = hellaswag ']'\n",
            "+ '[' agnews = storycloze ']'\n",
            "+ '[' agnews = raceh ']'\n",
            "+ '[' agnews = racem ']'\n",
            "+ '[' agnews = nq ']'\n",
            "+ '[' agnews = webqs ']'\n",
            "+ '[' agnews = triviaqa ']'\n",
            "+ '[' agnews = sq2 ']'\n",
            "+ '[' agnews = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ BSZ=4\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_eval --arch gptmodel_large --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --max-epoch 1 --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --max-update 0 --fp16 --eval-data agnews --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 3 --reset-dataloader --no-save --k 0 --batch-size 4 --batch-size-valid 4 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/agnews --ana-setting zs --permut-index 0\n",
            "+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/train_log_zs.txt\n",
            "2024-03-02 19:37:02 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-02 19:37:02 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-02 19:37:03.442102: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-02 19:37:03.442149: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-02 19:37:03.444252: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-02 19:37:04.710152: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-02 19:37:07 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 3, 'eval_data': 'agnews', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/agnews', 'ana_setting': 'zs', 'optim_group': 'all', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 0, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_large', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2048, 'decoder_output_dim': 2048, 'decoder_input_dim': 2048, 'decoder_ffn_embed_dim': 8192, 'decoder_layers': 24, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt'}, 'criterion': {'_name': 'fs_eval', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 3, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 4, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 4, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': True, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=3, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_eval', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=4, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid='4', max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_large', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.25], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=True, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='agnews', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/agnews', ana_setting='zs', optim_group='all', tokens_per_sample=2048, max_target_positions=None, k=0, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt', no_seed_provided=False, decoder_layers=24, decoder_embed_dim=2048, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2048, decoder_output_dim=2048, decoder_ffn_embed_dim=8192, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-02 19:37:07 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-02 19:37:09 | WARNING | datasets.builder | Using custom data configuration default\n",
            "2024-03-02 19:37:09 | WARNING | datasets.builder | Reusing dataset ag_news (/root/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n",
            "100%|██████████| 2/2 [00:00<00:00, 612.04it/s]\n",
            "2024-03-02 19:37:09 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548/cache-07b028a45ecfcdf7.arrow\n",
            "2024-03-02 19:37:09 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548/cache-f83bc7f828dbfa43.arrow\n",
            "2024-03-02 19:37:49 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-02 19:37:51 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2048, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-23): 24 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
            "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2048, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-02 19:37:51 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-02 19:37:51 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-02 19:37:51 | INFO | fairseq_cli.train | criterion: FewshotEvalCriterion\n",
            "2024-03-02 19:37:51 | INFO | fairseq_cli.train | num. shared model params: 1,313,460,224 (num. trained: 2,048)\n",
            "2024-03-02 19:37:51 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-02 19:37:52 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-02 19:37:52 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-02 19:37:52 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-02 19:37:52 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-02 19:37:52 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-02 19:37:52 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 4\n",
            "2024-03-02 19:37:52 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt\n",
            "2024-03-02 19:37:52 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last.pt\n",
            "2024-03-02 19:37:52 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-02 19:37:53 | INFO | fairseq_cli.train | Start validating\n",
            "2024-03-02 19:37:53 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "------------ example 0 input str valid is ['Classify the news articles into the categories of World, Sports, Business, and Technology. Article: American Express sues credit card rivals American Express is suing Visa and MasterCard plus eight US banks, claiming anti-competitive tactics kept it out of the market. The litigation is the latest setback for Visa and MasterCard, which last month  Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: American Express sues credit card rivals American Express is suing Visa and MasterCard plus eight US banks, claiming anti-competitive tactics kept it out of the market. The litigation is the latest setback for Visa and MasterCard, which last month  Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: American Express sues credit card rivals American Express is suing Visa and MasterCard plus eight US banks, claiming anti-competitive tactics kept it out of the market. The litigation is the latest setback for Visa and MasterCard, which last month  Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: American Express sues credit card rivals American Express is suing Visa and MasterCard plus eight US banks, claiming anti-competitive tactics kept it out of the market. The litigation is the latest setback for Visa and MasterCard, which last month  Answer:']\n",
            "------------ example 0 label str valid is [' World', ' Sports', ' Business', ' Technology']\n",
            "------------ example 1 input str valid is ['Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Producer Price Surge Fuels Inflation Fears Producer prices surged 1.7 percent in October, their sharpest monthly increase in nearly 15 years. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Producer Price Surge Fuels Inflation Fears Producer prices surged 1.7 percent in October, their sharpest monthly increase in nearly 15 years. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Producer Price Surge Fuels Inflation Fears Producer prices surged 1.7 percent in October, their sharpest monthly increase in nearly 15 years. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Producer Price Surge Fuels Inflation Fears Producer prices surged 1.7 percent in October, their sharpest monthly increase in nearly 15 years. Answer:']\n",
            "------------ example 1 label str valid is [' World', ' Sports', ' Business', ' Technology']\n",
            "NOTE: true K of baseline is 0, max valid len is 237\n",
            "| Loaded valid with 8000 samples\n",
            "| Loaded train with 8000 samples\n",
            "2024-03-02 19:41:12 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 9.062 | nll_loss 0.03 | accuracy 46.2 | f1 0 | pos_proportion 25.3 | neg_proportion 23.5 | wps 3027.3 | wpb 300 | bsz 1 | num_updates 0\n",
            "+ SEED=3\n",
            "+ TASK=agnews\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt\n",
            "+ ARCH=gptmodel_large\n",
            "+ K=32\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/agnews\n",
            "+ ana_setting=icl\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' agnews = agnews ']'\n",
            "+ N_CLASSES=4\n",
            "+ '[' agnews = trec ']'\n",
            "+ '[' agnews = sst5 ']'\n",
            "+ '[' agnews = dbpedia ']'\n",
            "+ '[' agnews = cb ']'\n",
            "+ '[' agnews = arce ']'\n",
            "+ '[' agnews = arcc ']'\n",
            "+ '[' agnews = obqa ']'\n",
            "+ '[' agnews = hellaswag ']'\n",
            "+ '[' agnews = storycloze ']'\n",
            "+ '[' agnews = raceh ']'\n",
            "+ '[' agnews = racem ']'\n",
            "+ '[' agnews = nq ']'\n",
            "+ '[' agnews = webqs ']'\n",
            "+ '[' agnews = triviaqa ']'\n",
            "+ '[' agnews = sq2 ']'\n",
            "+ '[' agnews = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ BSZ=4\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_eval --arch gptmodel_large --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --max-epoch 1 --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --max-update 0 --fp16 --eval-data agnews --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 3 --reset-dataloader --no-save --k 32 --batch-size 4 --batch-size-valid 4 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/agnews --ana-setting icl --permut-index 0\n",
            "+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/train_log_icl.txt\n",
            "2024-03-02 19:41:33 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-02 19:41:33 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-02 19:41:34.577270: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-02 19:41:34.577313: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-02 19:41:34.579246: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-02 19:41:35.861901: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-02 19:41:38 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 3, 'eval_data': 'agnews', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/agnews', 'ana_setting': 'icl', 'optim_group': 'all', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 32, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_large', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2048, 'decoder_output_dim': 2048, 'decoder_input_dim': 2048, 'decoder_ffn_embed_dim': 8192, 'decoder_layers': 24, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt'}, 'criterion': {'_name': 'fs_eval', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 3, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 4, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 4, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': True, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=3, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_eval', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=4, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid='4', max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_large', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.25], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=True, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='agnews', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/agnews', ana_setting='icl', optim_group='all', tokens_per_sample=2048, max_target_positions=None, k=32, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt', no_seed_provided=False, decoder_layers=24, decoder_embed_dim=2048, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2048, decoder_output_dim=2048, decoder_ffn_embed_dim=8192, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-02 19:41:38 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-02 19:41:39 | WARNING | datasets.builder | Using custom data configuration default\n",
            "2024-03-02 19:41:39 | WARNING | datasets.builder | Reusing dataset ag_news (/root/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n",
            "100%|██████████| 2/2 [00:00<00:00, 339.67it/s]\n",
            "2024-03-02 19:41:39 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548/cache-07b028a45ecfcdf7.arrow\n",
            "2024-03-02 19:41:39 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548/cache-f83bc7f828dbfa43.arrow\n",
            "2024-03-02 19:42:20 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-02 19:42:21 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2048, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-23): 24 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
            "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2048, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-02 19:42:21 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-02 19:42:21 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-02 19:42:21 | INFO | fairseq_cli.train | criterion: FewshotEvalCriterion\n",
            "2024-03-02 19:42:21 | INFO | fairseq_cli.train | num. shared model params: 1,313,460,224 (num. trained: 2,048)\n",
            "2024-03-02 19:42:21 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-02 19:42:22 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-02 19:42:22 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-02 19:42:22 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-02 19:42:22 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-02 19:42:22 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-02 19:42:22 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 4\n",
            "2024-03-02 19:42:22 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt\n",
            "2024-03-02 19:42:22 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last.pt\n",
            "2024-03-02 19:42:22 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-02 19:42:22 | INFO | fairseq_cli.train | Start validating\n",
            "2024-03-02 19:42:22 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "------------ example 0 input str train is ['Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Can Klitschko Establish Himself as the Best against Williams? December 8, 2004. Vitali Klitschko is recognized by Ring Magazine as the Heavyweight Champion of the World. HBO Sports would also like you to believe it. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Can Klitschko Establish Himself as the Best against Williams? December 8, 2004. Vitali Klitschko is recognized by Ring Magazine as the Heavyweight Champion of the World. HBO Sports would also like you to believe it. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Can Klitschko Establish Himself as the Best against Williams? December 8, 2004. Vitali Klitschko is recognized by Ring Magazine as the Heavyweight Champion of the World. HBO Sports would also like you to believe it. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Can Klitschko Establish Himself as the Best against Williams? December 8, 2004. Vitali Klitschko is recognized by Ring Magazine as the Heavyweight Champion of the World. HBO Sports would also like you to believe it. Answer:']\n",
            "------------ example 0 label str train is [' World', ' Sports', ' Business', ' Technology']\n",
            "------------ example 1 input str train is ['Classify the news articles into the categories of World, Sports, Business, and Technology. Article: China to Introduce Anti-Secession Law, Eyes Taiwan  BEIJING (Reuters) - China is to introduce legislation  against secession, state media reported on Friday, a move  analysts have said is aimed at mandating eventual reunification  with rival Taiwan. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: China to Introduce Anti-Secession Law, Eyes Taiwan  BEIJING (Reuters) - China is to introduce legislation  against secession, state media reported on Friday, a move  analysts have said is aimed at mandating eventual reunification  with rival Taiwan. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: China to Introduce Anti-Secession Law, Eyes Taiwan  BEIJING (Reuters) - China is to introduce legislation  against secession, state media reported on Friday, a move  analysts have said is aimed at mandating eventual reunification  with rival Taiwan. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: China to Introduce Anti-Secession Law, Eyes Taiwan  BEIJING (Reuters) - China is to introduce legislation  against secession, state media reported on Friday, a move  analysts have said is aimed at mandating eventual reunification  with rival Taiwan. Answer:']\n",
            "------------ example 1 label str train is [' World', ' Sports', ' Business', ' Technology']\n",
            "------------ example 0 input str valid is ['Classify the news articles into the categories of World, Sports, Business, and Technology. Article: American Express sues credit card rivals American Express is suing Visa and MasterCard plus eight US banks, claiming anti-competitive tactics kept it out of the market. The litigation is the latest setback for Visa and MasterCard, which last month  Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: American Express sues credit card rivals American Express is suing Visa and MasterCard plus eight US banks, claiming anti-competitive tactics kept it out of the market. The litigation is the latest setback for Visa and MasterCard, which last month  Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: American Express sues credit card rivals American Express is suing Visa and MasterCard plus eight US banks, claiming anti-competitive tactics kept it out of the market. The litigation is the latest setback for Visa and MasterCard, which last month  Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: American Express sues credit card rivals American Express is suing Visa and MasterCard plus eight US banks, claiming anti-competitive tactics kept it out of the market. The litigation is the latest setback for Visa and MasterCard, which last month  Answer:']\n",
            "------------ example 0 label str valid is [' World', ' Sports', ' Business', ' Technology']\n",
            "------------ example 1 input str valid is ['Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Producer Price Surge Fuels Inflation Fears Producer prices surged 1.7 percent in October, their sharpest monthly increase in nearly 15 years. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Producer Price Surge Fuels Inflation Fears Producer prices surged 1.7 percent in October, their sharpest monthly increase in nearly 15 years. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Producer Price Surge Fuels Inflation Fears Producer prices surged 1.7 percent in October, their sharpest monthly increase in nearly 15 years. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Producer Price Surge Fuels Inflation Fears Producer prices surged 1.7 percent in October, their sharpest monthly increase in nearly 15 years. Answer:']\n",
            "------------ example 1 label str valid is [' World', ' Sports', ' Business', ' Technology']\n",
            "NOTE: true K of baseline is 22, max valid len is 237\n",
            "| Loaded valid with 8000 samples\n",
            "| Loaded train with 8000 samples\n",
            "2024-03-02 19:49:10 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 1.479 | nll_loss 0 | accuracy 79.4 | f1 0 | pos_proportion 25.3 | neg_proportion 23.5 | wps 36033 | wpb 7332 | bsz 1 | num_updates 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python icl_ft/compute_sim.py agnews all 1_3b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-vjvaa7siIR",
        "outputId": "046b4bbd-e81f-4035-892f-9358275f89ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/agnews/ftzs 2000\n",
            "loading ftzs data costs 79.45283484458923 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/agnews/zs 2000\n",
            "loading zs data costs 55.786540031433105 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/agnews/icl 2000\n",
            "loading icl data costs 72.61046838760376 seconds\n",
            "================= number of both F2T examples: 615\n",
            "================= number of ICL F2T examples: 783\n",
            "================= number of FTZS F2T examples: 787\n",
            "++++++++++++++++ ICL recall to FT: 78.14\n",
            "count_f2t costs 0.004275321960449219 seconds\n",
            "============================== analyzing self_attn_out_hiddens ==============================\n",
            "per-layer updates sim (icl-zs)&(ftzs-zs):\n",
            " [0.0876 0.279  0.2855 0.2968 0.6705 0.2532 0.4551 0.2578 0.2592 0.3619\n",
            " 0.3391 0.3143 0.377  0.408  0.4486 0.3054 0.2978 0.2554 0.2984 0.2587\n",
            " 0.2242 0.0952 0.1002 0.5359]\n",
            "overall updates sim (icl-zs)&(ftzs-zs):\n",
            " 0.311\n",
            "\n",
            "per-layer updates sim (icl-zs)&(random):\n",
            " [-0.0042  0.0047  0.0193  0.0197  0.0148  0.0062  0.0069 -0.0005  0.0004\n",
            " -0.0031  0.0058  0.0023  0.0002  0.0022 -0.003  -0.0025 -0.0012 -0.0052\n",
            " -0.0044 -0.0046 -0.0001  0.006  -0.0057 -0.0062]\n",
            "overall updates sim (icl-zs)&(random):\n",
            " 0.002\n",
            "\n",
            "analyze_sim costs 24.366225004196167 seconds\n",
            "============================== analyzing attn_map, softmax=False ==============================\n",
            "per-layer direct sim (icl)&(zs):\n",
            " [-0.2952  0.2459  0.0676 -0.3539  0.0443  0.2206  0.4865  0.2424  0.2267\n",
            "  0.0823  0.1025 -0.1693 -0.195  -0.1889 -0.3543  0.1721 -0.2649 -0.2501\n",
            "  0.0293  0.5589  0.8034  0.8299  0.9048  0.6947]\n",
            "overall direct sim (icl)&(zs):\n",
            " 0.1517\n",
            "\n",
            "per-layer direct sim (icl)&(ftzs):\n",
            " [-0.2945  0.1722  0.0606 -0.2746  0.108   0.398   0.609   0.6046  0.4597\n",
            "  0.5186  0.6411  0.2562  0.5224  0.466   0.4711  0.6861  0.6237  0.6792\n",
            "  0.6291  0.6214  0.7341  0.8582  0.8567  0.7695]\n",
            "overall direct sim (icl)&(ftzs):\n",
            " 0.4657\n",
            "\n",
            "analyze_attn_map (w/o softmax) costs 311.40647745132446 seconds\n",
            "saving data costs 1.1200592517852783 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash run.sh en_dense_lm_1_3b gptmodel_large cb 32 3 0 \"{icl_base_dir}/output\" \"{icl_base_dir}\" 0.08"
      ],
      "metadata": {
        "id": "SDXmdK4zIjSN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4e03fd6-f962-4824-92b4-865d2c145c62",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+ SEED=3\n",
            "+ TASK=cb\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt\n",
            "+ ARCH=gptmodel_large\n",
            "+ K=32\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/cb\n",
            "+ ana_setting=ft\n",
            "+ lr=0.08\n",
            "+ max_epoch=1\n",
            "+ save_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/cb/en_dense_lm_1_3b/0.08\n",
            "+ optim_group=attn_kv\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' cb = agnews ']'\n",
            "+ '[' cb = trec ']'\n",
            "+ '[' cb = sst5 ']'\n",
            "+ '[' cb = dbpedia ']'\n",
            "+ '[' cb = cb ']'\n",
            "+ N_CLASSES=3\n",
            "+ '[' cb = arce ']'\n",
            "+ '[' cb = arcc ']'\n",
            "+ '[' cb = obqa ']'\n",
            "+ '[' cb = hellaswag ']'\n",
            "+ '[' cb = storycloze ']'\n",
            "+ '[' cb = raceh ']'\n",
            "+ '[' cb = racem ']'\n",
            "+ '[' cb = nq ']'\n",
            "+ '[' cb = webqs ']'\n",
            "+ '[' cb = triviaqa ']'\n",
            "+ '[' cb = sq2 ']'\n",
            "+ '[' cb = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ ORI_BSZ=1\n",
            "+ BSZ=3\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_ft --arch gptmodel_large --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --lr 0.08 --max-epoch 1 --curriculum 1000000 --max-update 1000000 --fp16 --eval-data cb --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 3 --reset-dataloader --k 32 --batch-size 1 --batch-size-valid 1 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/cb --ana-setting ft --save-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/cb/en_dense_lm_1_3b/0.08 --save-interval 1 --save-interval-updates 1000000 --validate-interval 1000000 --disable-validation --optim-group attn_kv --permut-index 0\n",
            "+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/train_log_ft.txt\n",
            "2024-03-02 13:19:56 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-02 13:21:06 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-02 13:21:06 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-02 13:21:20.168289: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-02 13:21:20.168341: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-02 13:21:20.170010: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-02 13:21:21.361596: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-02 13:21:35 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 3, 'eval_data': 'cb', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/cb', 'ana_setting': 'ft', 'optim_group': 'attn_kv', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 32, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_large', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2048, 'decoder_output_dim': 2048, 'decoder_input_dim': 2048, 'decoder_ffn_embed_dim': 8192, 'decoder_layers': 24, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt'}, 'criterion': {'_name': 'fs_ft', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.08]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 3, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1000000, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': None, 'batch_size_valid': 1, 'max_valid_steps': None, 'curriculum': 1000000, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 1000000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.08], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/cb/en_dense_lm_1_3b/0.08', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 1000000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=3, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_ft', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=1, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1000000, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=True, max_tokens_valid=None, batch_size_valid='1', max_valid_steps=None, curriculum=1000000, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_large', max_epoch=1, max_update=1000000, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.08], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/cb/en_dense_lm_1_3b/0.08', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=1000000, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='cb', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/cb', ana_setting='ft', optim_group='attn_kv', tokens_per_sample=2048, max_target_positions=None, k=32, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt', no_seed_provided=False, decoder_layers=24, decoder_embed_dim=2048, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2048, decoder_output_dim=2048, decoder_ffn_embed_dim=8192, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-02 13:21:36 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "Downloading builder script: 29.9kB [00:00, 28.6MB/s]                   \n",
            "Downloading metadata: 38.2kB [00:00, 36.8MB/s]                   \n",
            "Downloading and preparing dataset super_glue/cb (download: 73.71 KiB, generated: 198.02 KiB, post-processed: Unknown size, total: 271.73 KiB) to /root/.cache/huggingface/datasets/super_glue/cb/1.0.2/d040c658e2ddef6934fdd97deb45c777b6ff50c524781ea434e7219b56a428a7...\n",
            "Downloading data: 100%|██████████| 75.5k/75.5k [00:00<00:00, 35.7MB/s]\n",
            "Dataset super_glue downloaded and prepared to /root/.cache/huggingface/datasets/super_glue/cb/1.0.2/d040c658e2ddef6934fdd97deb45c777b6ff50c524781ea434e7219b56a428a7. Subsequent calls will reuse this data.\n",
            "100%|██████████| 3/3 [00:00<00:00, 674.83it/s]\n",
            "2024-03-02 13:23:15 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-02 13:23:19 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2048, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-23): 24 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
            "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2048, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-02 13:23:19 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-02 13:23:19 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-02 13:23:19 | INFO | fairseq_cli.train | criterion: FewshotFTCriterion\n",
            "2024-03-02 13:23:19 | INFO | fairseq_cli.train | num. shared model params: 1,313,460,224 (num. trained: 1,313,460,224)\n",
            "2024-03-02 13:23:19 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-02 13:23:21 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-02 13:23:21 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-02 13:23:21 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-02 13:23:21 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-02 13:23:21 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-02 13:23:21 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 1\n",
            "2024-03-02 13:23:21 | INFO | fairseq.trainer | Preparing to load checkpoint /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/cb/en_dense_lm_1_3b/0.08/checkpoint_last.pt\n",
            "2024-03-02 13:23:21 | INFO | fairseq.trainer | No existing checkpoint found /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/cb/en_dense_lm_1_3b/0.08/checkpoint_last.pt\n",
            "2024-03-02 13:23:21 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-02 13:23:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 32\n",
            "2024-03-02 13:23:21 | INFO | fairseq.trainer | begin training epoch 1\n",
            "2024-03-02 13:23:21 | INFO | fairseq_cli.train | Start fine-tuning\n",
            "------------ example 0 input str train is [\"For a while the notion gripped him, and he prowled the many floors of Hamleys looking for toys. He bought a magic set for Sebastian (although his ideal present for the kid would have been a brand-new name) and a marionette for Louise. He could remember that there was an age for puppets and magic just as he could remember the time that he 'd spent trying to fan a deck of cards or sitting in front of a mirror trying to get the hard consonants down like a real ventriloquist. Question: there was an age for puppets and magic. True, False, or Neither? Answer:\", \"For a while the notion gripped him, and he prowled the many floors of Hamleys looking for toys. He bought a magic set for Sebastian (although his ideal present for the kid would have been a brand-new name) and a marionette for Louise. He could remember that there was an age for puppets and magic just as he could remember the time that he 'd spent trying to fan a deck of cards or sitting in front of a mirror trying to get the hard consonants down like a real ventriloquist. Question: there was an age for puppets and magic. True, False, or Neither? Answer:\", \"For a while the notion gripped him, and he prowled the many floors of Hamleys looking for toys. He bought a magic set for Sebastian (although his ideal present for the kid would have been a brand-new name) and a marionette for Louise. He could remember that there was an age for puppets and magic just as he could remember the time that he 'd spent trying to fan a deck of cards or sitting in front of a mirror trying to get the hard consonants down like a real ventriloquist. Question: there was an age for puppets and magic. True, False, or Neither? Answer:\"]\n",
            "------------ example 0 label str train is [' True', ' False', ' Neither']\n",
            "------------ example 1 input str train is [\"``For God's sake keep them in their seats. If we get panic people are going to be crushed to death and there will be mayhem in the car park.'' The announcer could only guess from the urgency in the Chief Constable's voice that the situation was very very serious. Question: the situation was very very serious. True, False, or Neither? Answer:\", \"``For God's sake keep them in their seats. If we get panic people are going to be crushed to death and there will be mayhem in the car park.'' The announcer could only guess from the urgency in the Chief Constable's voice that the situation was very very serious. Question: the situation was very very serious. True, False, or Neither? Answer:\", \"``For God's sake keep them in their seats. If we get panic people are going to be crushed to death and there will be mayhem in the car park.'' The announcer could only guess from the urgency in the Chief Constable's voice that the situation was very very serious. Question: the situation was very very serious. True, False, or Neither? Answer:\"]\n",
            "------------ example 1 label str train is [' True', ' False', ' Neither']\n",
            "------------ example 0 input str valid is [\"A: Well, actually, uh, A: I don't think I'm in the, uh, majority in Texas Question: she is in the majority in Texas. True, False, or Neither? Answer:\", \"A: Well, actually, uh, A: I don't think I'm in the, uh, majority in Texas Question: she is in the majority in Texas. True, False, or Neither? Answer:\", \"A: Well, actually, uh, A: I don't think I'm in the, uh, majority in Texas Question: she is in the majority in Texas. True, False, or Neither? Answer:\"]\n",
            "------------ example 0 label str valid is [' True', ' False', ' Neither']\n",
            "------------ example 1 input str valid is [\"A: and that rolling kind of, uh, B: Terrain. A: Yeah. is fairly famili-,. The thing that I thought was interesting was that the critics, apparently it's going to win everything. B: Really? A: Uh, and I had been told, you know, you wouldn't notice that it was three hours long, and all this, kind of, Question: it was three hours long. True, False, or Neither? Answer:\", \"A: and that rolling kind of, uh, B: Terrain. A: Yeah. is fairly famili-,. The thing that I thought was interesting was that the critics, apparently it's going to win everything. B: Really? A: Uh, and I had been told, you know, you wouldn't notice that it was three hours long, and all this, kind of, Question: it was three hours long. True, False, or Neither? Answer:\", \"A: and that rolling kind of, uh, B: Terrain. A: Yeah. is fairly famili-,. The thing that I thought was interesting was that the critics, apparently it's going to win everything. B: Really? A: Uh, and I had been told, you know, you wouldn't notice that it was three hours long, and all this, kind of, Question: it was three hours long. True, False, or Neither? Answer:\"]\n",
            "------------ example 1 label str valid is [' True', ' False', ' Neither']\n",
            "NOTE: true K of baseline is 19, max valid len is 280\n",
            "------------ example 0 input str train is [\"For a while the notion gripped him, and he prowled the many floors of Hamleys looking for toys. He bought a magic set for Sebastian (although his ideal present for the kid would have been a brand-new name) and a marionette for Louise. He could remember that there was an age for puppets and magic just as he could remember the time that he 'd spent trying to fan a deck of cards or sitting in front of a mirror trying to get the hard consonants down like a real ventriloquist. Question: there was an age for puppets and magic. True, False, or Neither? Answer:\", \"For a while the notion gripped him, and he prowled the many floors of Hamleys looking for toys. He bought a magic set for Sebastian (although his ideal present for the kid would have been a brand-new name) and a marionette for Louise. He could remember that there was an age for puppets and magic just as he could remember the time that he 'd spent trying to fan a deck of cards or sitting in front of a mirror trying to get the hard consonants down like a real ventriloquist. Question: there was an age for puppets and magic. True, False, or Neither? Answer:\", \"For a while the notion gripped him, and he prowled the many floors of Hamleys looking for toys. He bought a magic set for Sebastian (although his ideal present for the kid would have been a brand-new name) and a marionette for Louise. He could remember that there was an age for puppets and magic just as he could remember the time that he 'd spent trying to fan a deck of cards or sitting in front of a mirror trying to get the hard consonants down like a real ventriloquist. Question: there was an age for puppets and magic. True, False, or Neither? Answer:\"]\n",
            "------------ example 0 label str train is [' True', ' False', ' Neither']\n",
            "------------ example 1 input str train is [\"``For God's sake keep them in their seats. If we get panic people are going to be crushed to death and there will be mayhem in the car park.'' The announcer could only guess from the urgency in the Chief Constable's voice that the situation was very very serious. Question: the situation was very very serious. True, False, or Neither? Answer:\", \"``For God's sake keep them in their seats. If we get panic people are going to be crushed to death and there will be mayhem in the car park.'' The announcer could only guess from the urgency in the Chief Constable's voice that the situation was very very serious. Question: the situation was very very serious. True, False, or Neither? Answer:\", \"``For God's sake keep them in their seats. If we get panic people are going to be crushed to death and there will be mayhem in the car park.'' The announcer could only guess from the urgency in the Chief Constable's voice that the situation was very very serious. Question: the situation was very very serious. True, False, or Neither? Answer:\"]\n",
            "------------ example 1 label str train is [' True', ' False', ' Neither']\n",
            "NOTE: true K of baseline is 32\n",
            "| Loaded valid with 168 samples\n",
            "| Loaded train with 32 samples\n",
            "2024-03-02 13:23:29 | INFO | train_inner | epoch 001:      1 / 32 loss=5.002, sample_size=131, ntokens=132, wps=0, ups=0, wpb=132, bsz=1, num_updates=1, lr=0.08, gnorm=4.895, loss_scale=4, train_wall=8, gb_free=32.8, wall=8\n",
            "2024-03-02 13:23:32 | INFO | train_inner | epoch 001:      2 / 32 loss=5.184, sample_size=74, ntokens=75, wps=26.2, ups=0.35, wpb=75, bsz=1, num_updates=2, lr=0.08, gnorm=7.638, loss_scale=4, train_wall=3, gb_free=32.6, wall=11\n",
            "2024-03-02 13:23:36 | INFO | train_inner | epoch 001:      3 / 32 loss=4.386, sample_size=101, ntokens=102, wps=27.5, ups=0.27, wpb=102, bsz=1, num_updates=3, lr=0.08, gnorm=6.494, loss_scale=4, train_wall=4, gb_free=32.6, wall=15\n",
            "2024-03-02 13:23:39 | INFO | train_inner | epoch 001:      4 / 32 loss=4.136, sample_size=88, ntokens=89, wps=27.3, ups=0.31, wpb=89, bsz=1, num_updates=4, lr=0.08, gnorm=3.857, loss_scale=4, train_wall=3, gb_free=32.6, wall=18\n",
            "2024-03-02 13:23:41 | INFO | train_inner | epoch 001:      5 / 32 loss=4.128, sample_size=56, ntokens=57, wps=26.8, ups=0.47, wpb=57, bsz=1, num_updates=5, lr=0.08, gnorm=5.238, loss_scale=4, train_wall=2, gb_free=32.6, wall=20\n",
            "2024-03-02 13:23:43 | INFO | train_inner | epoch 001:      6 / 32 loss=3.475, sample_size=54, ntokens=55, wps=27.3, ups=0.5, wpb=55, bsz=1, num_updates=6, lr=0.08, gnorm=6.318, loss_scale=4, train_wall=2, gb_free=32.6, wall=22\n",
            "2024-03-02 13:23:49 | INFO | train_inner | epoch 001:      7 / 32 loss=4.85, sample_size=163, ntokens=164, wps=27.8, ups=0.17, wpb=164, bsz=1, num_updates=7, lr=0.08, gnorm=4.74, loss_scale=4, train_wall=6, gb_free=32.6, wall=28\n",
            "2024-03-02 13:23:51 | INFO | train_inner | epoch 001:      8 / 32 loss=3.304, sample_size=64, ntokens=65, wps=27.1, ups=0.42, wpb=65, bsz=1, num_updates=8, lr=0.08, gnorm=4.399, loss_scale=4, train_wall=2, gb_free=32.6, wall=30\n",
            "2024-03-02 13:23:58 | INFO | train_inner | epoch 001:      9 / 32 loss=4.492, sample_size=185, ntokens=186, wps=28.3, ups=0.15, wpb=186, bsz=1, num_updates=9, lr=0.08, gnorm=3.596, loss_scale=4, train_wall=7, gb_free=32.6, wall=37\n",
            "2024-03-02 13:24:03 | INFO | train_inner | epoch 001:     10 / 32 loss=3.757, sample_size=129, ntokens=130, wps=28.2, ups=0.22, wpb=130, bsz=1, num_updates=10, lr=0.08, gnorm=3.021, loss_scale=4, train_wall=5, gb_free=32.6, wall=42\n",
            "2024-03-02 13:24:06 | INFO | train_inner | epoch 001:     11 / 32 loss=2.662, sample_size=82, ntokens=83, wps=27.4, ups=0.33, wpb=83, bsz=1, num_updates=11, lr=0.08, gnorm=3.352, loss_scale=4, train_wall=3, gb_free=32.6, wall=45\n",
            "2024-03-02 13:24:09 | INFO | train_inner | epoch 001:     12 / 32 loss=4.468, sample_size=78, ntokens=79, wps=27.4, ups=0.35, wpb=79, bsz=1, num_updates=12, lr=0.08, gnorm=5.527, loss_scale=4, train_wall=3, gb_free=32.6, wall=48\n",
            "2024-03-02 13:24:13 | INFO | train_inner | epoch 001:     13 / 32 loss=4.412, sample_size=125, ntokens=126, wps=28.2, ups=0.22, wpb=126, bsz=1, num_updates=13, lr=0.08, gnorm=3.777, loss_scale=4, train_wall=4, gb_free=32.6, wall=52\n",
            "2024-03-02 13:24:15 | INFO | train_inner | epoch 001:     14 / 32 loss=2.793, sample_size=62, ntokens=63, wps=27.4, ups=0.43, wpb=63, bsz=1, num_updates=14, lr=0.08, gnorm=3.651, loss_scale=4, train_wall=2, gb_free=32.6, wall=54\n",
            "2024-03-02 13:24:19 | INFO | train_inner | epoch 001:     15 / 32 loss=4.066, sample_size=95, ntokens=96, wps=27.6, ups=0.29, wpb=96, bsz=1, num_updates=15, lr=0.08, gnorm=4.004, loss_scale=4, train_wall=3, gb_free=32.6, wall=58\n",
            "2024-03-02 13:24:20 | INFO | train_inner | epoch 001:     16 / 32 loss=2.152, sample_size=44, ntokens=45, wps=27.2, ups=0.6, wpb=45, bsz=1, num_updates=16, lr=0.08, gnorm=4.47, loss_scale=4, train_wall=2, gb_free=32.6, wall=60\n",
            "2024-03-02 13:24:22 | INFO | train_inner | epoch 001:     17 / 32 loss=3.191, sample_size=48, ntokens=49, wps=27.3, ups=0.56, wpb=49, bsz=1, num_updates=17, lr=0.08, gnorm=7.664, loss_scale=4, train_wall=2, gb_free=32.6, wall=61\n",
            "2024-03-02 13:24:25 | INFO | train_inner | epoch 001:     18 / 32 loss=4.52, sample_size=71, ntokens=72, wps=28, ups=0.39, wpb=72, bsz=1, num_updates=18, lr=0.08, gnorm=6.933, loss_scale=4, train_wall=3, gb_free=32.6, wall=64\n",
            "2024-03-02 13:24:27 | INFO | train_inner | epoch 001:     19 / 32 loss=4.543, sample_size=64, ntokens=65, wps=27.6, ups=0.43, wpb=65, bsz=1, num_updates=19, lr=0.08, gnorm=10.02, loss_scale=4, train_wall=2, gb_free=32.6, wall=66\n",
            "2024-03-02 13:24:30 | INFO | train_inner | epoch 001:     20 / 32 loss=4.288, sample_size=75, ntokens=76, wps=27.7, ups=0.36, wpb=76, bsz=1, num_updates=20, lr=0.08, gnorm=5.344, loss_scale=4, train_wall=3, gb_free=32.6, wall=69\n",
            "2024-03-02 13:24:33 | INFO | train_inner | epoch 001:     21 / 32 loss=3.729, sample_size=95, ntokens=96, wps=27.7, ups=0.29, wpb=96, bsz=1, num_updates=21, lr=0.08, gnorm=5.315, loss_scale=4, train_wall=3, gb_free=32.6, wall=72\n",
            "2024-03-02 13:24:43 | INFO | train_inner | epoch 001:     22 / 32 loss=5.155, sample_size=193, ntokens=194, wps=21.1, ups=0.11, wpb=194, bsz=1, num_updates=22, lr=0.08, gnorm=4.053, loss_scale=4, train_wall=9, gb_free=32.6, wall=82\n",
            "2024-03-02 13:24:47 | INFO | train_inner | epoch 001:     23 / 32 loss=4.837, sample_size=80, ntokens=81, wps=19.3, ups=0.24, wpb=81, bsz=1, num_updates=23, lr=0.08, gnorm=4.283, loss_scale=4, train_wall=4, gb_free=32.6, wall=86\n",
            "2024-03-02 13:24:52 | INFO | train_inner | epoch 001:     24 / 32 loss=3.545, sample_size=147, ntokens=148, wps=26.8, ups=0.18, wpb=148, bsz=1, num_updates=24, lr=0.08, gnorm=3.453, loss_scale=4, train_wall=6, gb_free=32.6, wall=91\n",
            "2024-03-02 13:24:55 | INFO | train_inner | epoch 001:     25 / 32 loss=3.349, sample_size=72, ntokens=73, wps=27.3, ups=0.37, wpb=73, bsz=1, num_updates=25, lr=0.08, gnorm=3.617, loss_scale=4, train_wall=3, gb_free=32.6, wall=94\n",
            "2024-03-02 13:25:02 | INFO | train_inner | epoch 001:     26 / 32 loss=3.771, sample_size=189, ntokens=190, wps=28.3, ups=0.15, wpb=190, bsz=1, num_updates=26, lr=0.08, gnorm=3.055, loss_scale=4, train_wall=7, gb_free=32.6, wall=101\n",
            "2024-03-02 13:25:04 | INFO | train_inner | epoch 001:     27 / 32 loss=4.288, sample_size=56, ntokens=57, wps=27.4, ups=0.48, wpb=57, bsz=1, num_updates=27, lr=0.08, gnorm=6.034, loss_scale=4, train_wall=2, gb_free=32.6, wall=103\n",
            "2024-03-02 13:25:06 | INFO | train_inner | epoch 001:     28 / 32 loss=4.743, sample_size=52, ntokens=53, wps=27.4, ups=0.52, wpb=53, bsz=1, num_updates=28, lr=0.08, gnorm=6.115, loss_scale=4, train_wall=2, gb_free=32.6, wall=105\n",
            "2024-03-02 13:25:08 | INFO | train_inner | epoch 001:     29 / 32 loss=3.72, sample_size=59, ntokens=60, wps=27.5, ups=0.46, wpb=60, bsz=1, num_updates=29, lr=0.08, gnorm=3.676, loss_scale=4, train_wall=2, gb_free=32.6, wall=107\n",
            "2024-03-02 13:25:10 | INFO | train_inner | epoch 001:     30 / 32 loss=3.058, sample_size=65, ntokens=66, wps=27.9, ups=0.42, wpb=66, bsz=1, num_updates=30, lr=0.08, gnorm=3.759, loss_scale=4, train_wall=2, gb_free=32.6, wall=109\n",
            "2024-03-02 13:25:12 | INFO | train_inner | epoch 001:     31 / 32 loss=2.669, sample_size=48, ntokens=49, wps=27.6, ups=0.56, wpb=49, bsz=1, num_updates=31, lr=0.08, gnorm=3.47, loss_scale=4, train_wall=2, gb_free=32.6, wall=111\n",
            "2024-03-02 13:25:15 | INFO | train_inner | epoch 001:     32 / 32 loss=2.841, sample_size=74, ntokens=75, wps=27.5, ups=0.37, wpb=75, bsz=1, num_updates=32, lr=0.08, gnorm=4.826, loss_scale=4, train_wall=3, gb_free=32.6, wall=114\n",
            "2024-03-02 13:25:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 32 updates\n",
            "2024-03-02 13:25:15 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/cb/en_dense_lm_1_3b/0.08/checkpoint1.pt\n",
            "2024-03-02 13:25:33 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/cb/en_dense_lm_1_3b/0.08/checkpoint1.pt\n",
            "2024-03-02 13:25:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/cb/en_dense_lm_1_3b/0.08/checkpoint1.pt (epoch 1 @ 32 updates, score None) (writing took 37.93186697700003 seconds)\n",
            "2024-03-02 13:25:53 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
            "2024-03-02 13:25:53 | INFO | train | epoch 001 | loss 4.075 | sample_size 91.219 | ntokens 92.219 | wps 19.6 | ups 0.22 | wpb 92.2 | bsz 1 | num_updates 32 | lr 0.08 | gnorm 4.894 | loss_scale 4 | train_wall 113 | gb_free 32.6 | wall 152\n",
            "2024-03-02 13:25:53 | INFO | fairseq_cli.train | done training in 151.4 seconds\n",
            "+ SEED=3\n",
            "+ TASK=cb\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/cb/en_dense_lm_1_3b/0.08/checkpoint_last.pt\n",
            "+ ARCH=gptmodel_large\n",
            "+ K=0\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/cb\n",
            "+ ana_setting=ftzs\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' cb = agnews ']'\n",
            "+ '[' cb = trec ']'\n",
            "+ '[' cb = sst5 ']'\n",
            "+ '[' cb = dbpedia ']'\n",
            "+ '[' cb = cb ']'\n",
            "+ N_CLASSES=3\n",
            "+ '[' cb = arce ']'\n",
            "+ '[' cb = arcc ']'\n",
            "+ '[' cb = obqa ']'\n",
            "+ '[' cb = hellaswag ']'\n",
            "+ '[' cb = storycloze ']'\n",
            "+ '[' cb = raceh ']'\n",
            "+ '[' cb = racem ']'\n",
            "+ '[' cb = nq ']'\n",
            "+ '[' cb = webqs ']'\n",
            "+ '[' cb = triviaqa ']'\n",
            "+ '[' cb = sq2 ']'\n",
            "+ '[' cb = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ BSZ=3\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_eval --arch gptmodel_large --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --max-epoch 1 --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --max-update 0 --fp16 --eval-data cb --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 3 --reset-dataloader --no-save --k 0 --batch-size 3 --batch-size-valid 3 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/cb/en_dense_lm_1_3b/0.08/checkpoint_last.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/cb --ana-setting ftzs --permut-index 0\n",
            "+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/train_log_ftzs.txt\n",
            "2024-03-02 13:26:05 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-02 13:26:06 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-02 13:26:06 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-02 13:26:07.385918: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-02 13:26:07.385964: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-02 13:26:07.387605: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-02 13:26:08.589800: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-02 13:26:10 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 3, 'eval_data': 'cb', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/cb', 'ana_setting': 'ftzs', 'optim_group': 'all', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 0, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_large', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2048, 'decoder_output_dim': 2048, 'decoder_input_dim': 2048, 'decoder_ffn_embed_dim': 8192, 'decoder_layers': 24, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/cb/en_dense_lm_1_3b/0.08/checkpoint_last.pt'}, 'criterion': {'_name': 'fs_eval', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 3, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 3, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 3, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': True, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=3, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_eval', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=3, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid='3', max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_large', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.25], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=True, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='cb', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/cb', ana_setting='ftzs', optim_group='all', tokens_per_sample=2048, max_target_positions=None, k=0, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/cb/en_dense_lm_1_3b/0.08/checkpoint_last.pt', no_seed_provided=False, decoder_layers=24, decoder_embed_dim=2048, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2048, decoder_output_dim=2048, decoder_ffn_embed_dim=8192, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-02 13:26:10 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-02 13:26:12 | WARNING | datasets.builder | Reusing dataset super_glue (/root/.cache/huggingface/datasets/super_glue/cb/1.0.2/d040c658e2ddef6934fdd97deb45c777b6ff50c524781ea434e7219b56a428a7)\n",
            "100%|██████████| 3/3 [00:00<00:00, 751.76it/s]\n",
            "2024-03-02 13:26:12 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/super_glue/cb/1.0.2/d040c658e2ddef6934fdd97deb45c777b6ff50c524781ea434e7219b56a428a7/cache-938493646037f99b.arrow\n",
            "2024-03-02 13:26:12 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/super_glue/cb/1.0.2/d040c658e2ddef6934fdd97deb45c777b6ff50c524781ea434e7219b56a428a7/cache-51936d8860a97ff3.arrow\n",
            "2024-03-02 13:26:48 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-02 13:26:49 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2048, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-23): 24 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
            "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2048, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-02 13:26:49 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-02 13:26:49 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-02 13:26:49 | INFO | fairseq_cli.train | criterion: FewshotEvalCriterion\n",
            "2024-03-02 13:26:49 | INFO | fairseq_cli.train | num. shared model params: 1,313,460,224 (num. trained: 2,048)\n",
            "2024-03-02 13:26:49 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-02 13:26:51 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-02 13:26:51 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-02 13:26:51 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-02 13:26:51 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-02 13:26:51 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-02 13:26:51 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 3\n",
            "2024-03-02 13:26:51 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt\n",
            "2024-03-02 13:26:51 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last.pt\n",
            "2024-03-02 13:26:51 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-02 13:26:51 | INFO | fairseq_cli.train | Start validating\n",
            "2024-03-02 13:26:51 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "------------ example 0 input str valid is [\"A: Well, actually, uh, A: I don't think I'm in the, uh, majority in Texas Question: she is in the majority in Texas. True, False, or Neither? Answer:\", \"A: Well, actually, uh, A: I don't think I'm in the, uh, majority in Texas Question: she is in the majority in Texas. True, False, or Neither? Answer:\", \"A: Well, actually, uh, A: I don't think I'm in the, uh, majority in Texas Question: she is in the majority in Texas. True, False, or Neither? Answer:\"]\n",
            "------------ example 0 label str valid is [' True', ' False', ' Neither']\n",
            "------------ example 1 input str valid is [\"A: and that rolling kind of, uh, B: Terrain. A: Yeah. is fairly famili-,. The thing that I thought was interesting was that the critics, apparently it's going to win everything. B: Really? A: Uh, and I had been told, you know, you wouldn't notice that it was three hours long, and all this, kind of, Question: it was three hours long. True, False, or Neither? Answer:\", \"A: and that rolling kind of, uh, B: Terrain. A: Yeah. is fairly famili-,. The thing that I thought was interesting was that the critics, apparently it's going to win everything. B: Really? A: Uh, and I had been told, you know, you wouldn't notice that it was three hours long, and all this, kind of, Question: it was three hours long. True, False, or Neither? Answer:\", \"A: and that rolling kind of, uh, B: Terrain. A: Yeah. is fairly famili-,. The thing that I thought was interesting was that the critics, apparently it's going to win everything. B: Really? A: Uh, and I had been told, you know, you wouldn't notice that it was three hours long, and all this, kind of, Question: it was three hours long. True, False, or Neither? Answer:\"]\n",
            "------------ example 1 label str valid is [' True', ' False', ' Neither']\n",
            "NOTE: true K of baseline is 0, max valid len is 280\n",
            "| Loaded valid with 168 samples\n",
            "| Loaded train with 168 samples\n",
            "2024-03-02 13:27:00 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 2.295 | nll_loss 0.008 | accuracy 50 | f1 0 | pos_proportion 41.1 | neg_proportion 50 | wps 2205.2 | wpb 304.4 | bsz 1 | num_updates 0\n",
            "+ SEED=3\n",
            "+ TASK=cb\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt\n",
            "+ ARCH=gptmodel_large\n",
            "+ K=0\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/cb\n",
            "+ ana_setting=zs\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' cb = agnews ']'\n",
            "+ '[' cb = trec ']'\n",
            "+ '[' cb = sst5 ']'\n",
            "+ '[' cb = dbpedia ']'\n",
            "+ '[' cb = cb ']'\n",
            "+ N_CLASSES=3\n",
            "+ '[' cb = arce ']'\n",
            "+ '[' cb = arcc ']'\n",
            "+ '[' cb = obqa ']'\n",
            "+ '[' cb = hellaswag ']'\n",
            "+ '[' cb = storycloze ']'\n",
            "+ '[' cb = raceh ']'\n",
            "+ '[' cb = racem ']'\n",
            "+ '[' cb = nq ']'\n",
            "+ '[' cb = webqs ']'\n",
            "+ '[' cb = triviaqa ']'\n",
            "+ '[' cb = sq2 ']'\n",
            "+ '[' cb = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ BSZ=3\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_eval --arch gptmodel_large --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --max-epoch 1 --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --max-update 0 --fp16 --eval-data cb --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 3 --reset-dataloader --no-save --k 0 --batch-size 3 --batch-size-valid 3 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/cb --ana-setting zs --permut-index 0\n",
            "+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/train_log_zs.txt\n",
            "2024-03-02 13:27:07 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-02 13:27:07 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-02 13:27:07 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-02 13:27:09.046469: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-02 13:27:09.046510: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-02 13:27:09.048108: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-02 13:27:10.268315: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-02 13:27:12 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 3, 'eval_data': 'cb', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/cb', 'ana_setting': 'zs', 'optim_group': 'all', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 0, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_large', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2048, 'decoder_output_dim': 2048, 'decoder_input_dim': 2048, 'decoder_ffn_embed_dim': 8192, 'decoder_layers': 24, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt'}, 'criterion': {'_name': 'fs_eval', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 3, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 3, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 3, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': True, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=3, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_eval', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=3, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid='3', max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_large', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.25], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=True, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='cb', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/cb', ana_setting='zs', optim_group='all', tokens_per_sample=2048, max_target_positions=None, k=0, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt', no_seed_provided=False, decoder_layers=24, decoder_embed_dim=2048, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2048, decoder_output_dim=2048, decoder_ffn_embed_dim=8192, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-02 13:27:12 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-02 13:27:14 | WARNING | datasets.builder | Reusing dataset super_glue (/root/.cache/huggingface/datasets/super_glue/cb/1.0.2/d040c658e2ddef6934fdd97deb45c777b6ff50c524781ea434e7219b56a428a7)\n",
            "100%|██████████| 3/3 [00:00<00:00, 707.78it/s]\n",
            "2024-03-02 13:27:14 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/super_glue/cb/1.0.2/d040c658e2ddef6934fdd97deb45c777b6ff50c524781ea434e7219b56a428a7/cache-938493646037f99b.arrow\n",
            "2024-03-02 13:27:14 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/super_glue/cb/1.0.2/d040c658e2ddef6934fdd97deb45c777b6ff50c524781ea434e7219b56a428a7/cache-51936d8860a97ff3.arrow\n",
            "2024-03-02 13:27:48 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-02 13:27:49 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2048, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-23): 24 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
            "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2048, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-02 13:27:49 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-02 13:27:49 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-02 13:27:49 | INFO | fairseq_cli.train | criterion: FewshotEvalCriterion\n",
            "2024-03-02 13:27:49 | INFO | fairseq_cli.train | num. shared model params: 1,313,460,224 (num. trained: 2,048)\n",
            "2024-03-02 13:27:49 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-02 13:27:51 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-02 13:27:51 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-02 13:27:51 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-02 13:27:51 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-02 13:27:51 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-02 13:27:51 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 3\n",
            "2024-03-02 13:27:51 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt\n",
            "2024-03-02 13:27:51 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last.pt\n",
            "2024-03-02 13:27:51 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-02 13:27:51 | INFO | fairseq_cli.train | Start validating\n",
            "2024-03-02 13:27:51 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "------------ example 0 input str valid is [\"A: Well, actually, uh, A: I don't think I'm in the, uh, majority in Texas Question: she is in the majority in Texas. True, False, or Neither? Answer:\", \"A: Well, actually, uh, A: I don't think I'm in the, uh, majority in Texas Question: she is in the majority in Texas. True, False, or Neither? Answer:\", \"A: Well, actually, uh, A: I don't think I'm in the, uh, majority in Texas Question: she is in the majority in Texas. True, False, or Neither? Answer:\"]\n",
            "------------ example 0 label str valid is [' True', ' False', ' Neither']\n",
            "------------ example 1 input str valid is [\"A: and that rolling kind of, uh, B: Terrain. A: Yeah. is fairly famili-,. The thing that I thought was interesting was that the critics, apparently it's going to win everything. B: Really? A: Uh, and I had been told, you know, you wouldn't notice that it was three hours long, and all this, kind of, Question: it was three hours long. True, False, or Neither? Answer:\", \"A: and that rolling kind of, uh, B: Terrain. A: Yeah. is fairly famili-,. The thing that I thought was interesting was that the critics, apparently it's going to win everything. B: Really? A: Uh, and I had been told, you know, you wouldn't notice that it was three hours long, and all this, kind of, Question: it was three hours long. True, False, or Neither? Answer:\", \"A: and that rolling kind of, uh, B: Terrain. A: Yeah. is fairly famili-,. The thing that I thought was interesting was that the critics, apparently it's going to win everything. B: Really? A: Uh, and I had been told, you know, you wouldn't notice that it was three hours long, and all this, kind of, Question: it was three hours long. True, False, or Neither? Answer:\"]\n",
            "------------ example 1 label str valid is [' True', ' False', ' Neither']\n",
            "NOTE: true K of baseline is 0, max valid len is 280\n",
            "| Loaded valid with 168 samples\n",
            "| Loaded train with 168 samples\n",
            "2024-03-02 13:27:58 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 3.493 | nll_loss 0.011 | accuracy 37.5 | f1 0 | pos_proportion 41.1 | neg_proportion 50 | wps 2749.6 | wpb 304.4 | bsz 1 | num_updates 0\n",
            "+ SEED=3\n",
            "+ TASK=cb\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt\n",
            "+ ARCH=gptmodel_large\n",
            "+ K=32\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/cb\n",
            "+ ana_setting=icl\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' cb = agnews ']'\n",
            "+ '[' cb = trec ']'\n",
            "+ '[' cb = sst5 ']'\n",
            "+ '[' cb = dbpedia ']'\n",
            "+ '[' cb = cb ']'\n",
            "+ N_CLASSES=3\n",
            "+ '[' cb = arce ']'\n",
            "+ '[' cb = arcc ']'\n",
            "+ '[' cb = obqa ']'\n",
            "+ '[' cb = hellaswag ']'\n",
            "+ '[' cb = storycloze ']'\n",
            "+ '[' cb = raceh ']'\n",
            "+ '[' cb = racem ']'\n",
            "+ '[' cb = nq ']'\n",
            "+ '[' cb = webqs ']'\n",
            "+ '[' cb = triviaqa ']'\n",
            "+ '[' cb = sq2 ']'\n",
            "+ '[' cb = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ BSZ=3\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_eval --arch gptmodel_large --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --max-epoch 1 --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --max-update 0 --fp16 --eval-data cb --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 3 --reset-dataloader --no-save --k 32 --batch-size 3 --batch-size-valid 3 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/cb --ana-setting icl --permut-index 0\n",
            "+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/train_log_icl.txt\n",
            "2024-03-02 13:28:04 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-02 13:28:05 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-02 13:28:05 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-02 13:28:06.641429: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-02 13:28:06.641481: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-02 13:28:06.643438: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-02 13:28:07.947742: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-02 13:28:10 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 3, 'eval_data': 'cb', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/cb', 'ana_setting': 'icl', 'optim_group': 'all', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 32, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_large', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2048, 'decoder_output_dim': 2048, 'decoder_input_dim': 2048, 'decoder_ffn_embed_dim': 8192, 'decoder_layers': 24, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt'}, 'criterion': {'_name': 'fs_eval', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 3, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 3, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 3, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': True, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=3, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_eval', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=3, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid='3', max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_large', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.25], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=True, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='cb', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/cb', ana_setting='icl', optim_group='all', tokens_per_sample=2048, max_target_positions=None, k=32, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_1_3b/model.pt', no_seed_provided=False, decoder_layers=24, decoder_embed_dim=2048, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2048, decoder_output_dim=2048, decoder_ffn_embed_dim=8192, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-02 13:28:10 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-02 13:28:11 | WARNING | datasets.builder | Reusing dataset super_glue (/root/.cache/huggingface/datasets/super_glue/cb/1.0.2/d040c658e2ddef6934fdd97deb45c777b6ff50c524781ea434e7219b56a428a7)\n",
            "100%|██████████| 3/3 [00:00<00:00, 748.05it/s]\n",
            "2024-03-02 13:28:11 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/super_glue/cb/1.0.2/d040c658e2ddef6934fdd97deb45c777b6ff50c524781ea434e7219b56a428a7/cache-938493646037f99b.arrow\n",
            "2024-03-02 13:28:11 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/super_glue/cb/1.0.2/d040c658e2ddef6934fdd97deb45c777b6ff50c524781ea434e7219b56a428a7/cache-51936d8860a97ff3.arrow\n",
            "2024-03-02 13:28:44 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-02 13:28:45 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2048, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-23): 24 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "          (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
            "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2048, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-02 13:28:45 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-02 13:28:45 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-02 13:28:45 | INFO | fairseq_cli.train | criterion: FewshotEvalCriterion\n",
            "2024-03-02 13:28:45 | INFO | fairseq_cli.train | num. shared model params: 1,313,460,224 (num. trained: 2,048)\n",
            "2024-03-02 13:28:45 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-02 13:28:46 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-02 13:28:46 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-02 13:28:46 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-02 13:28:46 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-02 13:28:46 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-02 13:28:46 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 3\n",
            "2024-03-02 13:28:46 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt\n",
            "2024-03-02 13:28:46 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last.pt\n",
            "2024-03-02 13:28:46 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-02 13:28:46 | INFO | fairseq_cli.train | Start validating\n",
            "2024-03-02 13:28:46 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "------------ example 0 input str train is [\"For a while the notion gripped him, and he prowled the many floors of Hamleys looking for toys. He bought a magic set for Sebastian (although his ideal present for the kid would have been a brand-new name) and a marionette for Louise. He could remember that there was an age for puppets and magic just as he could remember the time that he 'd spent trying to fan a deck of cards or sitting in front of a mirror trying to get the hard consonants down like a real ventriloquist. Question: there was an age for puppets and magic. True, False, or Neither? Answer:\", \"For a while the notion gripped him, and he prowled the many floors of Hamleys looking for toys. He bought a magic set for Sebastian (although his ideal present for the kid would have been a brand-new name) and a marionette for Louise. He could remember that there was an age for puppets and magic just as he could remember the time that he 'd spent trying to fan a deck of cards or sitting in front of a mirror trying to get the hard consonants down like a real ventriloquist. Question: there was an age for puppets and magic. True, False, or Neither? Answer:\", \"For a while the notion gripped him, and he prowled the many floors of Hamleys looking for toys. He bought a magic set for Sebastian (although his ideal present for the kid would have been a brand-new name) and a marionette for Louise. He could remember that there was an age for puppets and magic just as he could remember the time that he 'd spent trying to fan a deck of cards or sitting in front of a mirror trying to get the hard consonants down like a real ventriloquist. Question: there was an age for puppets and magic. True, False, or Neither? Answer:\"]\n",
            "------------ example 0 label str train is [' True', ' False', ' Neither']\n",
            "------------ example 1 input str train is [\"``For God's sake keep them in their seats. If we get panic people are going to be crushed to death and there will be mayhem in the car park.'' The announcer could only guess from the urgency in the Chief Constable's voice that the situation was very very serious. Question: the situation was very very serious. True, False, or Neither? Answer:\", \"``For God's sake keep them in their seats. If we get panic people are going to be crushed to death and there will be mayhem in the car park.'' The announcer could only guess from the urgency in the Chief Constable's voice that the situation was very very serious. Question: the situation was very very serious. True, False, or Neither? Answer:\", \"``For God's sake keep them in their seats. If we get panic people are going to be crushed to death and there will be mayhem in the car park.'' The announcer could only guess from the urgency in the Chief Constable's voice that the situation was very very serious. Question: the situation was very very serious. True, False, or Neither? Answer:\"]\n",
            "------------ example 1 label str train is [' True', ' False', ' Neither']\n",
            "------------ example 0 input str valid is [\"A: Well, actually, uh, A: I don't think I'm in the, uh, majority in Texas Question: she is in the majority in Texas. True, False, or Neither? Answer:\", \"A: Well, actually, uh, A: I don't think I'm in the, uh, majority in Texas Question: she is in the majority in Texas. True, False, or Neither? Answer:\", \"A: Well, actually, uh, A: I don't think I'm in the, uh, majority in Texas Question: she is in the majority in Texas. True, False, or Neither? Answer:\"]\n",
            "------------ example 0 label str valid is [' True', ' False', ' Neither']\n",
            "------------ example 1 input str valid is [\"A: and that rolling kind of, uh, B: Terrain. A: Yeah. is fairly famili-,. The thing that I thought was interesting was that the critics, apparently it's going to win everything. B: Really? A: Uh, and I had been told, you know, you wouldn't notice that it was three hours long, and all this, kind of, Question: it was three hours long. True, False, or Neither? Answer:\", \"A: and that rolling kind of, uh, B: Terrain. A: Yeah. is fairly famili-,. The thing that I thought was interesting was that the critics, apparently it's going to win everything. B: Really? A: Uh, and I had been told, you know, you wouldn't notice that it was three hours long, and all this, kind of, Question: it was three hours long. True, False, or Neither? Answer:\", \"A: and that rolling kind of, uh, B: Terrain. A: Yeah. is fairly famili-,. The thing that I thought was interesting was that the critics, apparently it's going to win everything. B: Really? A: Uh, and I had been told, you know, you wouldn't notice that it was three hours long, and all this, kind of, Question: it was three hours long. True, False, or Neither? Answer:\"]\n",
            "------------ example 1 label str valid is [' True', ' False', ' Neither']\n",
            "NOTE: true K of baseline is 19, max valid len is 280\n",
            "| Loaded valid with 168 samples\n",
            "| Loaded train with 168 samples\n",
            "2024-03-02 13:28:59 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 2.016 | nll_loss 0 | accuracy 57.1 | f1 0 | pos_proportion 41.1 | neg_proportion 50 | wps 26039.2 | wpb 5503.4 | bsz 1 | num_updates 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python icl_ft/compute_sim.py cb all 1_3b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daDC7cYRWYLY",
        "outputId": "436cf677-c356-4158-868c-6393483a93c9",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/cb/ftzs 56\n",
            "loading ftzs data costs 2.0873353481292725 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/cb/zs 56\n",
            "loading zs data costs 1.6032629013061523 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/cb/icl 56\n",
            "loading icl data costs 1.8657379150390625 seconds\n",
            "================= number of both F2T examples: 22\n",
            "================= number of ICL F2T examples: 22\n",
            "================= number of FTZS F2T examples: 24\n",
            "++++++++++++++++ ICL recall to FT: 91.67\n",
            "count_f2t costs 0.00016069412231445312 seconds\n",
            "============================== analyzing self_attn_out_hiddens ==============================\n",
            "per-layer updates sim (icl-zs)&(ftzs-zs):\n",
            " [0.0313 0.0067 0.1782 0.2433 0.4174 0.0184 0.1737 0.1901 0.2254 0.182\n",
            " 0.2396 0.3182 0.2467 0.3523 0.23   0.2654 0.1857 0.1065 0.1797 0.2625\n",
            " 0.0968 0.2039 0.2625 0.2905]\n",
            "overall updates sim (icl-zs)&(ftzs-zs):\n",
            " 0.2045\n",
            "\n",
            "per-layer updates sim (icl-zs)&(random):\n",
            " [-0.0035  0.009   0.0192  0.0201  0.0123  0.0067  0.0038 -0.0042  0.0015\n",
            "  0.0096  0.0042  0.0029 -0.0018 -0.004  -0.0049  0.0002  0.0002 -0.0011\n",
            "  0.0017  0.0016  0.0024  0.0024  0.0061 -0.0021]\n",
            "overall updates sim (icl-zs)&(random):\n",
            " 0.0034\n",
            "\n",
            "analyze_sim costs 0.49506616592407227 seconds\n",
            "============================== analyzing attn_map, softmax=False ==============================\n",
            "per-layer direct sim (icl)&(zs):\n",
            " [-0.2153  0.2278  0.1349 -0.2483  0.232   0.3968  0.4967  0.4511  0.2412\n",
            "  0.1129 -0.0654 -0.2182 -0.3488 -0.3696 -0.5159 -0.181  -0.1332 -0.1679\n",
            " -0.0595  0.5459  0.8042  0.8612  0.942   0.7346]\n",
            "overall direct sim (icl)&(zs):\n",
            " 0.1524\n",
            "\n",
            "per-layer direct sim (icl)&(ftzs):\n",
            " [-0.2153  0.2261  0.1849 -0.2033  0.253   0.4577  0.5148  0.4736  0.2684\n",
            "  0.1645  0.0731 -0.2318 -0.4057 -0.1792 -0.4702  0.0916  0.0376 -0.0437\n",
            " -0.0503  0.5348  0.824   0.793   0.9051  0.7348]\n",
            "overall direct sim (icl)&(ftzs):\n",
            " 0.1974\n",
            "\n",
            "analyze_attn_map (w/o softmax) costs 9.787643671035767 seconds\n",
            "saving data costs 0.6189022064208984 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash analyze.sh"
      ],
      "metadata": {
        "id": "q2f4LFVxhEUc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27113d96-ee5f-4ac7-9815-5af53343d20c",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+ model=1_3b\n",
            "+ task=cb\n",
            "+ python icl_ft/compute_sim.py cb all 1_3b\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/cb/ftzs 56\n",
            "loading ftzs data costs 2.869798421859741 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/cb/zs 56\n",
            "loading zs data costs 2.3426899909973145 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/cb/icl 56\n",
            "loading icl data costs 2.7108042240142822 seconds\n",
            "================= number of both F2T examples: 22\n",
            "================= number of ICL F2T examples: 22\n",
            "================= number of FTZS F2T examples: 24\n",
            "++++++++++++++++ ICL recall to FT: 91.67\n",
            "count_f2t costs 0.00016736984252929688 seconds\n",
            "============================== analyzing self_attn_out_hiddens ==============================\n",
            "per-layer updates sim (icl-zs)&(ftzs-zs):\n",
            " [0.0313 0.0067 0.1782 0.2433 0.4174 0.0184 0.1737 0.1901 0.2254 0.182\n",
            " 0.2396 0.3182 0.2467 0.3523 0.23   0.2654 0.1857 0.1065 0.1797 0.2625\n",
            " 0.0968 0.2039 0.2625 0.2905]\n",
            "overall updates sim (icl-zs)&(ftzs-zs):\n",
            " 0.2045\n",
            "\n",
            "per-layer updates sim (icl-zs)&(random):\n",
            " [-0.005   0.0107  0.0172  0.0148  0.0143  0.0102  0.0008 -0.0036 -0.0004\n",
            "  0.0097  0.0064  0.0015 -0.0038 -0.0003 -0.0041  0.0047  0.0009 -0.0018\n",
            "  0.0039  0.0002  0.0029  0.0046  0.0079 -0.0031]\n",
            "overall updates sim (icl-zs)&(random):\n",
            " 0.0037\n",
            "\n",
            "analyze_sim costs 0.6271483898162842 seconds\n",
            "============================== analyzing attn_map, softmax=False ==============================\n",
            "per-layer direct sim (icl)&(zs):\n",
            " [-0.2153  0.2278  0.1349 -0.2483  0.232   0.3968  0.4967  0.4511  0.2412\n",
            "  0.1129 -0.0654 -0.2182 -0.3488 -0.3696 -0.5159 -0.181  -0.1332 -0.1679\n",
            " -0.0595  0.5459  0.8042  0.8612  0.942   0.7346]\n",
            "overall direct sim (icl)&(zs):\n",
            " 0.1524\n",
            "\n",
            "per-layer direct sim (icl)&(ftzs):\n",
            " [-0.2153  0.2261  0.1849 -0.2033  0.253   0.4577  0.5148  0.4736  0.2684\n",
            "  0.1645  0.0731 -0.2318 -0.4057 -0.1792 -0.4702  0.0916  0.0376 -0.0437\n",
            " -0.0503  0.5348  0.824   0.793   0.9051  0.7348]\n",
            "overall direct sim (icl)&(ftzs):\n",
            " 0.1974\n",
            "\n",
            "analyze_attn_map (w/o softmax) costs 10.376888275146484 seconds\n",
            "saving data costs 0.5981652736663818 seconds\n",
            "+ task=sst2\n",
            "+ python icl_ft/compute_sim.py sst2 all 1_3b\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst2/ftzs 872\n",
            "loading ftzs data costs 28.29657292366028 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst2/zs 872\n",
            "loading zs data costs 18.12028694152832 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst2/icl 872\n",
            "loading icl data costs 21.10366916656494 seconds\n",
            "================= number of both F2T examples: 45\n",
            "================= number of ICL F2T examples: 227\n",
            "================= number of FTZS F2T examples: 49\n",
            "++++++++++++++++ ICL recall to FT: 91.84\n",
            "count_f2t costs 0.0013709068298339844 seconds\n",
            "============================== analyzing self_attn_out_hiddens ==============================\n",
            "per-layer updates sim (icl-zs)&(ftzs-zs):\n",
            " [-0.0653 -0.1167 -0.0522  0.3658  0.1393  0.0625  0.2185  0.1852  0.0374\n",
            "  0.1821  0.1347  0.1507  0.2331  0.2052  0.241   0.1803  0.1987  0.0965\n",
            "  0.1212 -0.0905  0.1633 -0.0791 -0.2545  0.3766]\n",
            "overall updates sim (icl-zs)&(ftzs-zs):\n",
            " 0.1097\n",
            "\n",
            "per-layer updates sim (icl-zs)&(random):\n",
            " [-0.0119  0.0083  0.0204  0.0149  0.0053  0.01    0.0133 -0.0045 -0.0015\n",
            " -0.0078 -0.0069 -0.0015 -0.0034  0.005   0.0038 -0.0022 -0.0011 -0.0018\n",
            " -0.0029 -0.0069 -0.0056 -0.0006  0.0082  0.0083]\n",
            "overall updates sim (icl-zs)&(random):\n",
            " 0.0016\n",
            "\n",
            "analyze_sim costs 9.012929439544678 seconds\n",
            "============================== analyzing attn_map, softmax=False ==============================\n",
            "per-layer direct sim (icl)&(zs):\n",
            " [0.1751 0.5387 0.3876 0.3218 0.7105 0.8526 0.8505 0.7659 0.8727 0.6579\n",
            " 0.3527 0.3829 0.2426 0.4617 0.4751 0.5187 0.2762 0.0838 0.3084 0.7135\n",
            " 0.8789 0.865  0.9158 0.7029]\n",
            "overall direct sim (icl)&(zs):\n",
            " 0.5547\n",
            "\n",
            "per-layer direct sim (icl)&(ftzs):\n",
            " [0.1751 0.5385 0.3865 0.321  0.7099 0.8536 0.8505 0.7653 0.873  0.6684\n",
            " 0.3651 0.4564 0.2581 0.5389 0.4069 0.6378 0.4834 0.2553 0.4105 0.7292\n",
            " 0.8608 0.8801 0.9139 0.7048]\n",
            "overall direct sim (icl)&(ftzs):\n",
            " 0.5851\n",
            "\n",
            "analyze_attn_map (w/o softmax) costs 53.40292739868164 seconds\n",
            "saving data costs 0.004873514175415039 seconds\n",
            "+ task=sst5\n",
            "+ python icl_ft/compute_sim.py sst5 all 1_3b\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst5/ftzs 1101\n",
            "loading ftzs data costs 33.96241307258606 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst5/zs 1101\n",
            "loading zs data costs 21.865410804748535 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst5/icl 1101\n",
            "loading icl data costs 27.302872896194458 seconds\n",
            "================= number of both F2T examples: 6\n",
            "================= number of ICL F2T examples: 181\n",
            "================= number of FTZS F2T examples: 10\n",
            "++++++++++++++++ ICL recall to FT: 60.00\n",
            "count_f2t costs 0.0022640228271484375 seconds\n",
            "============================== analyzing self_attn_out_hiddens ==============================\n",
            "per-layer updates sim (icl-zs)&(ftzs-zs):\n",
            " [-0.057  -0.1108  0.1417  0.2693  0.1077 -0.1081  0.0842  0.2456  0.0733\n",
            "  0.0257  0.0795  0.1256  0.1645  0.1411  0.1154  0.0737  0.0807 -0.0038\n",
            "  0.0499 -0.176   0.1528 -0.002   0.1107  0.3164]\n",
            "overall updates sim (icl-zs)&(ftzs-zs):\n",
            " 0.0792\n",
            "\n",
            "per-layer updates sim (icl-zs)&(random):\n",
            " [ 0.0008  0.0087  0.0202  0.0174  0.0099  0.0062  0.008   0.0001 -0.0003\n",
            " -0.0066 -0.0086  0.0038  0.0011  0.0019  0.0021 -0.0004 -0.0018 -0.0027\n",
            "  0.0012  0.0018 -0.0036  0.002   0.0016 -0.0012]\n",
            "overall updates sim (icl-zs)&(random):\n",
            " 0.0026\n",
            "\n",
            "analyze_sim costs 12.544209718704224 seconds\n",
            "============================== analyzing attn_map, softmax=False ==============================\n",
            "per-layer direct sim (icl)&(zs):\n",
            " [ 0.0269  0.4767  0.2478  0.0935  0.5246  0.6042  0.7052  0.5133  0.6415\n",
            "  0.3054  0.3177  0.2341  0.0542 -0.1718 -0.1955  0.3057  0.1826  0.0445\n",
            "  0.3417  0.7194  0.8545  0.8711  0.9026  0.7913]\n",
            "overall direct sim (icl)&(zs):\n",
            " 0.3913\n",
            "\n",
            "per-layer direct sim (icl)&(ftzs):\n",
            " [ 0.0269  0.4767  0.2479  0.0943  0.525   0.6046  0.7057  0.5142  0.6431\n",
            "  0.3107  0.3296  0.2473  0.0787 -0.1454 -0.1522  0.3532  0.2551  0.0897\n",
            "  0.3522  0.7242  0.8498  0.8743  0.8998  0.797 ]\n",
            "overall direct sim (icl)&(ftzs):\n",
            " 0.4043\n",
            "\n",
            "analyze_attn_map (w/o softmax) costs 65.58382034301758 seconds\n",
            "saving data costs 0.00529026985168457 seconds\n",
            "+ task=subj\n",
            "+ python icl_ft/compute_sim.py subj all 1_3b\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/subj/ftzs 2000\n",
            "loading ftzs data costs 65.51981472969055 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/subj/zs 2000\n",
            "loading zs data costs 41.985437631607056 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/subj/icl 2000\n",
            "loading icl data costs 53.04506540298462 seconds\n",
            "================= number of both F2T examples: 225\n",
            "================= number of ICL F2T examples: 436\n",
            "================= number of FTZS F2T examples: 259\n",
            "++++++++++++++++ ICL recall to FT: 86.87\n",
            "count_f2t costs 0.003217935562133789 seconds\n",
            "============================== analyzing self_attn_out_hiddens ==============================\n",
            "per-layer updates sim (icl-zs)&(ftzs-zs):\n",
            " [ 0.3845  0.0352 -0.0777 -0.1806  0.1303  0.0457  0.2879  0.2666  0.199\n",
            "  0.2237  0.269   0.2974  0.32    0.3175  0.3766  0.3118  0.3488  0.1764\n",
            "  0.2407  0.1832  0.208   0.0348  0.1414  0.0503]\n",
            "overall updates sim (icl-zs)&(ftzs-zs):\n",
            " 0.1913\n",
            "\n",
            "per-layer updates sim (icl-zs)&(random):\n",
            " [-0.0015 -0.0007  0.0215  0.0202  0.0083  0.0047  0.009  -0.0056  0.0024\n",
            " -0.002  -0.0102  0.0043  0.001   0.0007  0.0024 -0.0017 -0.0046 -0.001\n",
            "  0.0027 -0.0097 -0.0006  0.0078  0.0065  0.0001]\n",
            "overall updates sim (icl-zs)&(random):\n",
            " 0.0023\n",
            "\n",
            "analyze_sim costs 22.708858489990234 seconds\n",
            "============================== analyzing attn_map, softmax=False ==============================\n",
            "per-layer direct sim (icl)&(zs):\n",
            " [-0.0702  0.418   0.1401  0.0201  0.4842  0.5555  0.6671  0.4695  0.586\n",
            "  0.3341  0.4048  0.2982  0.1346 -0.0851 -0.1824  0.3434  0.126   0.0048\n",
            "  0.3538  0.7018  0.8723  0.8725  0.9017  0.7367]\n",
            "overall direct sim (icl)&(zs):\n",
            " 0.3786\n",
            "\n",
            "per-layer direct sim (icl)&(ftzs):\n",
            " [-0.0702  0.4149  0.1312  0.0175  0.4839  0.5584  0.6688  0.4817  0.6025\n",
            "  0.3485  0.5143  0.5389  0.3886  0.1168  0.1811  0.6837  0.6391  0.4594\n",
            "  0.5546  0.7341  0.8438  0.8447  0.885   0.7451]\n",
            "overall direct sim (icl)&(ftzs):\n",
            " 0.4903\n",
            "\n",
            "analyze_attn_map (w/o softmax) costs 186.19579362869263 seconds\n",
            "saving data costs 0.007066488265991211 seconds\n",
            "+ task=mr\n",
            "+ python icl_ft/compute_sim.py mr all 1_3b\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/mr/ftzs 1066\n",
            "loading ftzs data costs 35.0199990272522 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/mr/zs 1066\n",
            "loading zs data costs 23.154656410217285 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/mr/icl 1066\n",
            "loading icl data costs 27.633119821548462 seconds\n",
            "================= number of both F2T examples: 133\n",
            "================= number of ICL F2T examples: 318\n",
            "================= number of FTZS F2T examples: 137\n",
            "++++++++++++++++ ICL recall to FT: 97.08\n",
            "count_f2t costs 0.0018911361694335938 seconds\n",
            "============================== analyzing self_attn_out_hiddens ==============================\n",
            "per-layer updates sim (icl-zs)&(ftzs-zs):\n",
            " [0.5598 0.1662 0.0316 0.0094 0.0984 0.1126 0.1355 0.1193 0.1037 0.1716\n",
            " 0.2017 0.2812 0.3242 0.3899 0.4287 0.3681 0.3064 0.2286 0.3154 0.1512\n",
            " 0.286  0.2471 0.1352 0.157 ]\n",
            "overall updates sim (icl-zs)&(ftzs-zs):\n",
            " 0.222\n",
            "\n",
            "per-layer updates sim (icl-zs)&(random):\n",
            " [ 0.0012  0.0016  0.0198  0.0107  0.0041  0.0024  0.0121 -0.0026 -0.0011\n",
            " -0.0039 -0.0101  0.0004 -0.0052  0.0022  0.0027  0.0002 -0.0048 -0.0007\n",
            " -0.0057 -0.009  -0.0018 -0.0007  0.0026  0.0019]\n",
            "overall updates sim (icl-zs)&(random):\n",
            " 0.0007\n",
            "\n",
            "analyze_sim costs 9.663306713104248 seconds\n",
            "============================== analyzing attn_map, softmax=False ==============================\n",
            "per-layer direct sim (icl)&(zs):\n",
            " [-0.0026  0.3987  0.2295  0.0299  0.5606  0.6712  0.7162  0.5954  0.6585\n",
            "  0.2908  0.3305  0.1964  0.071  -0.1713 -0.34    0.3649  0.2234  0.1702\n",
            "  0.4279  0.6942  0.8641  0.8939  0.9262  0.7514]\n",
            "overall direct sim (icl)&(zs):\n",
            " 0.398\n",
            "\n",
            "per-layer direct sim (icl)&(ftzs):\n",
            " [-0.0026  0.3969  0.2224  0.0297  0.5598  0.6722  0.7173  0.5908  0.6609\n",
            "  0.2903  0.3572  0.265   0.2073  0.2003  0.1004  0.796   0.6999  0.5897\n",
            "  0.6402  0.6616  0.7916  0.865   0.9044  0.7363]\n",
            "overall direct sim (icl)&(ftzs):\n",
            " 0.498\n",
            "\n",
            "analyze_attn_map (w/o softmax) costs 69.9932758808136 seconds\n",
            "saving data costs 0.007292747497558594 seconds\n",
            "+ task=agnews\n",
            "+ python icl_ft/compute_sim.py agnews all 1_3b\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/agnews/ftzs 2000\n",
            "loading ftzs data costs 79.70603442192078 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/agnews/zs 2000\n",
            "loading zs data costs 57.74440813064575 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/agnews/icl 2000\n",
            "loading icl data costs 81.51330757141113 seconds\n",
            "================= number of both F2T examples: 615\n",
            "================= number of ICL F2T examples: 783\n",
            "================= number of FTZS F2T examples: 787\n",
            "++++++++++++++++ ICL recall to FT: 78.14\n",
            "count_f2t costs 0.004071235656738281 seconds\n",
            "============================== analyzing self_attn_out_hiddens ==============================\n",
            "per-layer updates sim (icl-zs)&(ftzs-zs):\n",
            " [0.0876 0.279  0.2855 0.2968 0.6705 0.2532 0.4551 0.2578 0.2592 0.3619\n",
            " 0.3391 0.3143 0.377  0.408  0.4486 0.3054 0.2978 0.2554 0.2984 0.2587\n",
            " 0.2242 0.0952 0.1002 0.5359]\n",
            "overall updates sim (icl-zs)&(ftzs-zs):\n",
            " 0.311\n",
            "\n",
            "per-layer updates sim (icl-zs)&(random):\n",
            " [-0.0036  0.005   0.0191  0.0197  0.0149  0.0061  0.0068 -0.001   0.0003\n",
            " -0.0031  0.0063  0.0021  0.0002  0.0019 -0.0034 -0.0024 -0.0013 -0.005\n",
            " -0.0042 -0.004  -0.0005  0.006  -0.0056 -0.0058]\n",
            "overall updates sim (icl-zs)&(random):\n",
            " 0.002\n",
            "\n",
            "analyze_sim costs 20.945279121398926 seconds\n",
            "============================== analyzing attn_map, softmax=False ==============================\n",
            "per-layer direct sim (icl)&(zs):\n",
            " [-0.2952  0.2459  0.0676 -0.3539  0.0443  0.2206  0.4865  0.2424  0.2267\n",
            "  0.0823  0.1025 -0.1693 -0.195  -0.1889 -0.3543  0.1721 -0.2649 -0.2501\n",
            "  0.0293  0.5589  0.8034  0.8299  0.9048  0.6947]\n",
            "overall direct sim (icl)&(zs):\n",
            " 0.1517\n",
            "\n",
            "per-layer direct sim (icl)&(ftzs):\n",
            " [-0.2945  0.1722  0.0606 -0.2746  0.108   0.398   0.609   0.6046  0.4597\n",
            "  0.5186  0.6411  0.2562  0.5224  0.466   0.4711  0.6861  0.6237  0.6792\n",
            "  0.6291  0.6214  0.7341  0.8582  0.8567  0.7695]\n",
            "overall direct sim (icl)&(ftzs):\n",
            " 0.4657\n",
            "\n",
            "analyze_attn_map (w/o softmax) costs 312.84694361686707 seconds\n",
            "saving data costs 0.010564088821411133 seconds\n",
            "+ model=2_7b\n",
            "+ task=cb\n",
            "+ python icl_ft/compute_sim.py cb all 2_7b\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/icl_ft/compute_sim.py\", line 73, in <module>\n",
            "    ftzs_info = load_info('ftzs')\n",
            "  File \"/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/icl_ft/compute_sim.py\", line 30, in load_info\n",
            "    with open(f\"{rlt_dir}/record_info.jsonl\", \"r\") as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/cb/ftzs/record_info.jsonl'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://dl.fbaipublicfiles.com/fairseq/models/lm/en_dense_lm_2_7b.tar.gz\" -nc -P \"{gpt_icl_dir}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14wcIarksW-2",
        "outputId": "eb962289-8869-4880-da25-a75511b8833f",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File ‘/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b.tar.gz’ already there; not retrieving.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xvfk \"{base_dir}/gpt_icl/en_dense_lm_2_7b.tar.gz\" -C \"{gpt_icl_dir}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o85pbXihsbpo",
        "outputId": "d23483f7-a115-49d2-c9d1-db2353125eda",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tar: k: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash run.sh en_dense_lm_2_7b gptmodel_xl sst2 32 7 0 \"{icl_base_dir}/output\" \"{icl_base_dir}\" 0.007"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gftvzdsqat0Q",
        "outputId": "51d0fff1-2ab8-495e-f710-52c42c0bdfa1",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst2/ft/record_info.jsonl': No such file or directory\n",
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst2/en_dense_lm_2_7b/0.007': No such file or directory\n",
            "+ SEED=7\n",
            "+ TASK=sst2\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt\n",
            "+ ARCH=gptmodel_xl\n",
            "+ K=32\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst2\n",
            "+ ana_setting=ft\n",
            "+ lr=0.007\n",
            "+ max_epoch=1\n",
            "+ save_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst2/en_dense_lm_2_7b/0.007\n",
            "+ optim_group=attn_kv\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' sst2 = agnews ']'\n",
            "+ '[' sst2 = trec ']'\n",
            "+ '[' sst2 = sst5 ']'\n",
            "+ '[' sst2 = dbpedia ']'\n",
            "+ '[' sst2 = cb ']'\n",
            "+ '[' sst2 = arce ']'\n",
            "+ '[' sst2 = arcc ']'\n",
            "+ '[' sst2 = obqa ']'\n",
            "+ '[' sst2 = hellaswag ']'\n",
            "+ '[' sst2 = storycloze ']'\n",
            "+ '[' sst2 = raceh ']'\n",
            "+ '[' sst2 = racem ']'\n",
            "+ '[' sst2 = nq ']'\n",
            "+ '[' sst2 = webqs ']'\n",
            "+ '[' sst2 = triviaqa ']'\n",
            "+ '[' sst2 = sq2 ']'\n",
            "+ '[' sst2 = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ORI_BSZ=1\n",
            "+ BSZ=2\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_ft --arch gptmodel_xl --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --lr 0.007 --max-epoch 1 --curriculum 1000000 --max-update 1000000 --fp16 --eval-data sst2 --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 7 --reset-dataloader --k 32 --batch-size 1 --batch-size-valid 1 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst2 --ana-setting ft --save-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst2/en_dense_lm_2_7b/0.007 --save-interval 1 --save-interval-updates 1000000 --validate-interval 1000000 --disable-validation --optim-group attn_kv --permut-index 0\n",
            "+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output//train_log_ft.txt\n",
            "2024-03-01 16:04:17 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-01 16:05:29 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-01 16:05:29 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-01 16:05:44.847169: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-01 16:05:44.847232: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-01 16:05:44.849069: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-01 16:05:46.144511: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-01 16:06:01 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 7, 'eval_data': 'sst2', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst2', 'ana_setting': 'ft', 'optim_group': 'attn_kv', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 32, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_xl', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2560, 'decoder_output_dim': 2560, 'decoder_input_dim': 2560, 'decoder_ffn_embed_dim': 10240, 'decoder_layers': 32, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt'}, 'criterion': {'_name': 'fs_ft', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.007]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 7, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1000000, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': None, 'batch_size_valid': 1, 'max_valid_steps': None, 'curriculum': 1000000, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 1000000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.007], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst2/en_dense_lm_2_7b/0.007', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 1000000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=7, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_ft', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=1, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1000000, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=True, max_tokens_valid=None, batch_size_valid='1', max_valid_steps=None, curriculum=1000000, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_xl', max_epoch=1, max_update=1000000, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.007], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst2/en_dense_lm_2_7b/0.007', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=1000000, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='sst2', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst2', ana_setting='ft', optim_group='attn_kv', tokens_per_sample=2048, max_target_positions=None, k=32, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt', no_seed_provided=False, decoder_layers=32, decoder_embed_dim=2560, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2560, decoder_output_dim=2560, decoder_ffn_embed_dim=10240, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-01 16:06:01 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-01 16:06:04 | WARNING | datasets.builder | Reusing dataset glue (/root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
            "100%|██████████| 3/3 [00:00<00:00, 41.81it/s]\n",
            "2024-03-01 16:06:05 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-97f779923451a5e1.arrow\n",
            "2024-03-01 16:07:08 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-01 16:07:13 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2560, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
            "        (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2560, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-01 16:07:13 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-01 16:07:13 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-01 16:07:13 | INFO | fairseq_cli.train | criterion: FewshotFTCriterion\n",
            "2024-03-01 16:07:13 | INFO | fairseq_cli.train | num. shared model params: 2,648,724,480 (num. trained: 2,648,724,480)\n",
            "2024-03-01 16:07:13 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-01 16:07:15 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-01 16:07:15 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 16:07:15 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-01 16:07:15 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 16:07:15 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-01 16:07:15 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 1\n",
            "2024-03-01 16:07:15 | INFO | fairseq.trainer | Preparing to load checkpoint /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst2/en_dense_lm_2_7b/0.007/checkpoint_last.pt\n",
            "2024-03-01 16:07:15 | INFO | fairseq.trainer | No existing checkpoint found /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst2/en_dense_lm_2_7b/0.007/checkpoint_last.pt\n",
            "2024-03-01 16:07:15 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-01 16:07:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 32\n",
            "2024-03-01 16:07:17 | INFO | fairseq.trainer | begin training epoch 1\n",
            "2024-03-01 16:07:17 | INFO | fairseq_cli.train | Start fine-tuning\n",
            "------------ example 0 input str train is [\"Sentence: stock up on silver bullets for director neil marshall 's intense freight train of a film . '  Label:\", \"Sentence: stock up on silver bullets for director neil marshall 's intense freight train of a film . '  Label:\"]\n",
            "------------ example 0 label str train is [' Negative', ' Positive']\n",
            "------------ example 1 input str train is ['Sentence: loathe  Label:', 'Sentence: loathe  Label:']\n",
            "------------ example 1 label str train is [' Negative', ' Positive']\n",
            "------------ example 0 input str valid is [\"Sentence: add yet another hat to a talented head , clooney 's a good director .  Label:\", \"Sentence: add yet another hat to a talented head , clooney 's a good director .  Label:\"]\n",
            "------------ example 0 label str valid is [' Negative', ' Positive']\n",
            "------------ example 1 input str valid is ['Sentence: an unclassifiably awful study in self - and audience-abuse .  Label:', 'Sentence: an unclassifiably awful study in self - and audience-abuse .  Label:']\n",
            "------------ example 1 label str valid is [' Negative', ' Positive']\n",
            "NOTE: true K of baseline is 32, max valid len is 68\n",
            "------------ example 0 input str train is [\"Sentence: stock up on silver bullets for director neil marshall 's intense freight train of a film . '  Label:\", \"Sentence: stock up on silver bullets for director neil marshall 's intense freight train of a film . '  Label:\"]\n",
            "------------ example 0 label str train is [' Negative', ' Positive']\n",
            "------------ example 1 input str train is ['Sentence: loathe  Label:', 'Sentence: loathe  Label:']\n",
            "------------ example 1 label str train is [' Negative', ' Positive']\n",
            "NOTE: true K of baseline is 32\n",
            "| Loaded valid with 1744 samples\n",
            "| Loaded train with 32 samples\n",
            "2024-03-01 16:07:21 | INFO | train_inner | epoch 001:      1 / 32 loss=8.392, sample_size=28, ntokens=29, wps=0, ups=0, wpb=29, bsz=1, num_updates=1, lr=0.007, gnorm=15.912, loss_scale=4, train_wall=3, gb_free=26.1, wall=5\n",
            "2024-03-01 16:07:22 | INFO | train_inner | epoch 001:      2 / 32 loss=9.145, sample_size=9, ntokens=10, wps=12.3, ups=1.23, wpb=10, bsz=1, num_updates=2, lr=0.007, gnorm=23.654, loss_scale=4, train_wall=1, gb_free=25.8, wall=6\n",
            "2024-03-01 16:07:23 | INFO | train_inner | epoch 001:      3 / 32 loss=5.725, sample_size=19, ntokens=20, wps=15.1, ups=0.75, wpb=20, bsz=1, num_updates=3, lr=0.007, gnorm=10.082, loss_scale=4, train_wall=1, gb_free=25.8, wall=7\n",
            "2024-03-01 16:07:25 | INFO | train_inner | epoch 001:      4 / 32 loss=5.025, sample_size=33, ntokens=34, wps=15.8, ups=0.47, wpb=34, bsz=1, num_updates=4, lr=0.007, gnorm=8.814, loss_scale=4, train_wall=2, gb_free=25.8, wall=10\n",
            "2024-03-01 16:07:26 | INFO | train_inner | epoch 001:      5 / 32 loss=6.583, sample_size=13, ntokens=14, wps=14.8, ups=1.06, wpb=14, bsz=1, num_updates=5, lr=0.007, gnorm=13.191, loss_scale=4, train_wall=1, gb_free=25.8, wall=11\n",
            "2024-03-01 16:07:28 | INFO | train_inner | epoch 001:      6 / 32 loss=5.803, sample_size=27, ntokens=28, wps=16.3, ups=0.58, wpb=28, bsz=1, num_updates=6, lr=0.007, gnorm=10.412, loss_scale=4, train_wall=2, gb_free=25.8, wall=12\n",
            "2024-03-01 16:07:29 | INFO | train_inner | epoch 001:      7 / 32 loss=5.47, sample_size=11, ntokens=12, wps=14.5, ups=1.2, wpb=12, bsz=1, num_updates=7, lr=0.007, gnorm=17.039, loss_scale=4, train_wall=1, gb_free=25.8, wall=13\n",
            "2024-03-01 16:07:29 | INFO | train_inner | epoch 001:      8 / 32 loss=5.974, sample_size=10, ntokens=11, wps=14.4, ups=1.31, wpb=11, bsz=1, num_updates=8, lr=0.007, gnorm=33.356, loss_scale=4, train_wall=1, gb_free=25.8, wall=14\n",
            "2024-03-01 16:07:30 | INFO | train_inner | epoch 001:      9 / 32 loss=5.986, sample_size=10, ntokens=11, wps=14.4, ups=1.31, wpb=11, bsz=1, num_updates=9, lr=0.007, gnorm=17.269, loss_scale=4, train_wall=1, gb_free=25.8, wall=15\n",
            "2024-03-01 16:07:31 | INFO | train_inner | epoch 001:     10 / 32 loss=3.728, sample_size=9, ntokens=10, wps=14.1, ups=1.41, wpb=10, bsz=1, num_updates=10, lr=0.007, gnorm=21.732, loss_scale=4, train_wall=1, gb_free=25.8, wall=15\n",
            "2024-03-01 16:07:32 | INFO | train_inner | epoch 001:     11 / 32 loss=5.106, sample_size=20, ntokens=21, wps=15.8, ups=0.75, wpb=21, bsz=1, num_updates=11, lr=0.007, gnorm=21.45, loss_scale=4, train_wall=1, gb_free=25.8, wall=17\n",
            "2024-03-01 16:07:33 | INFO | train_inner | epoch 001:     12 / 32 loss=4.867, sample_size=12, ntokens=13, wps=14.7, ups=1.13, wpb=13, bsz=1, num_updates=12, lr=0.007, gnorm=16.427, loss_scale=4, train_wall=1, gb_free=25.8, wall=18\n",
            "2024-03-01 16:07:34 | INFO | train_inner | epoch 001:     13 / 32 loss=3.774, sample_size=13, ntokens=14, wps=14.8, ups=1.06, wpb=14, bsz=1, num_updates=13, lr=0.007, gnorm=14.415, loss_scale=4, train_wall=1, gb_free=25.8, wall=18\n",
            "2024-03-01 16:07:36 | INFO | train_inner | epoch 001:     14 / 32 loss=5.895, sample_size=25, ntokens=26, wps=16.1, ups=0.62, wpb=26, bsz=1, num_updates=14, lr=0.007, gnorm=12.805, loss_scale=4, train_wall=2, gb_free=25.8, wall=20\n",
            "2024-03-01 16:07:37 | INFO | train_inner | epoch 001:     15 / 32 loss=5.236, sample_size=22, ntokens=23, wps=15.9, ups=0.69, wpb=23, bsz=1, num_updates=15, lr=0.007, gnorm=11.261, loss_scale=4, train_wall=1, gb_free=25.8, wall=22\n",
            "2024-03-01 16:07:39 | INFO | train_inner | epoch 001:     16 / 32 loss=4.93, sample_size=29, ntokens=30, wps=16, ups=0.53, wpb=30, bsz=1, num_updates=16, lr=0.007, gnorm=15.904, loss_scale=4, train_wall=2, gb_free=25.8, wall=23\n",
            "2024-03-01 16:07:40 | INFO | train_inner | epoch 001:     17 / 32 loss=3.088, sample_size=10, ntokens=11, wps=14.2, ups=1.29, wpb=11, bsz=1, num_updates=17, lr=0.007, gnorm=13.424, loss_scale=4, train_wall=1, gb_free=25.8, wall=24\n",
            "2024-03-01 16:07:41 | INFO | train_inner | epoch 001:     18 / 32 loss=4.325, sample_size=25, ntokens=26, wps=16.3, ups=0.63, wpb=26, bsz=1, num_updates=18, lr=0.007, gnorm=12.607, loss_scale=4, train_wall=2, gb_free=25.8, wall=26\n",
            "2024-03-01 16:07:42 | INFO | train_inner | epoch 001:     19 / 32 loss=2.304, sample_size=10, ntokens=11, wps=14.4, ups=1.31, wpb=11, bsz=1, num_updates=19, lr=0.007, gnorm=10.162, loss_scale=4, train_wall=1, gb_free=25.8, wall=27\n",
            "2024-03-01 16:07:43 | INFO | train_inner | epoch 001:     20 / 32 loss=3.138, sample_size=12, ntokens=13, wps=15, ups=1.15, wpb=13, bsz=1, num_updates=20, lr=0.007, gnorm=13.077, loss_scale=4, train_wall=1, gb_free=25.8, wall=27\n",
            "2024-03-01 16:07:44 | INFO | train_inner | epoch 001:     21 / 32 loss=2.565, sample_size=9, ntokens=10, wps=14, ups=1.4, wpb=10, bsz=1, num_updates=21, lr=0.007, gnorm=11.098, loss_scale=4, train_wall=1, gb_free=25.8, wall=28\n",
            "2024-03-01 16:07:44 | INFO | train_inner | epoch 001:     22 / 32 loss=3.186, sample_size=8, ntokens=9, wps=13.8, ups=1.54, wpb=9, bsz=1, num_updates=22, lr=0.007, gnorm=21.097, loss_scale=4, train_wall=1, gb_free=25.8, wall=29\n",
            "2024-03-01 16:07:46 | INFO | train_inner | epoch 001:     23 / 32 loss=5.113, sample_size=29, ntokens=30, wps=16.2, ups=0.54, wpb=30, bsz=1, num_updates=23, lr=0.007, gnorm=21.452, loss_scale=4, train_wall=2, gb_free=25.8, wall=31\n",
            "2024-03-01 16:07:48 | INFO | train_inner | epoch 001:     24 / 32 loss=5.787, sample_size=24, ntokens=25, wps=15.3, ups=0.61, wpb=25, bsz=1, num_updates=24, lr=0.007, gnorm=11.207, loss_scale=4, train_wall=2, gb_free=25.8, wall=32\n",
            "2024-03-01 16:07:48 | INFO | train_inner | epoch 001:     25 / 32 loss=3.877, sample_size=10, ntokens=11, wps=14.6, ups=1.33, wpb=11, bsz=1, num_updates=25, lr=0.007, gnorm=12.59, loss_scale=4, train_wall=1, gb_free=25.8, wall=33\n",
            "2024-03-01 16:07:50 | INFO | train_inner | epoch 001:     26 / 32 loss=4.686, sample_size=25, ntokens=26, wps=16.2, ups=0.62, wpb=26, bsz=1, num_updates=26, lr=0.007, gnorm=10.28, loss_scale=4, train_wall=2, gb_free=25.8, wall=35\n",
            "2024-03-01 16:07:53 | INFO | train_inner | epoch 001:     27 / 32 loss=7.64, sample_size=40, ntokens=41, wps=16.3, ups=0.4, wpb=41, bsz=1, num_updates=27, lr=0.007, gnorm=12.799, loss_scale=4, train_wall=3, gb_free=25.8, wall=37\n",
            "2024-03-01 16:07:54 | INFO | train_inner | epoch 001:     28 / 32 loss=3.281, sample_size=10, ntokens=11, wps=6.7, ups=0.61, wpb=11, bsz=1, num_updates=28, lr=0.007, gnorm=17.025, loss_scale=4, train_wall=2, gb_free=25.8, wall=39\n",
            "2024-03-01 16:07:55 | INFO | train_inner | epoch 001:     29 / 32 loss=4.634, sample_size=12, ntokens=13, wps=15, ups=1.16, wpb=13, bsz=1, num_updates=29, lr=0.007, gnorm=12.514, loss_scale=4, train_wall=1, gb_free=25.8, wall=40\n",
            "2024-03-01 16:07:57 | INFO | train_inner | epoch 001:     30 / 32 loss=5.455, sample_size=24, ntokens=25, wps=16, ups=0.64, wpb=25, bsz=1, num_updates=30, lr=0.007, gnorm=9.924, loss_scale=4, train_wall=2, gb_free=25.8, wall=41\n",
            "2024-03-01 16:07:57 | INFO | train_inner | epoch 001:     31 / 32 loss=2.047, sample_size=8, ntokens=9, wps=13.9, ups=1.54, wpb=9, bsz=1, num_updates=31, lr=0.007, gnorm=10.188, loss_scale=4, train_wall=1, gb_free=25.8, wall=42\n",
            "2024-03-01 16:07:58 | INFO | train_inner | epoch 001:     32 / 32 loss=3.059, sample_size=9, ntokens=10, wps=13.9, ups=1.39, wpb=10, bsz=1, num_updates=32, lr=0.007, gnorm=10.594, loss_scale=4, train_wall=1, gb_free=25.8, wall=43\n",
            "2024-03-01 16:07:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 32 updates\n",
            "2024-03-01 16:07:58 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst2/en_dense_lm_2_7b/0.007/checkpoint1.pt\n",
            "2024-03-01 16:08:38 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst2/en_dense_lm_2_7b/0.007/checkpoint1.pt\n",
            "2024-03-01 16:09:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst2/en_dense_lm_2_7b/0.007/checkpoint1.pt (epoch 1 @ 32 updates, score None) (writing took 78.68169811499865 seconds)\n",
            "2024-03-01 16:09:17 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
            "2024-03-01 16:09:17 | INFO | train | epoch 001 | loss 5.266 | sample_size 17.344 | ntokens 18.344 | wps 4.8 | ups 0.27 | wpb 18.3 | bsz 1 | num_updates 32 | lr 0.007 | gnorm 14.805 | loss_scale 4 | train_wall 41 | gb_free 25.8 | wall 121\n",
            "2024-03-01 16:09:17 | INFO | fairseq_cli.train | done training in 119.6 seconds\n",
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst2/ftzs/record_info.jsonl': No such file or directory\n",
            "+ SEED=7\n",
            "+ TASK=sst2\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst2/en_dense_lm_2_7b/0.007/checkpoint_last.pt\n",
            "+ ARCH=gptmodel_xl\n",
            "+ K=0\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst2\n",
            "+ ana_setting=ftzs\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' sst2 = agnews ']'\n",
            "+ '[' sst2 = trec ']'\n",
            "+ '[' sst2 = sst5 ']'\n",
            "+ '[' sst2 = dbpedia ']'\n",
            "+ '[' sst2 = cb ']'\n",
            "+ '[' sst2 = arce ']'\n",
            "+ '[' sst2 = arcc ']'\n",
            "+ '[' sst2 = obqa ']'\n",
            "+ '[' sst2 = hellaswag ']'\n",
            "+ '[' sst2 = storycloze ']'\n",
            "+ '[' sst2 = raceh ']'\n",
            "+ '[' sst2 = racem ']'\n",
            "+ '[' sst2 = nq ']'\n",
            "+ '[' sst2 = webqs ']'\n",
            "+ '[' sst2 = triviaqa ']'\n",
            "+ '[' sst2 = sq2 ']'\n",
            "+ '[' sst2 = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ BSZ=2\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_eval --arch gptmodel_xl --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --max-epoch 1 --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --max-update 0 --fp16 --eval-data sst2 --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 7 --reset-dataloader --no-save --k 0 --batch-size 2 --batch-size-valid 2 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst2/en_dense_lm_2_7b/0.007/checkpoint_last.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst2 --ana-setting ftzs --permut-index 0\n",
            "+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output//train_log_ftzs.txt\n",
            "2024-03-01 16:09:29 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-01 16:09:30 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-01 16:09:30 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-01 16:09:31.858167: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-01 16:09:31.858215: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-01 16:09:31.859710: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-01 16:09:33.160010: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-01 16:09:35 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 7, 'eval_data': 'sst2', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst2', 'ana_setting': 'ftzs', 'optim_group': 'all', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 0, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_xl', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2560, 'decoder_output_dim': 2560, 'decoder_input_dim': 2560, 'decoder_ffn_embed_dim': 10240, 'decoder_layers': 32, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst2/en_dense_lm_2_7b/0.007/checkpoint_last.pt'}, 'criterion': {'_name': 'fs_eval', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 7, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 2, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 2, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': True, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=7, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_eval', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=2, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid='2', max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_xl', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.25], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=True, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='sst2', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst2', ana_setting='ftzs', optim_group='all', tokens_per_sample=2048, max_target_positions=None, k=0, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst2/en_dense_lm_2_7b/0.007/checkpoint_last.pt', no_seed_provided=False, decoder_layers=32, decoder_embed_dim=2560, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2560, decoder_output_dim=2560, decoder_ffn_embed_dim=10240, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-01 16:09:35 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-01 16:09:37 | WARNING | datasets.builder | Reusing dataset glue (/root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
            "100%|██████████| 3/3 [00:00<00:00, 55.36it/s]\n",
            "2024-03-01 16:09:37 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-1d2026950fa1952d.arrow\n",
            "2024-03-01 16:09:37 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-97f779923451a5e1.arrow\n",
            "2024-03-01 16:10:52 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-01 16:10:54 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2560, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
            "        (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2560, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-01 16:10:54 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-01 16:10:54 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-01 16:10:54 | INFO | fairseq_cli.train | criterion: FewshotEvalCriterion\n",
            "2024-03-01 16:10:54 | INFO | fairseq_cli.train | num. shared model params: 2,648,724,480 (num. trained: 2,560)\n",
            "2024-03-01 16:10:54 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-01 16:10:57 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-01 16:10:57 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 16:10:57 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-01 16:10:57 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 16:10:57 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-01 16:10:57 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 2\n",
            "2024-03-01 16:10:57 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt\n",
            "2024-03-01 16:10:57 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last.pt\n",
            "2024-03-01 16:10:57 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-01 16:10:58 | INFO | fairseq_cli.train | Start validating\n",
            "2024-03-01 16:10:58 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "------------ example 0 input str valid is [\"Sentence: add yet another hat to a talented head , clooney 's a good director .  Label:\", \"Sentence: add yet another hat to a talented head , clooney 's a good director .  Label:\"]\n",
            "------------ example 0 label str valid is [' Negative', ' Positive']\n",
            "------------ example 1 input str valid is ['Sentence: an unclassifiably awful study in self - and audience-abuse .  Label:', 'Sentence: an unclassifiably awful study in self - and audience-abuse .  Label:']\n",
            "------------ example 1 label str valid is [' Negative', ' Positive']\n",
            "NOTE: true K of baseline is 0, max valid len is 68\n",
            "| Loaded valid with 1744 samples\n",
            "| Loaded train with 1744 samples\n",
            "2024-03-01 16:13:33 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 0.954 | nll_loss 0.015 | accuracy 76.8 | f1 0 | pos_proportion 49.1 | neg_proportion 50.9 | wps 349.8 | wpb 61.7 | bsz 1 | num_updates 0\n",
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst2/zs/record_info.jsonl': No such file or directory\n",
            "+ SEED=7\n",
            "+ TASK=sst2\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt\n",
            "+ ARCH=gptmodel_xl\n",
            "+ K=0\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst2\n",
            "+ ana_setting=zs\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' sst2 = agnews ']'\n",
            "+ '[' sst2 = trec ']'\n",
            "+ '[' sst2 = sst5 ']'\n",
            "+ '[' sst2 = dbpedia ']'\n",
            "+ '[' sst2 = cb ']'\n",
            "+ '[' sst2 = arce ']'\n",
            "+ '[' sst2 = arcc ']'\n",
            "+ '[' sst2 = obqa ']'\n",
            "+ '[' sst2 = hellaswag ']'\n",
            "+ '[' sst2 = storycloze ']'\n",
            "+ '[' sst2 = raceh ']'\n",
            "+ '[' sst2 = racem ']'\n",
            "+ '[' sst2 = nq ']'\n",
            "+ '[' sst2 = webqs ']'\n",
            "+ '[' sst2 = triviaqa ']'\n",
            "+ '[' sst2 = sq2 ']'\n",
            "+ '[' sst2 = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ BSZ=2\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_eval --arch gptmodel_xl --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --max-epoch 1 --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --max-update 0 --fp16 --eval-data sst2 --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 7 --reset-dataloader --no-save --k 0 --batch-size 2 --batch-size-valid 2 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst2 --ana-setting zs --permut-index 0\n",
            "+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output//train_log_zs.txt\n",
            "2024-03-01 16:13:50 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-01 16:13:50 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-01 16:13:50 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-01 16:13:52.531656: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-01 16:13:52.531703: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-01 16:13:52.533679: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-01 16:13:53.906480: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-01 16:14:00 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 7, 'eval_data': 'sst2', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst2', 'ana_setting': 'zs', 'optim_group': 'all', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 0, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_xl', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2560, 'decoder_output_dim': 2560, 'decoder_input_dim': 2560, 'decoder_ffn_embed_dim': 10240, 'decoder_layers': 32, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt'}, 'criterion': {'_name': 'fs_eval', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 7, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 2, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 2, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': True, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=7, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_eval', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=2, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid='2', max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_xl', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.25], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=True, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='sst2', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst2', ana_setting='zs', optim_group='all', tokens_per_sample=2048, max_target_positions=None, k=0, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt', no_seed_provided=False, decoder_layers=32, decoder_embed_dim=2560, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2560, decoder_output_dim=2560, decoder_ffn_embed_dim=10240, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-01 16:14:00 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-01 16:14:02 | WARNING | datasets.builder | Reusing dataset glue (/root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
            "100%|██████████| 3/3 [00:00<00:00, 595.44it/s]\n",
            "2024-03-01 16:14:02 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-1d2026950fa1952d.arrow\n",
            "2024-03-01 16:14:02 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-97f779923451a5e1.arrow\n",
            "2024-03-01 16:15:09 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-01 16:15:12 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2560, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
            "        (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2560, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-01 16:15:12 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-01 16:15:12 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-01 16:15:12 | INFO | fairseq_cli.train | criterion: FewshotEvalCriterion\n",
            "2024-03-01 16:15:12 | INFO | fairseq_cli.train | num. shared model params: 2,648,724,480 (num. trained: 2,560)\n",
            "2024-03-01 16:15:12 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-01 16:15:15 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-01 16:15:15 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 16:15:15 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-01 16:15:15 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 16:15:15 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-01 16:15:15 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 2\n",
            "2024-03-01 16:15:15 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt\n",
            "2024-03-01 16:15:15 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last.pt\n",
            "2024-03-01 16:15:15 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-01 16:15:16 | INFO | fairseq_cli.train | Start validating\n",
            "2024-03-01 16:15:16 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "------------ example 0 input str valid is [\"Sentence: add yet another hat to a talented head , clooney 's a good director .  Label:\", \"Sentence: add yet another hat to a talented head , clooney 's a good director .  Label:\"]\n",
            "------------ example 0 label str valid is [' Negative', ' Positive']\n",
            "------------ example 1 input str valid is ['Sentence: an unclassifiably awful study in self - and audience-abuse .  Label:', 'Sentence: an unclassifiably awful study in self - and audience-abuse .  Label:']\n",
            "------------ example 1 label str valid is [' Negative', ' Positive']\n",
            "NOTE: true K of baseline is 0, max valid len is 68\n",
            "| Loaded valid with 1744 samples\n",
            "| Loaded train with 1744 samples\n",
            "2024-03-01 16:16:58 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 15.905 | nll_loss 0.258 | accuracy 71.2 | f1 0 | pos_proportion 49.1 | neg_proportion 50.9 | wps 534.1 | wpb 61.7 | bsz 1 | num_updates 0\n",
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst2/icl/record_info.jsonl': No such file or directory\n",
            "+ SEED=7\n",
            "+ TASK=sst2\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt\n",
            "+ ARCH=gptmodel_xl\n",
            "+ K=32\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst2\n",
            "+ ana_setting=icl\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' sst2 = agnews ']'\n",
            "+ '[' sst2 = trec ']'\n",
            "+ '[' sst2 = sst5 ']'\n",
            "+ '[' sst2 = dbpedia ']'\n",
            "+ '[' sst2 = cb ']'\n",
            "+ '[' sst2 = arce ']'\n",
            "+ '[' sst2 = arcc ']'\n",
            "+ '[' sst2 = obqa ']'\n",
            "+ '[' sst2 = hellaswag ']'\n",
            "+ '[' sst2 = storycloze ']'\n",
            "+ '[' sst2 = raceh ']'\n",
            "+ '[' sst2 = racem ']'\n",
            "+ '[' sst2 = nq ']'\n",
            "+ '[' sst2 = webqs ']'\n",
            "+ '[' sst2 = triviaqa ']'\n",
            "+ '[' sst2 = sq2 ']'\n",
            "+ '[' sst2 = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ BSZ=2\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_eval --arch gptmodel_xl --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --max-epoch 1 --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --max-update 0 --fp16 --eval-data sst2 --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 7 --reset-dataloader --no-save --k 32 --batch-size 2 --batch-size-valid 2 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst2 --ana-setting icl --permut-index 0\n",
            "+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output//train_log_icl.txt\n",
            "2024-03-01 16:17:15 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-01 16:17:16 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-01 16:17:16 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-01 16:17:17.859608: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-01 16:17:17.859653: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-01 16:17:17.861422: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-01 16:17:19.089989: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-01 16:17:21 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 7, 'eval_data': 'sst2', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst2', 'ana_setting': 'icl', 'optim_group': 'all', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 32, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_xl', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2560, 'decoder_output_dim': 2560, 'decoder_input_dim': 2560, 'decoder_ffn_embed_dim': 10240, 'decoder_layers': 32, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt'}, 'criterion': {'_name': 'fs_eval', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 7, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 2, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 2, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': True, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=7, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_eval', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=2, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid='2', max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_xl', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.25], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=True, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='sst2', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst2', ana_setting='icl', optim_group='all', tokens_per_sample=2048, max_target_positions=None, k=32, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt', no_seed_provided=False, decoder_layers=32, decoder_embed_dim=2560, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2560, decoder_output_dim=2560, decoder_ffn_embed_dim=10240, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-01 16:17:21 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-01 16:17:22 | WARNING | datasets.builder | Reusing dataset glue (/root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
            "100%|██████████| 3/3 [00:00<00:00, 736.53it/s]\n",
            "2024-03-01 16:17:22 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-1d2026950fa1952d.arrow\n",
            "2024-03-01 16:17:22 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-97f779923451a5e1.arrow\n",
            "2024-03-01 16:18:26 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-01 16:18:28 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2560, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
            "        (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2560, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-01 16:18:28 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-01 16:18:28 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-01 16:18:28 | INFO | fairseq_cli.train | criterion: FewshotEvalCriterion\n",
            "2024-03-01 16:18:28 | INFO | fairseq_cli.train | num. shared model params: 2,648,724,480 (num. trained: 2,560)\n",
            "2024-03-01 16:18:28 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-01 16:18:31 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-01 16:18:31 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 16:18:31 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-01 16:18:31 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 16:18:31 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-01 16:18:31 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 2\n",
            "2024-03-01 16:18:31 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt\n",
            "2024-03-01 16:18:31 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last.pt\n",
            "2024-03-01 16:18:31 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-01 16:18:31 | INFO | fairseq_cli.train | Start validating\n",
            "2024-03-01 16:18:31 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "------------ example 0 input str train is [\"Sentence: stock up on silver bullets for director neil marshall 's intense freight train of a film . '  Label:\", \"Sentence: stock up on silver bullets for director neil marshall 's intense freight train of a film . '  Label:\"]\n",
            "------------ example 0 label str train is [' Negative', ' Positive']\n",
            "------------ example 1 input str train is ['Sentence: loathe  Label:', 'Sentence: loathe  Label:']\n",
            "------------ example 1 label str train is [' Negative', ' Positive']\n",
            "------------ example 0 input str valid is [\"Sentence: add yet another hat to a talented head , clooney 's a good director .  Label:\", \"Sentence: add yet another hat to a talented head , clooney 's a good director .  Label:\"]\n",
            "------------ example 0 label str valid is [' Negative', ' Positive']\n",
            "------------ example 1 input str valid is ['Sentence: an unclassifiably awful study in self - and audience-abuse .  Label:', 'Sentence: an unclassifiably awful study in self - and audience-abuse .  Label:']\n",
            "------------ example 1 label str valid is [' Negative', ' Positive']\n",
            "NOTE: true K of baseline is 32, max valid len is 68\n",
            "| Loaded valid with 1744 samples\n",
            "| Loaded train with 1744 samples\n",
            "2024-03-01 16:20:29 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 0.342 | nll_loss 0 | accuracy 94.8 | f1 0 | pos_proportion 49.1 | neg_proportion 50.9 | wps 9222.8 | wpb 1235.7 | bsz 1 | num_updates 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash run.sh en_dense_lm_2_7b gptmodel_xl sst5 32 5 0 \"{icl_base_dir}/output\" \"{icl_base_dir}\" 0.04"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7FuShCmuG1Q",
        "outputId": "e35076dc-753d-4054-bab5-2d68bbb90314",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst5/ft/record_info.jsonl': No such file or directory\n",
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst5/en_dense_lm_2_7b/0.04': No such file or directory\n",
            "+ SEED=5\n",
            "+ TASK=sst5\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt\n",
            "+ ARCH=gptmodel_xl\n",
            "+ K=32\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst5\n",
            "+ ana_setting=ft\n",
            "+ lr=0.04\n",
            "+ max_epoch=1\n",
            "+ save_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst5/en_dense_lm_2_7b/0.04\n",
            "+ optim_group=attn_kv\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' sst5 = agnews ']'\n",
            "+ '[' sst5 = trec ']'\n",
            "+ '[' sst5 = sst5 ']'\n",
            "+ N_CLASSES=5\n",
            "+ '[' sst5 = dbpedia ']'\n",
            "+ '[' sst5 = cb ']'\n",
            "+ '[' sst5 = arce ']'\n",
            "+ '[' sst5 = arcc ']'\n",
            "+ '[' sst5 = obqa ']'\n",
            "+ '[' sst5 = hellaswag ']'\n",
            "+ '[' sst5 = storycloze ']'\n",
            "+ '[' sst5 = raceh ']'\n",
            "+ '[' sst5 = racem ']'\n",
            "+ '[' sst5 = nq ']'\n",
            "+ '[' sst5 = webqs ']'\n",
            "+ '[' sst5 = triviaqa ']'\n",
            "+ '[' sst5 = sq2 ']'\n",
            "+ '[' sst5 = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ORI_BSZ=1\n",
            "+ BSZ=5\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_ft --arch gptmodel_xl --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --lr 0.04 --max-epoch 1 --curriculum 1000000 --max-update 1000000 --fp16 --eval-data sst5 --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 5 --reset-dataloader --k 32 --batch-size 1 --batch-size-valid 1 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst5 --ana-setting ft --save-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst5/en_dense_lm_2_7b/0.04 --save-interval 1 --save-interval-updates 1000000 --validate-interval 1000000 --disable-validation --optim-group attn_kv --permut-index 0\n",
            "+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output//train_log_ft.txt\n",
            "2024-03-01 16:20:40 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-01 16:20:41 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-01 16:20:41 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-01 16:20:42.303088: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-01 16:20:42.303130: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-01 16:20:42.304859: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-01 16:20:43.575192: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-01 16:20:45 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 5, 'eval_data': 'sst5', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst5', 'ana_setting': 'ft', 'optim_group': 'attn_kv', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 32, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_xl', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2560, 'decoder_output_dim': 2560, 'decoder_input_dim': 2560, 'decoder_ffn_embed_dim': 10240, 'decoder_layers': 32, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt'}, 'criterion': {'_name': 'fs_ft', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.04]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 5, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1000000, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': None, 'batch_size_valid': 1, 'max_valid_steps': None, 'curriculum': 1000000, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 1000000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.04], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst5/en_dense_lm_2_7b/0.04', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 1000000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=5, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_ft', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=1, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1000000, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=True, max_tokens_valid=None, batch_size_valid='1', max_valid_steps=None, curriculum=1000000, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_xl', max_epoch=1, max_update=1000000, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.04], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst5/en_dense_lm_2_7b/0.04', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=1000000, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='sst5', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst5', ana_setting='ft', optim_group='attn_kv', tokens_per_sample=2048, max_target_positions=None, k=32, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt', no_seed_provided=False, decoder_layers=32, decoder_embed_dim=2560, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2560, decoder_output_dim=2560, decoder_ffn_embed_dim=10240, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-01 16:20:45 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-01 16:20:48 | WARNING | datasets.builder | Using custom data configuration SetFit--sst5-0c891184cb873f87\n",
            "2024-03-01 16:20:48 | WARNING | datasets.builder | Reusing dataset json (/root/.cache/huggingface/datasets/SetFit___json/SetFit--sst5-0c891184cb873f87/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253)\n",
            "100%|██████████| 3/3 [00:00<00:00, 147.01it/s]\n",
            "2024-03-01 16:20:48 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/SetFit___json/SetFit--sst5-0c891184cb873f87/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-085d282a8e30d5e1.arrow\n",
            "2024-03-01 16:20:48 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/SetFit___json/SetFit--sst5-0c891184cb873f87/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-f1a26c00e694c55c.arrow\n",
            "2024-03-01 16:21:53 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-01 16:21:55 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2560, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
            "        (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2560, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-01 16:21:55 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-01 16:21:55 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-01 16:21:55 | INFO | fairseq_cli.train | criterion: FewshotFTCriterion\n",
            "2024-03-01 16:21:55 | INFO | fairseq_cli.train | num. shared model params: 2,648,724,480 (num. trained: 2,648,724,480)\n",
            "2024-03-01 16:21:55 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-01 16:21:58 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-01 16:21:58 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 16:21:58 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-01 16:21:58 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 16:21:58 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-01 16:21:58 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 1\n",
            "2024-03-01 16:21:58 | INFO | fairseq.trainer | Preparing to load checkpoint /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst5/en_dense_lm_2_7b/0.04/checkpoint_last.pt\n",
            "2024-03-01 16:21:58 | INFO | fairseq.trainer | No existing checkpoint found /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst5/en_dense_lm_2_7b/0.04/checkpoint_last.pt\n",
            "2024-03-01 16:21:58 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-01 16:21:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 32\n",
            "2024-03-01 16:21:58 | INFO | fairseq.trainer | begin training epoch 1\n",
            "2024-03-01 16:21:58 | INFO | fairseq_cli.train | Start fine-tuning\n",
            "------------ example 0 input str train is [\"Sentence: an unintentionally surreal kid 's picture ... in which actors in bad bear suits enact a sort of inter-species parody of a vh1 behind the music episode . Label:\", \"Sentence: an unintentionally surreal kid 's picture ... in which actors in bad bear suits enact a sort of inter-species parody of a vh1 behind the music episode . Label:\", \"Sentence: an unintentionally surreal kid 's picture ... in which actors in bad bear suits enact a sort of inter-species parody of a vh1 behind the music episode . Label:\", \"Sentence: an unintentionally surreal kid 's picture ... in which actors in bad bear suits enact a sort of inter-species parody of a vh1 behind the music episode . Label:\", \"Sentence: an unintentionally surreal kid 's picture ... in which actors in bad bear suits enact a sort of inter-species parody of a vh1 behind the music episode . Label:\"]\n",
            "------------ example 0 label str train is [' terrible', ' bad', ' neutral', ' good', ' great']\n",
            "------------ example 1 input str train is [\"Sentence: twenty-three movies into a mostly magnificent directorial career , clint eastwood 's efficiently minimalist style finally has failed him . Label:\", \"Sentence: twenty-three movies into a mostly magnificent directorial career , clint eastwood 's efficiently minimalist style finally has failed him . Label:\", \"Sentence: twenty-three movies into a mostly magnificent directorial career , clint eastwood 's efficiently minimalist style finally has failed him . Label:\", \"Sentence: twenty-three movies into a mostly magnificent directorial career , clint eastwood 's efficiently minimalist style finally has failed him . Label:\", \"Sentence: twenty-three movies into a mostly magnificent directorial career , clint eastwood 's efficiently minimalist style finally has failed him . Label:\"]\n",
            "------------ example 1 label str train is [' terrible', ' bad', ' neutral', ' good', ' great']\n",
            "------------ example 0 input str valid is ['Sentence: no one goes unindicted here , which is probably for the best . Label:', 'Sentence: no one goes unindicted here , which is probably for the best . Label:', 'Sentence: no one goes unindicted here , which is probably for the best . Label:', 'Sentence: no one goes unindicted here , which is probably for the best . Label:', 'Sentence: no one goes unindicted here , which is probably for the best . Label:']\n",
            "------------ example 0 label str valid is [' terrible', ' bad', ' neutral', ' good', ' great']\n",
            "------------ example 1 input str valid is ['Sentence: pumpkin wants to have it both ways . Label:', 'Sentence: pumpkin wants to have it both ways . Label:', 'Sentence: pumpkin wants to have it both ways . Label:', 'Sentence: pumpkin wants to have it both ways . Label:', 'Sentence: pumpkin wants to have it both ways . Label:']\n",
            "------------ example 1 label str valid is [' terrible', ' bad', ' neutral', ' good', ' great']\n",
            "NOTE: true K of baseline is 32, max valid len is 67\n",
            "------------ example 0 input str train is [\"Sentence: an unintentionally surreal kid 's picture ... in which actors in bad bear suits enact a sort of inter-species parody of a vh1 behind the music episode . Label:\", \"Sentence: an unintentionally surreal kid 's picture ... in which actors in bad bear suits enact a sort of inter-species parody of a vh1 behind the music episode . Label:\", \"Sentence: an unintentionally surreal kid 's picture ... in which actors in bad bear suits enact a sort of inter-species parody of a vh1 behind the music episode . Label:\", \"Sentence: an unintentionally surreal kid 's picture ... in which actors in bad bear suits enact a sort of inter-species parody of a vh1 behind the music episode . Label:\", \"Sentence: an unintentionally surreal kid 's picture ... in which actors in bad bear suits enact a sort of inter-species parody of a vh1 behind the music episode . Label:\"]\n",
            "------------ example 0 label str train is [' terrible', ' bad', ' neutral', ' good', ' great']\n",
            "------------ example 1 input str train is [\"Sentence: twenty-three movies into a mostly magnificent directorial career , clint eastwood 's efficiently minimalist style finally has failed him . Label:\", \"Sentence: twenty-three movies into a mostly magnificent directorial career , clint eastwood 's efficiently minimalist style finally has failed him . Label:\", \"Sentence: twenty-three movies into a mostly magnificent directorial career , clint eastwood 's efficiently minimalist style finally has failed him . Label:\", \"Sentence: twenty-three movies into a mostly magnificent directorial career , clint eastwood 's efficiently minimalist style finally has failed him . Label:\", \"Sentence: twenty-three movies into a mostly magnificent directorial career , clint eastwood 's efficiently minimalist style finally has failed him . Label:\"]\n",
            "------------ example 1 label str train is [' terrible', ' bad', ' neutral', ' good', ' great']\n",
            "NOTE: true K of baseline is 32\n",
            "| Loaded valid with 5505 samples\n",
            "| Loaded train with 32 samples\n",
            "2024-03-01 16:22:02 | INFO | train_inner | epoch 001:      1 / 32 loss=7.795, sample_size=39, ntokens=40, wps=0, ups=0, wpb=40, bsz=1, num_updates=1, lr=0.04, gnorm=10.729, loss_scale=4, train_wall=4, gb_free=26.1, wall=4\n",
            "2024-03-01 16:22:04 | INFO | train_inner | epoch 001:      2 / 32 loss=7.63, sample_size=32, ntokens=33, wps=15.1, ups=0.46, wpb=33, bsz=1, num_updates=2, lr=0.04, gnorm=22.823, loss_scale=4, train_wall=2, gb_free=25.8, wall=6\n",
            "2024-03-01 16:22:05 | INFO | train_inner | epoch 001:      3 / 32 loss=8.044, sample_size=15, ntokens=16, wps=14, ups=0.88, wpb=16, bsz=1, num_updates=3, lr=0.04, gnorm=21.956, loss_scale=4, train_wall=1, gb_free=25.8, wall=8\n",
            "2024-03-01 16:22:09 | INFO | train_inner | epoch 001:      4 / 32 loss=6.945, sample_size=54, ntokens=55, wps=15.9, ups=0.29, wpb=55, bsz=1, num_updates=4, lr=0.04, gnorm=7.68, loss_scale=4, train_wall=3, gb_free=25.8, wall=11\n",
            "2024-03-01 16:22:10 | INFO | train_inner | epoch 001:      5 / 32 loss=5.384, sample_size=23, ntokens=24, wps=15.6, ups=0.65, wpb=24, bsz=1, num_updates=5, lr=0.04, gnorm=6.848, loss_scale=4, train_wall=2, gb_free=25.8, wall=13\n",
            "2024-03-01 16:22:12 | INFO | train_inner | epoch 001:      6 / 32 loss=4.847, sample_size=27, ntokens=28, wps=15.8, ups=0.56, wpb=28, bsz=1, num_updates=6, lr=0.04, gnorm=6.313, loss_scale=4, train_wall=2, gb_free=25.8, wall=14\n",
            "2024-03-01 16:22:13 | INFO | train_inner | epoch 001:      7 / 32 loss=5.156, sample_size=17, ntokens=18, wps=15.1, ups=0.84, wpb=18, bsz=1, num_updates=7, lr=0.04, gnorm=9.156, loss_scale=4, train_wall=1, gb_free=25.8, wall=16\n",
            "2024-03-01 16:22:15 | INFO | train_inner | epoch 001:      8 / 32 loss=4.887, sample_size=21, ntokens=22, wps=15.4, ups=0.7, wpb=22, bsz=1, num_updates=8, lr=0.04, gnorm=13.234, loss_scale=4, train_wall=1, gb_free=25.8, wall=17\n",
            "2024-03-01 16:22:18 | INFO | train_inner | epoch 001:      9 / 32 loss=5.191, sample_size=50, ntokens=51, wps=16.1, ups=0.32, wpb=51, bsz=1, num_updates=9, lr=0.04, gnorm=9.754, loss_scale=4, train_wall=3, gb_free=25.8, wall=20\n",
            "2024-03-01 16:22:20 | INFO | train_inner | epoch 001:     10 / 32 loss=4.478, sample_size=32, ntokens=33, wps=15.6, ups=0.47, wpb=33, bsz=1, num_updates=10, lr=0.04, gnorm=8.684, loss_scale=4, train_wall=2, gb_free=25.8, wall=22\n",
            "2024-03-01 16:22:22 | INFO | train_inner | epoch 001:     11 / 32 loss=4.755, sample_size=35, ntokens=36, wps=15.7, ups=0.44, wpb=36, bsz=1, num_updates=11, lr=0.04, gnorm=7.237, loss_scale=4, train_wall=2, gb_free=25.8, wall=25\n",
            "2024-03-01 16:22:25 | INFO | train_inner | epoch 001:     12 / 32 loss=4.091, sample_size=43, ntokens=44, wps=15.9, ups=0.36, wpb=44, bsz=1, num_updates=12, lr=0.04, gnorm=6.956, loss_scale=4, train_wall=3, gb_free=25.8, wall=27\n",
            "2024-03-01 16:22:27 | INFO | train_inner | epoch 001:     13 / 32 loss=5.125, sample_size=37, ntokens=38, wps=15.7, ups=0.41, wpb=38, bsz=1, num_updates=13, lr=0.04, gnorm=8.178, loss_scale=4, train_wall=2, gb_free=25.8, wall=30\n",
            "2024-03-01 16:22:29 | INFO | train_inner | epoch 001:     14 / 32 loss=4.936, sample_size=27, ntokens=28, wps=15.9, ups=0.57, wpb=28, bsz=1, num_updates=14, lr=0.04, gnorm=8.254, loss_scale=4, train_wall=2, gb_free=25.8, wall=31\n",
            "2024-03-01 16:22:32 | INFO | train_inner | epoch 001:     15 / 32 loss=4.652, sample_size=35, ntokens=36, wps=15.8, ups=0.44, wpb=36, bsz=1, num_updates=15, lr=0.04, gnorm=7.379, loss_scale=4, train_wall=2, gb_free=25.8, wall=34\n",
            "2024-03-01 16:22:34 | INFO | train_inner | epoch 001:     16 / 32 loss=4.715, sample_size=34, ntokens=35, wps=15.9, ups=0.45, wpb=35, bsz=1, num_updates=16, lr=0.04, gnorm=7.611, loss_scale=4, train_wall=2, gb_free=25.8, wall=36\n",
            "2024-03-01 16:22:36 | INFO | train_inner | epoch 001:     17 / 32 loss=5.942, sample_size=33, ntokens=34, wps=15.7, ups=0.46, wpb=34, bsz=1, num_updates=17, lr=0.04, gnorm=11.067, loss_scale=4, train_wall=2, gb_free=25.8, wall=38\n",
            "2024-03-01 16:22:37 | INFO | train_inner | epoch 001:     18 / 32 loss=3.83, sample_size=15, ntokens=16, wps=15.1, ups=0.95, wpb=16, bsz=1, num_updates=18, lr=0.04, gnorm=11.882, loss_scale=4, train_wall=1, gb_free=25.8, wall=39\n",
            "2024-03-01 16:22:39 | INFO | train_inner | epoch 001:     19 / 32 loss=4.482, sample_size=25, ntokens=26, wps=15.7, ups=0.6, wpb=26, bsz=1, num_updates=19, lr=0.04, gnorm=14.24, loss_scale=4, train_wall=2, gb_free=25.8, wall=41\n",
            "2024-03-01 16:22:40 | INFO | train_inner | epoch 001:     20 / 32 loss=4.541, sample_size=19, ntokens=20, wps=15.5, ups=0.78, wpb=20, bsz=1, num_updates=20, lr=0.04, gnorm=8.156, loss_scale=4, train_wall=1, gb_free=25.8, wall=42\n",
            "2024-03-01 16:22:41 | INFO | train_inner | epoch 001:     21 / 32 loss=4.116, sample_size=22, ntokens=23, wps=15.6, ups=0.68, wpb=23, bsz=1, num_updates=21, lr=0.04, gnorm=7.554, loss_scale=4, train_wall=1, gb_free=25.8, wall=44\n",
            "2024-03-01 16:22:44 | INFO | train_inner | epoch 001:     22 / 32 loss=4.423, sample_size=35, ntokens=36, wps=16, ups=0.44, wpb=36, bsz=1, num_updates=22, lr=0.04, gnorm=5.981, loss_scale=4, train_wall=2, gb_free=25.8, wall=46\n",
            "2024-03-01 16:22:45 | INFO | train_inner | epoch 001:     23 / 32 loss=3.915, sample_size=16, ntokens=17, wps=15.4, ups=0.91, wpb=17, bsz=1, num_updates=23, lr=0.04, gnorm=8.043, loss_scale=4, train_wall=1, gb_free=25.8, wall=47\n",
            "2024-03-01 16:22:47 | INFO | train_inner | epoch 001:     24 / 32 loss=5.038, sample_size=32, ntokens=33, wps=16.1, ups=0.49, wpb=33, bsz=1, num_updates=24, lr=0.04, gnorm=7.537, loss_scale=4, train_wall=2, gb_free=25.8, wall=49\n",
            "2024-03-01 16:22:49 | INFO | train_inner | epoch 001:     25 / 32 loss=4.55, sample_size=28, ntokens=29, wps=15.5, ups=0.53, wpb=29, bsz=1, num_updates=25, lr=0.04, gnorm=6.558, loss_scale=4, train_wall=2, gb_free=25.8, wall=51\n",
            "2024-03-01 16:22:51 | INFO | train_inner | epoch 001:     26 / 32 loss=4.739, sample_size=29, ntokens=30, wps=15.8, ups=0.53, wpb=30, bsz=1, num_updates=26, lr=0.04, gnorm=6.167, loss_scale=4, train_wall=2, gb_free=25.8, wall=53\n",
            "2024-03-01 16:22:52 | INFO | train_inner | epoch 001:     27 / 32 loss=4.435, sample_size=25, ntokens=26, wps=16, ups=0.62, wpb=26, bsz=1, num_updates=27, lr=0.04, gnorm=7.875, loss_scale=4, train_wall=2, gb_free=25.8, wall=54\n",
            "2024-03-01 16:22:54 | INFO | train_inner | epoch 001:     28 / 32 loss=3.61, sample_size=23, ntokens=24, wps=16, ups=0.67, wpb=24, bsz=1, num_updates=28, lr=0.04, gnorm=7.307, loss_scale=4, train_wall=2, gb_free=25.8, wall=56\n",
            "2024-03-01 16:22:57 | INFO | train_inner | epoch 001:     29 / 32 loss=6.4, sample_size=47, ntokens=48, wps=16.4, ups=0.34, wpb=48, bsz=1, num_updates=29, lr=0.04, gnorm=10.884, loss_scale=4, train_wall=3, gb_free=25.8, wall=59\n",
            "2024-03-01 16:22:58 | INFO | train_inner | epoch 001:     30 / 32 loss=4.911, sample_size=26, ntokens=27, wps=15.9, ups=0.59, wpb=27, bsz=1, num_updates=30, lr=0.04, gnorm=6.023, loss_scale=4, train_wall=2, gb_free=25.8, wall=61\n",
            "2024-03-01 16:23:02 | INFO | train_inner | epoch 001:     31 / 32 loss=5.486, sample_size=64, ntokens=65, wps=16.4, ups=0.25, wpb=65, bsz=1, num_updates=31, lr=0.04, gnorm=7.403, loss_scale=4, train_wall=4, gb_free=25.8, wall=64\n",
            "2024-03-01 16:23:04 | INFO | train_inner | epoch 001:     32 / 32 loss=4.753, sample_size=31, ntokens=32, wps=15.9, ups=0.5, wpb=32, bsz=1, num_updates=32, lr=0.04, gnorm=6.55, loss_scale=4, train_wall=2, gb_free=25.8, wall=66\n",
            "2024-03-01 16:23:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 32 updates\n",
            "2024-03-01 16:23:04 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst5/en_dense_lm_2_7b/0.04/checkpoint1.pt\n",
            "2024-03-01 16:24:13 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst5/en_dense_lm_2_7b/0.04/checkpoint1.pt\n",
            "2024-03-01 16:24:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst5/en_dense_lm_2_7b/0.04/checkpoint1.pt (epoch 1 @ 32 updates, score None) (writing took 110.76953153300201 seconds)\n",
            "2024-03-01 16:24:55 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
            "2024-03-01 16:24:55 | INFO | train | epoch 001 | loss 5.234 | sample_size 30.969 | ntokens 31.969 | wps 5.7 | ups 0.18 | wpb 32 | bsz 1 | num_updates 32 | lr 0.04 | gnorm 9.251 | loss_scale 4 | train_wall 66 | gb_free 25.8 | wall 177\n",
            "2024-03-01 16:24:55 | INFO | fairseq_cli.train | done training in 177.0 seconds\n",
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst5/ftzs/record_info.jsonl': No such file or directory\n",
            "+ SEED=5\n",
            "+ TASK=sst5\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst5/en_dense_lm_2_7b/0.04/checkpoint_last.pt\n",
            "+ ARCH=gptmodel_xl\n",
            "+ K=0\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst5\n",
            "+ ana_setting=ftzs\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' sst5 = agnews ']'\n",
            "+ '[' sst5 = trec ']'\n",
            "+ '[' sst5 = sst5 ']'\n",
            "+ N_CLASSES=5\n",
            "+ '[' sst5 = dbpedia ']'\n",
            "+ '[' sst5 = cb ']'\n",
            "+ '[' sst5 = arce ']'\n",
            "+ '[' sst5 = arcc ']'\n",
            "+ '[' sst5 = obqa ']'\n",
            "+ '[' sst5 = hellaswag ']'\n",
            "+ '[' sst5 = storycloze ']'\n",
            "+ '[' sst5 = raceh ']'\n",
            "+ '[' sst5 = racem ']'\n",
            "+ '[' sst5 = nq ']'\n",
            "+ '[' sst5 = webqs ']'\n",
            "+ '[' sst5 = triviaqa ']'\n",
            "+ '[' sst5 = sq2 ']'\n",
            "+ '[' sst5 = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ BSZ=5\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_eval --arch gptmodel_xl --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --max-epoch 1 --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --max-update 0 --fp16 --eval-data sst5 --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 5 --reset-dataloader --no-save --k 0 --batch-size 5 --batch-size-valid 5 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst5/en_dense_lm_2_7b/0.04/checkpoint_last.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst5 --ana-setting ftzs --permut-index 0\n",
            "+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output//train_log_ftzs.txt\n",
            "2024-03-01 16:25:14 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-01 16:25:14 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-01 16:25:14 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-01 16:25:16.137601: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-01 16:25:16.137650: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-01 16:25:16.139443: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-01 16:25:17.438050: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-01 16:25:19 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 5, 'eval_data': 'sst5', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst5', 'ana_setting': 'ftzs', 'optim_group': 'all', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 0, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_xl', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2560, 'decoder_output_dim': 2560, 'decoder_input_dim': 2560, 'decoder_ffn_embed_dim': 10240, 'decoder_layers': 32, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst5/en_dense_lm_2_7b/0.04/checkpoint_last.pt'}, 'criterion': {'_name': 'fs_eval', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 5, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 5, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 5, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': True, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=5, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_eval', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=5, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid='5', max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_xl', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.25], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=True, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='sst5', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst5', ana_setting='ftzs', optim_group='all', tokens_per_sample=2048, max_target_positions=None, k=0, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/sst5/en_dense_lm_2_7b/0.04/checkpoint_last.pt', no_seed_provided=False, decoder_layers=32, decoder_embed_dim=2560, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2560, decoder_output_dim=2560, decoder_ffn_embed_dim=10240, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-01 16:25:20 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-01 16:25:22 | WARNING | datasets.builder | Using custom data configuration SetFit--sst5-0c891184cb873f87\n",
            "2024-03-01 16:25:22 | WARNING | datasets.builder | Reusing dataset json (/root/.cache/huggingface/datasets/SetFit___json/SetFit--sst5-0c891184cb873f87/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253)\n",
            "100%|██████████| 3/3 [00:00<00:00, 246.23it/s]\n",
            "2024-03-01 16:25:22 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/SetFit___json/SetFit--sst5-0c891184cb873f87/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-085d282a8e30d5e1.arrow\n",
            "2024-03-01 16:25:22 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/SetFit___json/SetFit--sst5-0c891184cb873f87/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-f1a26c00e694c55c.arrow\n",
            "2024-03-01 16:27:06 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-01 16:27:08 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2560, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
            "        (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2560, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-01 16:27:08 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-01 16:27:08 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-01 16:27:08 | INFO | fairseq_cli.train | criterion: FewshotEvalCriterion\n",
            "2024-03-01 16:27:08 | INFO | fairseq_cli.train | num. shared model params: 2,648,724,480 (num. trained: 2,560)\n",
            "2024-03-01 16:27:08 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-01 16:27:12 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-01 16:27:12 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 16:27:12 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-01 16:27:12 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 16:27:12 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-01 16:27:12 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 5\n",
            "2024-03-01 16:27:12 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt\n",
            "2024-03-01 16:27:12 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last.pt\n",
            "2024-03-01 16:27:12 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-01 16:27:12 | INFO | fairseq_cli.train | Start validating\n",
            "2024-03-01 16:27:12 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "------------ example 0 input str valid is ['Sentence: no one goes unindicted here , which is probably for the best . Label:', 'Sentence: no one goes unindicted here , which is probably for the best . Label:', 'Sentence: no one goes unindicted here , which is probably for the best . Label:', 'Sentence: no one goes unindicted here , which is probably for the best . Label:', 'Sentence: no one goes unindicted here , which is probably for the best . Label:']\n",
            "------------ example 0 label str valid is [' terrible', ' bad', ' neutral', ' good', ' great']\n",
            "------------ example 1 input str valid is ['Sentence: pumpkin wants to have it both ways . Label:', 'Sentence: pumpkin wants to have it both ways . Label:', 'Sentence: pumpkin wants to have it both ways . Label:', 'Sentence: pumpkin wants to have it both ways . Label:', 'Sentence: pumpkin wants to have it both ways . Label:']\n",
            "------------ example 1 label str valid is [' terrible', ' bad', ' neutral', ' good', ' great']\n",
            "NOTE: true K of baseline is 0, max valid len is 67\n",
            "| Loaded valid with 5505 samples\n",
            "| Loaded train with 5505 samples\n",
            "2024-03-01 16:30:28 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.188 | nll_loss 0.028 | accuracy 36.4 | f1 0 | pos_proportion 12.6 | neg_proportion 26.2 | wps 846 | wpb 149.7 | bsz 1 | num_updates 0\n",
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst5/zs/record_info.jsonl': No such file or directory\n",
            "+ SEED=5\n",
            "+ TASK=sst5\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt\n",
            "+ ARCH=gptmodel_xl\n",
            "+ K=0\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst5\n",
            "+ ana_setting=zs\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' sst5 = agnews ']'\n",
            "+ '[' sst5 = trec ']'\n",
            "+ '[' sst5 = sst5 ']'\n",
            "+ N_CLASSES=5\n",
            "+ '[' sst5 = dbpedia ']'\n",
            "+ '[' sst5 = cb ']'\n",
            "+ '[' sst5 = arce ']'\n",
            "+ '[' sst5 = arcc ']'\n",
            "+ '[' sst5 = obqa ']'\n",
            "+ '[' sst5 = hellaswag ']'\n",
            "+ '[' sst5 = storycloze ']'\n",
            "+ '[' sst5 = raceh ']'\n",
            "+ '[' sst5 = racem ']'\n",
            "+ '[' sst5 = nq ']'\n",
            "+ '[' sst5 = webqs ']'\n",
            "+ '[' sst5 = triviaqa ']'\n",
            "+ '[' sst5 = sq2 ']'\n",
            "+ '[' sst5 = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ BSZ=5\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_eval --arch gptmodel_xl --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --max-epoch 1 --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --max-update 0 --fp16 --eval-data sst5 --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 5 --reset-dataloader --no-save --k 0 --batch-size 5 --batch-size-valid 5 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst5 --ana-setting zs --permut-index 0\n",
            "+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output//train_log_zs.txt\n",
            "2024-03-01 16:31:03 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-01 16:31:04 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-01 16:31:04 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-01 16:31:06.109075: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-01 16:31:06.109123: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-01 16:31:06.110988: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-01 16:31:07.924877: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-01 16:31:10 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 5, 'eval_data': 'sst5', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst5', 'ana_setting': 'zs', 'optim_group': 'all', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 0, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_xl', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2560, 'decoder_output_dim': 2560, 'decoder_input_dim': 2560, 'decoder_ffn_embed_dim': 10240, 'decoder_layers': 32, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt'}, 'criterion': {'_name': 'fs_eval', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 5, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 5, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 5, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': True, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=5, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_eval', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=5, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid='5', max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_xl', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.25], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=True, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='sst5', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst5', ana_setting='zs', optim_group='all', tokens_per_sample=2048, max_target_positions=None, k=0, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt', no_seed_provided=False, decoder_layers=32, decoder_embed_dim=2560, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2560, decoder_output_dim=2560, decoder_ffn_embed_dim=10240, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-01 16:31:10 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-01 16:31:12 | WARNING | datasets.builder | Using custom data configuration SetFit--sst5-0c891184cb873f87\n",
            "2024-03-01 16:31:12 | WARNING | datasets.builder | Reusing dataset json (/root/.cache/huggingface/datasets/SetFit___json/SetFit--sst5-0c891184cb873f87/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253)\n",
            "100%|██████████| 3/3 [00:00<00:00, 453.65it/s]\n",
            "2024-03-01 16:31:12 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/SetFit___json/SetFit--sst5-0c891184cb873f87/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-085d282a8e30d5e1.arrow\n",
            "2024-03-01 16:31:12 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/SetFit___json/SetFit--sst5-0c891184cb873f87/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-f1a26c00e694c55c.arrow\n",
            "2024-03-01 16:33:08 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-01 16:33:10 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2560, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
            "        (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2560, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-01 16:33:10 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-01 16:33:10 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-01 16:33:10 | INFO | fairseq_cli.train | criterion: FewshotEvalCriterion\n",
            "2024-03-01 16:33:10 | INFO | fairseq_cli.train | num. shared model params: 2,648,724,480 (num. trained: 2,560)\n",
            "2024-03-01 16:33:10 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-01 16:33:13 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-01 16:33:13 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 16:33:13 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-01 16:33:13 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 16:33:13 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-01 16:33:13 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 5\n",
            "2024-03-01 16:33:13 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt\n",
            "2024-03-01 16:33:13 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last.pt\n",
            "2024-03-01 16:33:13 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-01 16:33:13 | INFO | fairseq_cli.train | Start validating\n",
            "2024-03-01 16:33:13 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "------------ example 0 input str valid is ['Sentence: no one goes unindicted here , which is probably for the best . Label:', 'Sentence: no one goes unindicted here , which is probably for the best . Label:', 'Sentence: no one goes unindicted here , which is probably for the best . Label:', 'Sentence: no one goes unindicted here , which is probably for the best . Label:', 'Sentence: no one goes unindicted here , which is probably for the best . Label:']\n",
            "------------ example 0 label str valid is [' terrible', ' bad', ' neutral', ' good', ' great']\n",
            "------------ example 1 input str valid is ['Sentence: pumpkin wants to have it both ways . Label:', 'Sentence: pumpkin wants to have it both ways . Label:', 'Sentence: pumpkin wants to have it both ways . Label:', 'Sentence: pumpkin wants to have it both ways . Label:', 'Sentence: pumpkin wants to have it both ways . Label:']\n",
            "------------ example 1 label str valid is [' terrible', ' bad', ' neutral', ' good', ' great']\n",
            "NOTE: true K of baseline is 0, max valid len is 67\n",
            "| Loaded valid with 5505 samples\n",
            "| Loaded train with 5505 samples\n",
            "2024-03-01 16:35:19 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 11.348 | nll_loss 0.076 | accuracy 35.9 | f1 0 | pos_proportion 12.6 | neg_proportion 26.2 | wps 1320.3 | wpb 149.7 | bsz 1 | num_updates 0\n",
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst5/icl/record_info.jsonl': No such file or directory\n",
            "+ SEED=5\n",
            "+ TASK=sst5\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt\n",
            "+ ARCH=gptmodel_xl\n",
            "+ K=32\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst5\n",
            "+ ana_setting=icl\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' sst5 = agnews ']'\n",
            "+ '[' sst5 = trec ']'\n",
            "+ '[' sst5 = sst5 ']'\n",
            "+ N_CLASSES=5\n",
            "+ '[' sst5 = dbpedia ']'\n",
            "+ '[' sst5 = cb ']'\n",
            "+ '[' sst5 = arce ']'\n",
            "+ '[' sst5 = arcc ']'\n",
            "+ '[' sst5 = obqa ']'\n",
            "+ '[' sst5 = hellaswag ']'\n",
            "+ '[' sst5 = storycloze ']'\n",
            "+ '[' sst5 = raceh ']'\n",
            "+ '[' sst5 = racem ']'\n",
            "+ '[' sst5 = nq ']'\n",
            "+ '[' sst5 = webqs ']'\n",
            "+ '[' sst5 = triviaqa ']'\n",
            "+ '[' sst5 = sq2 ']'\n",
            "+ '[' sst5 = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ BSZ=5\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_eval --arch gptmodel_xl --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --max-epoch 1 --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --max-update 0 --fp16 --eval-data sst5 --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 5 --reset-dataloader --no-save --k 32 --batch-size 5 --batch-size-valid 5 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst5 --ana-setting icl --permut-index 0\n",
            "+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output//train_log_icl.txt\n",
            "2024-03-01 16:35:37 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-01 16:35:37 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-01 16:35:37 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-01 16:35:39.532581: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-01 16:35:39.532627: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-01 16:35:39.534484: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-01 16:35:40.831651: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-01 16:35:43 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 5, 'eval_data': 'sst5', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst5', 'ana_setting': 'icl', 'optim_group': 'all', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 32, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_xl', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2560, 'decoder_output_dim': 2560, 'decoder_input_dim': 2560, 'decoder_ffn_embed_dim': 10240, 'decoder_layers': 32, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt'}, 'criterion': {'_name': 'fs_eval', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 5, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 5, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 5, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': True, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=5, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_eval', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=5, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid='5', max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_xl', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.25], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=True, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='sst5', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst5', ana_setting='icl', optim_group='all', tokens_per_sample=2048, max_target_positions=None, k=32, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt', no_seed_provided=False, decoder_layers=32, decoder_embed_dim=2560, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2560, decoder_output_dim=2560, decoder_ffn_embed_dim=10240, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-01 16:35:43 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-01 16:35:45 | WARNING | datasets.builder | Using custom data configuration SetFit--sst5-0c891184cb873f87\n",
            "2024-03-01 16:35:45 | WARNING | datasets.builder | Reusing dataset json (/root/.cache/huggingface/datasets/SetFit___json/SetFit--sst5-0c891184cb873f87/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253)\n",
            "100%|██████████| 3/3 [00:00<00:00, 476.44it/s]\n",
            "2024-03-01 16:35:45 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/SetFit___json/SetFit--sst5-0c891184cb873f87/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-085d282a8e30d5e1.arrow\n",
            "2024-03-01 16:35:45 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/SetFit___json/SetFit--sst5-0c891184cb873f87/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-f1a26c00e694c55c.arrow\n",
            "2024-03-01 16:36:52 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-01 16:36:53 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2560, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
            "        (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2560, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-01 16:36:53 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-01 16:36:53 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-01 16:36:53 | INFO | fairseq_cli.train | criterion: FewshotEvalCriterion\n",
            "2024-03-01 16:36:53 | INFO | fairseq_cli.train | num. shared model params: 2,648,724,480 (num. trained: 2,560)\n",
            "2024-03-01 16:36:53 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-01 16:36:56 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-01 16:36:56 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 16:36:56 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-01 16:36:56 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 16:36:56 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-01 16:36:56 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 5\n",
            "2024-03-01 16:36:56 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt\n",
            "2024-03-01 16:36:56 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last.pt\n",
            "2024-03-01 16:36:56 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-01 16:36:57 | INFO | fairseq_cli.train | Start validating\n",
            "2024-03-01 16:36:57 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "------------ example 0 input str train is [\"Sentence: an unintentionally surreal kid 's picture ... in which actors in bad bear suits enact a sort of inter-species parody of a vh1 behind the music episode . Label:\", \"Sentence: an unintentionally surreal kid 's picture ... in which actors in bad bear suits enact a sort of inter-species parody of a vh1 behind the music episode . Label:\", \"Sentence: an unintentionally surreal kid 's picture ... in which actors in bad bear suits enact a sort of inter-species parody of a vh1 behind the music episode . Label:\", \"Sentence: an unintentionally surreal kid 's picture ... in which actors in bad bear suits enact a sort of inter-species parody of a vh1 behind the music episode . Label:\", \"Sentence: an unintentionally surreal kid 's picture ... in which actors in bad bear suits enact a sort of inter-species parody of a vh1 behind the music episode . Label:\"]\n",
            "------------ example 0 label str train is [' terrible', ' bad', ' neutral', ' good', ' great']\n",
            "------------ example 1 input str train is [\"Sentence: twenty-three movies into a mostly magnificent directorial career , clint eastwood 's efficiently minimalist style finally has failed him . Label:\", \"Sentence: twenty-three movies into a mostly magnificent directorial career , clint eastwood 's efficiently minimalist style finally has failed him . Label:\", \"Sentence: twenty-three movies into a mostly magnificent directorial career , clint eastwood 's efficiently minimalist style finally has failed him . Label:\", \"Sentence: twenty-three movies into a mostly magnificent directorial career , clint eastwood 's efficiently minimalist style finally has failed him . Label:\", \"Sentence: twenty-three movies into a mostly magnificent directorial career , clint eastwood 's efficiently minimalist style finally has failed him . Label:\"]\n",
            "------------ example 1 label str train is [' terrible', ' bad', ' neutral', ' good', ' great']\n",
            "------------ example 0 input str valid is ['Sentence: no one goes unindicted here , which is probably for the best . Label:', 'Sentence: no one goes unindicted here , which is probably for the best . Label:', 'Sentence: no one goes unindicted here , which is probably for the best . Label:', 'Sentence: no one goes unindicted here , which is probably for the best . Label:', 'Sentence: no one goes unindicted here , which is probably for the best . Label:']\n",
            "------------ example 0 label str valid is [' terrible', ' bad', ' neutral', ' good', ' great']\n",
            "------------ example 1 input str valid is ['Sentence: pumpkin wants to have it both ways . Label:', 'Sentence: pumpkin wants to have it both ways . Label:', 'Sentence: pumpkin wants to have it both ways . Label:', 'Sentence: pumpkin wants to have it both ways . Label:', 'Sentence: pumpkin wants to have it both ways . Label:']\n",
            "------------ example 1 label str valid is [' terrible', ' bad', ' neutral', ' good', ' great']\n",
            "NOTE: true K of baseline is 32, max valid len is 67\n",
            "| Loaded valid with 5505 samples\n",
            "| Loaded train with 5505 samples\n",
            "2024-03-01 16:40:13 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 2.13 | nll_loss 0 | accuracy 46.5 | f1 0 | pos_proportion 12.6 | neg_proportion 26.2 | wps 29734.8 | wpb 5264.7 | bsz 1 | num_updates 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash run.sh en_dense_lm_2_7b gptmodel_xl mr 32 1 0 \"{icl_base_dir}/output\" \"{icl_base_dir}\" 0.001"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpoiR3YAuMVE",
        "outputId": "1f261829-65fd-4065-d2b8-0e000ea279e6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/mr/ft/record_info.jsonl': No such file or directory\n",
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/mr/en_dense_lm_2_7b/0.001': No such file or directory\n",
            "+ SEED=1\n",
            "+ TASK=mr\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt\n",
            "+ ARCH=gptmodel_xl\n",
            "+ K=32\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/mr\n",
            "+ ana_setting=ft\n",
            "+ lr=0.001\n",
            "+ max_epoch=1\n",
            "+ save_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/mr/en_dense_lm_2_7b/0.001\n",
            "+ optim_group=attn_kv\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' mr = agnews ']'\n",
            "+ '[' mr = trec ']'\n",
            "+ '[' mr = sst5 ']'\n",
            "+ '[' mr = dbpedia ']'\n",
            "+ '[' mr = cb ']'\n",
            "+ '[' mr = arce ']'\n",
            "+ '[' mr = arcc ']'\n",
            "+ '[' mr = obqa ']'\n",
            "+ '[' mr = hellaswag ']'\n",
            "+ '[' mr = storycloze ']'\n",
            "+ '[' mr = raceh ']'\n",
            "+ '[' mr = racem ']'\n",
            "+ '[' mr = nq ']'\n",
            "+ '[' mr = webqs ']'\n",
            "+ '[' mr = triviaqa ']'\n",
            "+ '[' mr = sq2 ']'\n",
            "+ '[' mr = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ORI_BSZ=1\n",
            "+ BSZ=2\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_ft --arch gptmodel_xl --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --lr 0.001 --max-epoch 1 --curriculum 1000000 --max-update 1000000 --fp16 --eval-data mr --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 1 --reset-dataloader --k 32 --batch-size 1 --batch-size-valid 1 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/mr --ana-setting ft --save-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/mr/en_dense_lm_2_7b/0.001 --save-interval 1 --save-interval-updates 1000000 --validate-interval 1000000 --disable-validation --optim-group attn_kv --permut-index 0\n",
            "+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output//train_log_ft.txt\n",
            "2024-03-01 16:40:32 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-01 16:40:33 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-01 16:40:33 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-01 16:40:34.513170: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-01 16:40:34.513242: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-01 16:40:34.515053: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-01 16:40:35.746588: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-01 16:40:38 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 1, 'eval_data': 'mr', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/mr', 'ana_setting': 'ft', 'optim_group': 'attn_kv', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 32, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_xl', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2560, 'decoder_output_dim': 2560, 'decoder_input_dim': 2560, 'decoder_ffn_embed_dim': 10240, 'decoder_layers': 32, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt'}, 'criterion': {'_name': 'fs_ft', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.001]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1000000, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': None, 'batch_size_valid': 1, 'max_valid_steps': None, 'curriculum': 1000000, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 1000000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/mr/en_dense_lm_2_7b/0.001', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 1000000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_ft', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=1, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1000000, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=True, max_tokens_valid=None, batch_size_valid='1', max_valid_steps=None, curriculum=1000000, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_xl', max_epoch=1, max_update=1000000, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.001], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/mr/en_dense_lm_2_7b/0.001', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=1000000, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='mr', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/mr', ana_setting='ft', optim_group='attn_kv', tokens_per_sample=2048, max_target_positions=None, k=32, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt', no_seed_provided=False, decoder_layers=32, decoder_embed_dim=2560, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2560, decoder_output_dim=2560, decoder_ffn_embed_dim=10240, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-01 16:40:38 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-01 16:40:39 | WARNING | datasets.builder | Using custom data configuration default\n",
            "2024-03-01 16:40:40 | WARNING | datasets.builder | Reusing dataset rotten_tomatoes (/root/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46)\n",
            "100%|██████████| 3/3 [00:00<00:00, 193.62it/s]\n",
            "2024-03-01 16:40:40 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-3299f20b13103dcc.arrow\n",
            "2024-03-01 16:41:46 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-01 16:41:47 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2560, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
            "        (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2560, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-01 16:41:47 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-01 16:41:47 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-01 16:41:47 | INFO | fairseq_cli.train | criterion: FewshotFTCriterion\n",
            "2024-03-01 16:41:47 | INFO | fairseq_cli.train | num. shared model params: 2,648,724,480 (num. trained: 2,648,724,480)\n",
            "2024-03-01 16:41:47 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-01 16:41:50 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-01 16:41:50 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 16:41:50 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-01 16:41:50 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 16:41:50 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-01 16:41:50 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 1\n",
            "2024-03-01 16:41:50 | INFO | fairseq.trainer | Preparing to load checkpoint /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/mr/en_dense_lm_2_7b/0.001/checkpoint_last.pt\n",
            "2024-03-01 16:41:50 | INFO | fairseq.trainer | No existing checkpoint found /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/mr/en_dense_lm_2_7b/0.001/checkpoint_last.pt\n",
            "2024-03-01 16:41:50 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-01 16:41:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 32\n",
            "2024-03-01 16:41:50 | INFO | fairseq.trainer | begin training epoch 1\n",
            "2024-03-01 16:41:50 | INFO | fairseq_cli.train | Start fine-tuning\n",
            "------------ example 0 input str train is [\"Review: hashiguchi vividly captures the way young japanese live now , chafing against their culture's manic mix of millennial brusqueness and undying , traditional politesse . Sentiment:\", \"Review: hashiguchi vividly captures the way young japanese live now , chafing against their culture's manic mix of millennial brusqueness and undying , traditional politesse . Sentiment:\"]\n",
            "------------ example 0 label str train is [' Negative', ' Positive']\n",
            "------------ example 1 input str train is ['Review: the strong subject matter continues to shock throughout the film . not everyone will play the dark , challenging tune taught by the piano teacher . Sentiment:', 'Review: the strong subject matter continues to shock throughout the film . not everyone will play the dark , challenging tune taught by the piano teacher . Sentiment:']\n",
            "------------ example 1 label str train is [' Negative', ' Positive']\n",
            "------------ example 0 input str valid is ['Review: i liked a lot of the smaller scenes . Sentiment:', 'Review: i liked a lot of the smaller scenes . Sentiment:']\n",
            "------------ example 0 label str valid is [' Negative', ' Positive']\n",
            "------------ example 1 input str valid is ['Review: what happens when something goes bump in the night and nobody cares ? Sentiment:', 'Review: what happens when something goes bump in the night and nobody cares ? Sentiment:']\n",
            "------------ example 1 label str valid is [' Negative', ' Positive']\n",
            "NOTE: true K of baseline is 32, max valid len is 84\n",
            "------------ example 0 input str train is [\"Review: hashiguchi vividly captures the way young japanese live now , chafing against their culture's manic mix of millennial brusqueness and undying , traditional politesse . Sentiment:\", \"Review: hashiguchi vividly captures the way young japanese live now , chafing against their culture's manic mix of millennial brusqueness and undying , traditional politesse . Sentiment:\"]\n",
            "------------ example 0 label str train is [' Negative', ' Positive']\n",
            "------------ example 1 input str train is ['Review: the strong subject matter continues to shock throughout the film . not everyone will play the dark , challenging tune taught by the piano teacher . Sentiment:', 'Review: the strong subject matter continues to shock throughout the film . not everyone will play the dark , challenging tune taught by the piano teacher . Sentiment:']\n",
            "------------ example 1 label str train is [' Negative', ' Positive']\n",
            "NOTE: true K of baseline is 32\n",
            "| Loaded valid with 2132 samples\n",
            "| Loaded train with 32 samples\n",
            "2024-03-01 16:41:55 | INFO | train_inner | epoch 001:      1 / 32 loss=7.808, sample_size=43, ntokens=44, wps=0, ups=0, wpb=44, bsz=1, num_updates=1, lr=0.001, gnorm=11.098, loss_scale=4, train_wall=4, gb_free=26.1, wall=4\n",
            "2024-03-01 16:41:57 | INFO | train_inner | epoch 001:      2 / 32 loss=8.44, sample_size=32, ntokens=33, wps=15.1, ups=0.46, wpb=33, bsz=1, num_updates=2, lr=0.001, gnorm=13.846, loss_scale=4, train_wall=2, gb_free=25.8, wall=7\n",
            "2024-03-01 16:42:00 | INFO | train_inner | epoch 001:      3 / 32 loss=6.189, sample_size=47, ntokens=48, wps=15.7, ups=0.33, wpb=48, bsz=1, num_updates=3, lr=0.001, gnorm=10.074, loss_scale=4, train_wall=3, gb_free=25.8, wall=10\n",
            "2024-03-01 16:42:03 | INFO | train_inner | epoch 001:      4 / 32 loss=6.655, sample_size=45, ntokens=46, wps=15.6, ups=0.34, wpb=46, bsz=1, num_updates=4, lr=0.001, gnorm=10.262, loss_scale=4, train_wall=3, gb_free=25.8, wall=13\n",
            "2024-03-01 16:42:05 | INFO | train_inner | epoch 001:      5 / 32 loss=6.418, sample_size=31, ntokens=32, wps=15.3, ups=0.48, wpb=32, bsz=1, num_updates=5, lr=0.001, gnorm=12.489, loss_scale=4, train_wall=2, gb_free=25.8, wall=15\n",
            "2024-03-01 16:42:07 | INFO | train_inner | epoch 001:      6 / 32 loss=6.44, sample_size=40, ntokens=41, wps=15.5, ups=0.38, wpb=41, bsz=1, num_updates=6, lr=0.001, gnorm=10.267, loss_scale=4, train_wall=3, gb_free=25.8, wall=17\n",
            "2024-03-01 16:42:11 | INFO | train_inner | epoch 001:      7 / 32 loss=5.912, sample_size=59, ntokens=60, wps=16, ups=0.27, wpb=60, bsz=1, num_updates=7, lr=0.001, gnorm=8.378, loss_scale=4, train_wall=4, gb_free=25.8, wall=21\n",
            "2024-03-01 16:42:14 | INFO | train_inner | epoch 001:      8 / 32 loss=6.709, sample_size=35, ntokens=36, wps=15.9, ups=0.44, wpb=36, bsz=1, num_updates=8, lr=0.001, gnorm=13.716, loss_scale=4, train_wall=2, gb_free=25.8, wall=23\n",
            "2024-03-01 16:42:16 | INFO | train_inner | epoch 001:      9 / 32 loss=5.841, sample_size=34, ntokens=35, wps=15.7, ups=0.45, wpb=35, bsz=1, num_updates=9, lr=0.001, gnorm=12.613, loss_scale=4, train_wall=2, gb_free=25.8, wall=26\n",
            "2024-03-01 16:42:18 | INFO | train_inner | epoch 001:     10 / 32 loss=6.088, sample_size=38, ntokens=39, wps=15.7, ups=0.4, wpb=39, bsz=1, num_updates=10, lr=0.001, gnorm=9.018, loss_scale=4, train_wall=2, gb_free=25.8, wall=28\n",
            "2024-03-01 16:42:20 | INFO | train_inner | epoch 001:     11 / 32 loss=6.485, sample_size=19, ntokens=20, wps=14.9, ups=0.75, wpb=20, bsz=1, num_updates=11, lr=0.001, gnorm=15.931, loss_scale=4, train_wall=1, gb_free=25.8, wall=29\n",
            "2024-03-01 16:42:22 | INFO | train_inner | epoch 001:     12 / 32 loss=7.261, sample_size=42, ntokens=43, wps=15.9, ups=0.37, wpb=43, bsz=1, num_updates=12, lr=0.001, gnorm=13.564, loss_scale=4, train_wall=3, gb_free=25.8, wall=32\n",
            "2024-03-01 16:42:25 | INFO | train_inner | epoch 001:     13 / 32 loss=5.172, sample_size=47, ntokens=48, wps=16, ups=0.33, wpb=48, bsz=1, num_updates=13, lr=0.001, gnorm=7.785, loss_scale=4, train_wall=3, gb_free=25.8, wall=35\n",
            "2024-03-01 16:42:26 | INFO | train_inner | epoch 001:     14 / 32 loss=8.523, sample_size=13, ntokens=14, wps=14.5, ups=1.04, wpb=14, bsz=1, num_updates=14, lr=0.001, gnorm=21.764, loss_scale=4, train_wall=1, gb_free=25.8, wall=36\n",
            "2024-03-01 16:42:29 | INFO | train_inner | epoch 001:     15 / 32 loss=7.21, sample_size=39, ntokens=40, wps=16, ups=0.4, wpb=40, bsz=1, num_updates=15, lr=0.001, gnorm=14.736, loss_scale=4, train_wall=2, gb_free=25.8, wall=39\n",
            "2024-03-01 16:42:30 | INFO | train_inner | epoch 001:     16 / 32 loss=4.264, sample_size=18, ntokens=19, wps=15.1, ups=0.8, wpb=19, bsz=1, num_updates=16, lr=0.001, gnorm=12.622, loss_scale=4, train_wall=1, gb_free=25.8, wall=40\n",
            "2024-03-01 16:42:32 | INFO | train_inner | epoch 001:     17 / 32 loss=6.454, sample_size=34, ntokens=35, wps=15.7, ups=0.45, wpb=35, bsz=1, num_updates=17, lr=0.001, gnorm=11.368, loss_scale=4, train_wall=2, gb_free=25.8, wall=42\n",
            "2024-03-01 16:42:33 | INFO | train_inner | epoch 001:     18 / 32 loss=5.725, sample_size=14, ntokens=15, wps=14.9, ups=0.99, wpb=15, bsz=1, num_updates=18, lr=0.001, gnorm=15.278, loss_scale=4, train_wall=1, gb_free=25.8, wall=43\n",
            "2024-03-01 16:42:34 | INFO | train_inner | epoch 001:     19 / 32 loss=6.858, sample_size=11, ntokens=12, wps=14.6, ups=1.21, wpb=12, bsz=1, num_updates=19, lr=0.001, gnorm=18.563, loss_scale=4, train_wall=1, gb_free=25.8, wall=44\n",
            "2024-03-01 16:42:37 | INFO | train_inner | epoch 001:     20 / 32 loss=4.951, sample_size=42, ntokens=43, wps=16, ups=0.37, wpb=43, bsz=1, num_updates=20, lr=0.001, gnorm=11.73, loss_scale=4, train_wall=3, gb_free=25.8, wall=47\n",
            "2024-03-01 16:42:38 | INFO | train_inner | epoch 001:     21 / 32 loss=5.347, sample_size=17, ntokens=18, wps=15.2, ups=0.84, wpb=18, bsz=1, num_updates=21, lr=0.001, gnorm=14.92, loss_scale=4, train_wall=1, gb_free=25.8, wall=48\n",
            "2024-03-01 16:42:41 | INFO | train_inner | epoch 001:     22 / 32 loss=5.643, sample_size=52, ntokens=53, wps=15.9, ups=0.3, wpb=53, bsz=1, num_updates=22, lr=0.001, gnorm=8.404, loss_scale=4, train_wall=3, gb_free=25.8, wall=51\n",
            "2024-03-01 16:42:44 | INFO | train_inner | epoch 001:     23 / 32 loss=5.432, sample_size=48, ntokens=49, wps=16, ups=0.33, wpb=49, bsz=1, num_updates=23, lr=0.001, gnorm=9.907, loss_scale=4, train_wall=3, gb_free=25.8, wall=54\n",
            "2024-03-01 16:42:45 | INFO | train_inner | epoch 001:     24 / 32 loss=4.168, sample_size=14, ntokens=15, wps=15.1, ups=1, wpb=15, bsz=1, num_updates=24, lr=0.001, gnorm=13.469, loss_scale=4, train_wall=1, gb_free=25.8, wall=55\n",
            "2024-03-01 16:42:48 | INFO | train_inner | epoch 001:     25 / 32 loss=5.403, sample_size=34, ntokens=35, wps=15.8, ups=0.45, wpb=35, bsz=1, num_updates=25, lr=0.001, gnorm=14.161, loss_scale=4, train_wall=2, gb_free=25.8, wall=57\n",
            "2024-03-01 16:42:50 | INFO | train_inner | epoch 001:     26 / 32 loss=5.003, sample_size=37, ntokens=38, wps=15.3, ups=0.4, wpb=38, bsz=1, num_updates=26, lr=0.001, gnorm=9.328, loss_scale=4, train_wall=2, gb_free=25.8, wall=60\n",
            "2024-03-01 16:42:52 | INFO | train_inner | epoch 001:     27 / 32 loss=5.274, sample_size=36, ntokens=37, wps=16.1, ups=0.43, wpb=37, bsz=1, num_updates=27, lr=0.001, gnorm=17.473, loss_scale=4, train_wall=2, gb_free=25.8, wall=62\n",
            "2024-03-01 16:42:55 | INFO | train_inner | epoch 001:     28 / 32 loss=6.617, sample_size=39, ntokens=40, wps=15.8, ups=0.4, wpb=40, bsz=1, num_updates=28, lr=0.001, gnorm=14.651, loss_scale=4, train_wall=3, gb_free=25.8, wall=65\n",
            "2024-03-01 16:42:57 | INFO | train_inner | epoch 001:     29 / 32 loss=4.371, sample_size=30, ntokens=31, wps=15.4, ups=0.5, wpb=31, bsz=1, num_updates=29, lr=0.001, gnorm=9.693, loss_scale=4, train_wall=2, gb_free=25.8, wall=67\n",
            "2024-03-01 16:42:59 | INFO | train_inner | epoch 001:     30 / 32 loss=6.156, sample_size=36, ntokens=37, wps=15.7, ups=0.42, wpb=37, bsz=1, num_updates=30, lr=0.001, gnorm=13.549, loss_scale=4, train_wall=2, gb_free=25.8, wall=69\n",
            "2024-03-01 16:43:02 | INFO | train_inner | epoch 001:     31 / 32 loss=5.166, sample_size=39, ntokens=40, wps=15.8, ups=0.4, wpb=40, bsz=1, num_updates=31, lr=0.001, gnorm=10.213, loss_scale=4, train_wall=3, gb_free=25.8, wall=72\n",
            "2024-03-01 16:43:04 | INFO | train_inner | epoch 001:     32 / 32 loss=5.049, sample_size=40, ntokens=41, wps=16.1, ups=0.39, wpb=41, bsz=1, num_updates=32, lr=0.001, gnorm=7.532, loss_scale=4, train_wall=3, gb_free=25.8, wall=74\n",
            "2024-03-01 16:43:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 32 updates\n",
            "2024-03-01 16:43:04 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/mr/en_dense_lm_2_7b/0.001/checkpoint1.pt\n",
            "2024-03-01 16:43:52 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/mr/en_dense_lm_2_7b/0.001/checkpoint1.pt\n",
            "2024-03-01 16:44:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/mr/en_dense_lm_2_7b/0.001/checkpoint1.pt (epoch 1 @ 32 updates, score None) (writing took 92.31977698500123 seconds)\n",
            "2024-03-01 16:44:37 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
            "2024-03-01 16:44:37 | INFO | train | epoch 001 | loss 6.032 | sample_size 34.531 | ntokens 35.531 | wps 6.7 | ups 0.19 | wpb 35.5 | bsz 1 | num_updates 32 | lr 0.001 | gnorm 12.45 | loss_scale 4 | train_wall 74 | gb_free 25.8 | wall 166\n",
            "2024-03-01 16:44:37 | INFO | fairseq_cli.train | done training in 166.2 seconds\n",
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/mr/ftzs/record_info.jsonl': No such file or directory\n",
            "+ SEED=1\n",
            "+ TASK=mr\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/mr/en_dense_lm_2_7b/0.001/checkpoint_last.pt\n",
            "+ ARCH=gptmodel_xl\n",
            "+ K=0\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/mr\n",
            "+ ana_setting=ftzs\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' mr = agnews ']'\n",
            "+ '[' mr = trec ']'\n",
            "+ '[' mr = sst5 ']'\n",
            "+ '[' mr = dbpedia ']'\n",
            "+ '[' mr = cb ']'\n",
            "+ '[' mr = arce ']'\n",
            "+ '[' mr = arcc ']'\n",
            "+ '[' mr = obqa ']'\n",
            "+ '[' mr = hellaswag ']'\n",
            "+ '[' mr = storycloze ']'\n",
            "+ '[' mr = raceh ']'\n",
            "+ '[' mr = racem ']'\n",
            "+ '[' mr = nq ']'\n",
            "+ '[' mr = webqs ']'\n",
            "+ '[' mr = triviaqa ']'\n",
            "+ '[' mr = sq2 ']'\n",
            "+ '[' mr = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ BSZ=2\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_eval --arch gptmodel_xl --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --max-epoch 1 --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --max-update 0 --fp16 --eval-data mr --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 1 --reset-dataloader --no-save --k 0 --batch-size 2 --batch-size-valid 2 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/mr/en_dense_lm_2_7b/0.001/checkpoint_last.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF5+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output//train_log_ftzs.txt\n",
            "02_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/mr --ana-setting ftzs --permut-index 0\n",
            "2024-03-01 16:44:55 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-01 16:44:56 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-01 16:44:56 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-01 16:44:58.287265: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-01 16:44:58.287309: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-01 16:44:58.288968: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-01 16:44:59.691341: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-01 16:45:02 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 1, 'eval_data': 'mr', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/mr', 'ana_setting': 'ftzs', 'optim_group': 'all', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 0, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_xl', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2560, 'decoder_output_dim': 2560, 'decoder_input_dim': 2560, 'decoder_ffn_embed_dim': 10240, 'decoder_layers': 32, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/mr/en_dense_lm_2_7b/0.001/checkpoint_last.pt'}, 'criterion': {'_name': 'fs_eval', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 2, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 2, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': True, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_eval', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=2, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid='2', max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_xl', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.25], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=True, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='mr', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/mr', ana_setting='ftzs', optim_group='all', tokens_per_sample=2048, max_target_positions=None, k=0, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/mr/en_dense_lm_2_7b/0.001/checkpoint_last.pt', no_seed_provided=False, decoder_layers=32, decoder_embed_dim=2560, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2560, decoder_output_dim=2560, decoder_ffn_embed_dim=10240, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-01 16:45:02 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-01 16:45:03 | WARNING | datasets.builder | Using custom data configuration default\n",
            "2024-03-01 16:45:03 | WARNING | datasets.builder | Reusing dataset rotten_tomatoes (/root/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46)\n",
            "100%|██████████| 3/3 [00:00<00:00, 283.60it/s]\n",
            "2024-03-01 16:45:03 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-e0fd9bc1e5156f21.arrow\n",
            "2024-03-01 16:45:03 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-3299f20b13103dcc.arrow\n",
            "2024-03-01 16:46:43 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-01 16:46:45 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2560, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
            "        (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2560, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-01 16:46:45 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-01 16:46:45 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-01 16:46:45 | INFO | fairseq_cli.train | criterion: FewshotEvalCriterion\n",
            "2024-03-01 16:46:45 | INFO | fairseq_cli.train | num. shared model params: 2,648,724,480 (num. trained: 2,560)\n",
            "2024-03-01 16:46:45 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-01 16:46:48 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-01 16:46:48 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 16:46:48 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-01 16:46:48 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 16:46:48 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-01 16:46:48 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 2\n",
            "2024-03-01 16:46:48 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt\n",
            "2024-03-01 16:46:48 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last.pt\n",
            "2024-03-01 16:46:48 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-01 16:46:49 | INFO | fairseq_cli.train | Start validating\n",
            "2024-03-01 16:46:49 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "------------ example 0 input str valid is ['Review: i liked a lot of the smaller scenes . Sentiment:', 'Review: i liked a lot of the smaller scenes . Sentiment:']\n",
            "------------ example 0 label str valid is [' Negative', ' Positive']\n",
            "------------ example 1 input str valid is ['Review: what happens when something goes bump in the night and nobody cares ? Sentiment:', 'Review: what happens when something goes bump in the night and nobody cares ? Sentiment:']\n",
            "------------ example 1 label str valid is [' Negative', ' Positive']\n",
            "NOTE: true K of baseline is 0, max valid len is 84\n",
            "| Loaded valid with 2132 samples\n",
            "| Loaded train with 2132 samples\n",
            "2024-03-01 16:49:58 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 3.528 | nll_loss 0.055 | accuracy 79.8 | f1 0 | pos_proportion 50 | neg_proportion 50 | wps 363.1 | wpb 64 | bsz 1 | num_updates 0\n",
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/mr/zs/record_info.jsonl': No such file or directory\n",
            "+ SEED=1\n",
            "+ TASK=mr\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt\n",
            "+ ARCH=gptmodel_xl\n",
            "+ K=0\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/mr\n",
            "+ ana_setting=zs\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' mr = agnews ']'\n",
            "+ '[' mr = trec ']'\n",
            "+ '[' mr = sst5 ']'\n",
            "+ '[' mr = dbpedia ']'\n",
            "+ '[' mr = cb ']'\n",
            "+ '[' mr = arce ']'\n",
            "+ '[' mr = arcc ']'\n",
            "+ '[' mr = obqa ']'\n",
            "+ '[' mr = hellaswag ']'\n",
            "+ '[' mr = storycloze ']'\n",
            "+ '[' mr = raceh ']'\n",
            "+ '[' mr = racem ']'\n",
            "+ '[' mr = nq ']'\n",
            "+ '[' mr = webqs ']'\n",
            "+ '[' mr = triviaqa ']'\n",
            "+ '[' mr = sq2 ']'\n",
            "+ '[' mr = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ BSZ=2\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_eval --arch gptmodel_xl --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --max-epoch 1 --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --max-update 0 --fp16 --eval-data mr --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 1 --reset-dataloader --no-save --k 0 --batch-size 2 --batch-size-valid 2 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/mr --ana-setting zs --permut-index 0\n",
            "+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output//train_log_zs.txt\n",
            "2024-03-01 16:50:18 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-01 16:50:18 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-01 16:50:18 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-01 16:50:20.552087: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-01 16:50:20.552126: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-01 16:50:20.560336: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-01 16:50:21.990811: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-01 16:50:24 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 1, 'eval_data': 'mr', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/mr', 'ana_setting': 'zs', 'optim_group': 'all', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 0, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_xl', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2560, 'decoder_output_dim': 2560, 'decoder_input_dim': 2560, 'decoder_ffn_embed_dim': 10240, 'decoder_layers': 32, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt'}, 'criterion': {'_name': 'fs_eval', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 2, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 2, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': True, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_eval', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=2, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid='2', max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_xl', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.25], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=True, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='mr', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/mr', ana_setting='zs', optim_group='all', tokens_per_sample=2048, max_target_positions=None, k=0, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt', no_seed_provided=False, decoder_layers=32, decoder_embed_dim=2560, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2560, decoder_output_dim=2560, decoder_ffn_embed_dim=10240, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-01 16:50:24 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-01 16:50:26 | WARNING | datasets.builder | Using custom data configuration default\n",
            "2024-03-01 16:50:26 | WARNING | datasets.builder | Reusing dataset rotten_tomatoes (/root/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46)\n",
            "100%|██████████| 3/3 [00:00<00:00, 221.89it/s]\n",
            "2024-03-01 16:50:26 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-e0fd9bc1e5156f21.arrow\n",
            "2024-03-01 16:50:26 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-3299f20b13103dcc.arrow\n",
            "2024-03-01 16:51:53 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-01 16:51:54 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2560, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
            "        (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2560, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-01 16:51:54 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-01 16:51:54 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-01 16:51:54 | INFO | fairseq_cli.train | criterion: FewshotEvalCriterion\n",
            "2024-03-01 16:51:54 | INFO | fairseq_cli.train | num. shared model params: 2,648,724,480 (num. trained: 2,560)\n",
            "2024-03-01 16:51:54 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-01 16:51:58 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-01 16:51:58 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 16:51:58 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-01 16:51:58 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 16:51:58 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-01 16:51:58 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 2\n",
            "2024-03-01 16:51:58 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt\n",
            "2024-03-01 16:51:58 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last.pt\n",
            "2024-03-01 16:51:58 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-01 16:51:58 | INFO | fairseq_cli.train | Start validating\n",
            "2024-03-01 16:51:58 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "------------ example 0 input str valid is ['Review: i liked a lot of the smaller scenes . Sentiment:', 'Review: i liked a lot of the smaller scenes . Sentiment:']\n",
            "------------ example 0 label str valid is [' Negative', ' Positive']\n",
            "------------ example 1 input str valid is ['Review: what happens when something goes bump in the night and nobody cares ? Sentiment:', 'Review: what happens when something goes bump in the night and nobody cares ? Sentiment:']\n",
            "------------ example 1 label str valid is [' Negative', ' Positive']\n",
            "NOTE: true K of baseline is 0, max valid len is 84\n",
            "| Loaded valid with 2132 samples\n",
            "| Loaded train with 2132 samples\n",
            "2024-03-01 16:54:03 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 11.208 | nll_loss 0.175 | accuracy 60.8 | f1 0 | pos_proportion 50 | neg_proportion 50 | wps 552.3 | wpb 64 | bsz 1 | num_updates 0\n",
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/mr/icl/record_info.jsonl': No such file or directory\n",
            "+ SEED=1\n",
            "+ TASK=mr\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt\n",
            "+ ARCH=gptmodel_xl\n",
            "+ K=32\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/mr\n",
            "+ ana_setting=icl\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' mr = agnews ']'\n",
            "+ '[' mr = trec ']'\n",
            "+ '[' mr = sst5 ']'\n",
            "+ '[' mr = dbpedia ']'\n",
            "+ '[' mr = cb ']'\n",
            "+ '[' mr = arce ']'\n",
            "+ '[' mr = arcc ']'\n",
            "+ '[' mr = obqa ']'\n",
            "+ '[' mr = hellaswag ']'\n",
            "+ '[' mr = storycloze ']'\n",
            "+ '[' mr = raceh ']'\n",
            "+ '[' mr = racem ']'\n",
            "+ '[' mr = nq ']'\n",
            "+ '[' mr = webqs ']'\n",
            "+ '[' mr = triviaqa ']'\n",
            "+ '[' mr = sq2 ']'\n",
            "+ '[' mr = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ BSZ=2\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_eval --arch gptmodel_xl --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --max-epoch 1 --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --max-update 0 --fp16 --eval-data mr --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 1 --reset-dataloader --no-save --k 32 --batch-size 2 --batch-size-valid 2 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/mr --ana-setting icl --permut-index 0\n",
            "+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output//train_log_icl.txt\n",
            "2024-03-01 16:54:25 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-01 16:54:26 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-01 16:54:26 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-01 16:54:27.571525: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-01 16:54:27.571571: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-01 16:54:27.573382: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-01 16:54:28.800014: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-01 16:54:30 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 1, 'eval_data': 'mr', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/mr', 'ana_setting': 'icl', 'optim_group': 'all', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 32, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_xl', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2560, 'decoder_output_dim': 2560, 'decoder_input_dim': 2560, 'decoder_ffn_embed_dim': 10240, 'decoder_layers': 32, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt'}, 'criterion': {'_name': 'fs_eval', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 2, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 2, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': True, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_eval', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=2, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid='2', max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_xl', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.25], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=True, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='mr', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/mr', ana_setting='icl', optim_group='all', tokens_per_sample=2048, max_target_positions=None, k=32, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt', no_seed_provided=False, decoder_layers=32, decoder_embed_dim=2560, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2560, decoder_output_dim=2560, decoder_ffn_embed_dim=10240, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-01 16:54:31 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-01 16:54:32 | WARNING | datasets.builder | Using custom data configuration default\n",
            "2024-03-01 16:54:32 | WARNING | datasets.builder | Reusing dataset rotten_tomatoes (/root/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46)\n",
            "100%|██████████| 3/3 [00:00<00:00, 707.14it/s]\n",
            "2024-03-01 16:54:32 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-e0fd9bc1e5156f21.arrow\n",
            "2024-03-01 16:54:32 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-3299f20b13103dcc.arrow\n",
            "2024-03-01 16:55:39 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-01 16:55:40 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2560, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
            "        (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2560, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-01 16:55:40 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-01 16:55:40 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-01 16:55:40 | INFO | fairseq_cli.train | criterion: FewshotEvalCriterion\n",
            "2024-03-01 16:55:40 | INFO | fairseq_cli.train | num. shared model params: 2,648,724,480 (num. trained: 2,560)\n",
            "2024-03-01 16:55:40 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-01 16:55:43 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-01 16:55:43 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 16:55:43 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-01 16:55:43 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 16:55:43 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-01 16:55:43 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 2\n",
            "2024-03-01 16:55:43 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt\n",
            "2024-03-01 16:55:43 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last.pt\n",
            "2024-03-01 16:55:43 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-01 16:55:43 | INFO | fairseq_cli.train | Start validating\n",
            "2024-03-01 16:55:43 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "------------ example 0 input str train is [\"Review: hashiguchi vividly captures the way young japanese live now , chafing against their culture's manic mix of millennial brusqueness and undying , traditional politesse . Sentiment:\", \"Review: hashiguchi vividly captures the way young japanese live now , chafing against their culture's manic mix of millennial brusqueness and undying , traditional politesse . Sentiment:\"]\n",
            "------------ example 0 label str train is [' Negative', ' Positive']\n",
            "------------ example 1 input str train is ['Review: the strong subject matter continues to shock throughout the film . not everyone will play the dark , challenging tune taught by the piano teacher . Sentiment:', 'Review: the strong subject matter continues to shock throughout the film . not everyone will play the dark , challenging tune taught by the piano teacher . Sentiment:']\n",
            "------------ example 1 label str train is [' Negative', ' Positive']\n",
            "------------ example 0 input str valid is ['Review: i liked a lot of the smaller scenes . Sentiment:', 'Review: i liked a lot of the smaller scenes . Sentiment:']\n",
            "------------ example 0 label str valid is [' Negative', ' Positive']\n",
            "------------ example 1 input str valid is ['Review: what happens when something goes bump in the night and nobody cares ? Sentiment:', 'Review: what happens when something goes bump in the night and nobody cares ? Sentiment:']\n",
            "------------ example 1 label str valid is [' Negative', ' Positive']\n",
            "NOTE: true K of baseline is 32, max valid len is 84\n",
            "| Loaded valid with 2132 samples\n",
            "| Loaded train with 2132 samples\n",
            "2024-03-01 16:59:02 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 0.315 | nll_loss 0 | accuracy 91.3 | f1 0 | pos_proportion 50 | neg_proportion 50 | wps 12638.6 | wpb 2338 | bsz 1 | num_updates 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash run.sh en_dense_lm_2_7b gptmodel_xl subj 32 4 0 \"{icl_base_dir}/output\" \"{icl_base_dir}\" 0.002"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1itRwYUOuSbf",
        "outputId": "c7a97069-b88b-4d27-f6fe-dee29d466bb0",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/subj/ft/record_info.jsonl': No such file or directory\n",
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/subj/en_dense_lm_2_7b/0.002': No such file or directory\n",
            "+ SEED=4\n",
            "+ TASK=subj\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt\n",
            "+ ARCH=gptmodel_xl\n",
            "+ K=32\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/subj\n",
            "+ ana_setting=ft\n",
            "+ lr=0.002\n",
            "+ max_epoch=1\n",
            "+ save_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/subj/en_dense_lm_2_7b/0.002\n",
            "+ optim_group=attn_kv\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' subj = agnews ']'\n",
            "+ '[' subj = trec ']'\n",
            "+ '[' subj = sst5 ']'\n",
            "+ '[' subj = dbpedia ']'\n",
            "+ '[' subj = cb ']'\n",
            "+ '[' subj = arce ']'\n",
            "+ '[' subj = arcc ']'\n",
            "+ '[' subj = obqa ']'\n",
            "+ '[' subj = hellaswag ']'\n",
            "+ '[' subj = storycloze ']'\n",
            "+ '[' subj = raceh ']'\n",
            "+ '[' subj = racem ']'\n",
            "+ '[' subj = nq ']'\n",
            "+ '[' subj = webqs ']'\n",
            "+ '[' subj = triviaqa ']'\n",
            "+ '[' subj = sq2 ']'\n",
            "+ '[' subj = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ORI_BSZ=1\n",
            "+ BSZ=2\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_ft --arch gptmodel_xl --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --lr 0.002 --max-epoch 1 --curriculum 1000000 --max-update 1000000 --fp16 --eval-data subj --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 4 --reset-dataloader --k 32 --batch-size 1 --batch-size-valid 1 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/subj --ana-setting ft --save-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/subj/en_dense_lm_2_7b/0.002 --save-interval 1 --save-interval-updates 1000000 --validate-interval 1000000 --disable-validation --optim-group attn_kv --permut-index 0\n",
            "+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output//train_log_ft.txt\n",
            "2024-03-01 16:59:15 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-01 16:59:16 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-01 16:59:16 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-01 16:59:17.418496: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-01 16:59:17.418544: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-01 16:59:17.420349: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-01 16:59:18.687464: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-01 16:59:20 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 4, 'eval_data': 'subj', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/subj', 'ana_setting': 'ft', 'optim_group': 'attn_kv', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 32, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_xl', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2560, 'decoder_output_dim': 2560, 'decoder_input_dim': 2560, 'decoder_ffn_embed_dim': 10240, 'decoder_layers': 32, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt'}, 'criterion': {'_name': 'fs_ft', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.002]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 4, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1000000, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': None, 'batch_size_valid': 1, 'max_valid_steps': None, 'curriculum': 1000000, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 1000000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/subj/en_dense_lm_2_7b/0.002', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 1000000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=4, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_ft', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=1, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1000000, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=True, max_tokens_valid=None, batch_size_valid='1', max_valid_steps=None, curriculum=1000000, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_xl', max_epoch=1, max_update=1000000, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.002], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/subj/en_dense_lm_2_7b/0.002', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=1000000, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='subj', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/subj', ana_setting='ft', optim_group='attn_kv', tokens_per_sample=2048, max_target_positions=None, k=32, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt', no_seed_provided=False, decoder_layers=32, decoder_embed_dim=2560, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2560, decoder_output_dim=2560, decoder_ffn_embed_dim=10240, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-01 16:59:21 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-01 16:59:23 | WARNING | datasets.builder | Using custom data configuration SetFit--subj-693a635c625bebac\n",
            "2024-03-01 16:59:23 | WARNING | datasets.builder | Reusing dataset json (/root/.cache/huggingface/datasets/SetFit___json/SetFit--subj-693a635c625bebac/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253)\n",
            "100%|██████████| 2/2 [00:00<00:00, 99.85it/s]\n",
            "2024-03-01 16:59:23 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/SetFit___json/SetFit--subj-693a635c625bebac/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-41679576bb6cfc7c.arrow\n",
            "2024-03-01 16:59:23 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/SetFit___json/SetFit--subj-693a635c625bebac/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-6b58bb8b23415efd.arrow\n",
            "2024-03-01 17:00:31 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-01 17:00:32 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2560, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
            "        (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2560, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-01 17:00:32 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-01 17:00:32 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-01 17:00:32 | INFO | fairseq_cli.train | criterion: FewshotFTCriterion\n",
            "2024-03-01 17:00:32 | INFO | fairseq_cli.train | num. shared model params: 2,648,724,480 (num. trained: 2,648,724,480)\n",
            "2024-03-01 17:00:32 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-01 17:00:36 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-01 17:00:36 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 17:00:36 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-01 17:00:36 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 17:00:36 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-01 17:00:36 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 1\n",
            "2024-03-01 17:00:36 | INFO | fairseq.trainer | Preparing to load checkpoint /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/subj/en_dense_lm_2_7b/0.002/checkpoint_last.pt\n",
            "2024-03-01 17:00:36 | INFO | fairseq.trainer | No existing checkpoint found /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/subj/en_dense_lm_2_7b/0.002/checkpoint_last.pt\n",
            "2024-03-01 17:00:36 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-01 17:00:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 32\n",
            "2024-03-01 17:00:37 | INFO | fairseq.trainer | begin training epoch 1\n",
            "2024-03-01 17:00:37 | INFO | fairseq_cli.train | Start fine-tuning\n",
            "------------ example 0 input str train is ['Input: a spellbinding african film about the modern condition of rootlessness , a state experienced by millions around the globe . Type:', 'Input: a spellbinding african film about the modern condition of rootlessness , a state experienced by millions around the globe . Type:']\n",
            "------------ example 0 label str train is [' objective', ' subjective']\n",
            "------------ example 1 input str train is [\"Input: and if she 's lucky , she may find love along the way . Type:\", \"Input: and if she 's lucky , she may find love along the way . Type:\"]\n",
            "------------ example 1 label str train is [' objective', ' subjective']\n",
            "------------ example 0 input str valid is ['Input: never giving up the fight to win the war , mcnamara is silently planning , waiting for his moment to strike back at the enemy . Type:', 'Input: never giving up the fight to win the war , mcnamara is silently planning , waiting for his moment to strike back at the enemy . Type:']\n",
            "------------ example 0 label str valid is [' objective', ' subjective']\n",
            "------------ example 1 input str valid is ['Input: if the story lacks bite , the performances are never less than affectionate . Type:', 'Input: if the story lacks bite , the performances are never less than affectionate . Type:']\n",
            "------------ example 1 label str valid is [' objective', ' subjective']\n",
            "NOTE: true K of baseline is 32, max valid len is 174\n",
            "------------ example 0 input str train is ['Input: a spellbinding african film about the modern condition of rootlessness , a state experienced by millions around the globe . Type:', 'Input: a spellbinding african film about the modern condition of rootlessness , a state experienced by millions around the globe . Type:']\n",
            "------------ example 0 label str train is [' objective', ' subjective']\n",
            "------------ example 1 input str train is [\"Input: and if she 's lucky , she may find love along the way . Type:\", \"Input: and if she 's lucky , she may find love along the way . Type:\"]\n",
            "------------ example 1 label str train is [' objective', ' subjective']\n",
            "NOTE: true K of baseline is 32\n",
            "| Loaded valid with 4000 samples\n",
            "| Loaded train with 32 samples\n",
            "2024-03-01 17:00:40 | INFO | train_inner | epoch 001:      1 / 32 loss=7.913, sample_size=28, ntokens=29, wps=0, ups=0, wpb=29, bsz=1, num_updates=1, lr=0.002, gnorm=12.345, loss_scale=4, train_wall=3, gb_free=26.1, wall=4\n",
            "2024-03-01 17:00:41 | INFO | train_inner | epoch 001:      2 / 32 loss=7.144, sample_size=20, ntokens=21, wps=14.2, ups=0.68, wpb=21, bsz=1, num_updates=2, lr=0.002, gnorm=17.263, loss_scale=4, train_wall=1, gb_free=25.8, wall=5\n",
            "2024-03-01 17:00:44 | INFO | train_inner | epoch 001:      3 / 32 loss=5.947, sample_size=32, ntokens=33, wps=15.2, ups=0.46, wpb=33, bsz=1, num_updates=3, lr=0.002, gnorm=13.419, loss_scale=4, train_wall=2, gb_free=25.8, wall=7\n",
            "2024-03-01 17:00:47 | INFO | train_inner | epoch 001:      4 / 32 loss=5.741, sample_size=48, ntokens=49, wps=15.6, ups=0.32, wpb=49, bsz=1, num_updates=4, lr=0.002, gnorm=10.056, loss_scale=4, train_wall=3, gb_free=25.8, wall=10\n",
            "2024-03-01 17:00:48 | INFO | train_inner | epoch 001:      5 / 32 loss=6.933, sample_size=21, ntokens=22, wps=15.1, ups=0.69, wpb=22, bsz=1, num_updates=5, lr=0.002, gnorm=14.622, loss_scale=4, train_wall=1, gb_free=25.8, wall=12\n",
            "2024-03-01 17:00:50 | INFO | train_inner | epoch 001:      6 / 32 loss=8.435, sample_size=19, ntokens=20, wps=14.8, ups=0.74, wpb=20, bsz=1, num_updates=6, lr=0.002, gnorm=14.723, loss_scale=4, train_wall=1, gb_free=25.8, wall=13\n",
            "2024-03-01 17:00:53 | INFO | train_inner | epoch 001:      7 / 32 loss=7.423, sample_size=45, ntokens=46, wps=15.5, ups=0.34, wpb=46, bsz=1, num_updates=7, lr=0.002, gnorm=8.212, loss_scale=4, train_wall=3, gb_free=25.8, wall=16\n",
            "2024-03-01 17:00:55 | INFO | train_inner | epoch 001:      8 / 32 loss=6.464, sample_size=44, ntokens=45, wps=15.8, ups=0.35, wpb=45, bsz=1, num_updates=8, lr=0.002, gnorm=10.157, loss_scale=4, train_wall=3, gb_free=25.8, wall=19\n",
            "2024-03-01 17:00:58 | INFO | train_inner | epoch 001:      9 / 32 loss=5.363, sample_size=39, ntokens=40, wps=15.8, ups=0.39, wpb=40, bsz=1, num_updates=9, lr=0.002, gnorm=8.409, loss_scale=4, train_wall=3, gb_free=25.8, wall=22\n",
            "2024-03-01 17:01:00 | INFO | train_inner | epoch 001:     10 / 32 loss=5.287, sample_size=28, ntokens=29, wps=15.3, ups=0.53, wpb=29, bsz=1, num_updates=10, lr=0.002, gnorm=27.777, loss_scale=4, train_wall=2, gb_free=25.8, wall=24\n",
            "2024-03-01 17:01:02 | INFO | train_inner | epoch 001:     11 / 32 loss=5.649, sample_size=29, ntokens=30, wps=15.5, ups=0.52, wpb=30, bsz=1, num_updates=11, lr=0.002, gnorm=10.234, loss_scale=4, train_wall=2, gb_free=25.8, wall=25\n",
            "2024-03-01 17:01:06 | INFO | train_inner | epoch 001:     12 / 32 loss=5.091, sample_size=59, ntokens=60, wps=15.8, ups=0.26, wpb=60, bsz=1, num_updates=12, lr=0.002, gnorm=7.186, loss_scale=4, train_wall=4, gb_free=25.8, wall=29\n",
            "2024-03-01 17:01:08 | INFO | train_inner | epoch 001:     13 / 32 loss=5.69, sample_size=46, ntokens=47, wps=15.8, ups=0.34, wpb=47, bsz=1, num_updates=13, lr=0.002, gnorm=8.006, loss_scale=4, train_wall=3, gb_free=25.8, wall=32\n",
            "2024-03-01 17:01:10 | INFO | train_inner | epoch 001:     14 / 32 loss=7.342, sample_size=30, ntokens=31, wps=15.6, ups=0.5, wpb=31, bsz=1, num_updates=14, lr=0.002, gnorm=10.025, loss_scale=4, train_wall=2, gb_free=25.8, wall=34\n",
            "2024-03-01 17:01:12 | INFO | train_inner | epoch 001:     15 / 32 loss=6.398, sample_size=29, ntokens=30, wps=15.5, ups=0.52, wpb=30, bsz=1, num_updates=15, lr=0.002, gnorm=10.966, loss_scale=4, train_wall=2, gb_free=25.8, wall=36\n",
            "2024-03-01 17:01:14 | INFO | train_inner | epoch 001:     16 / 32 loss=5.913, sample_size=20, ntokens=21, wps=14.9, ups=0.71, wpb=21, bsz=1, num_updates=16, lr=0.002, gnorm=11.565, loss_scale=4, train_wall=1, gb_free=25.8, wall=38\n",
            "2024-03-01 17:01:16 | INFO | train_inner | epoch 001:     17 / 32 loss=6.078, sample_size=31, ntokens=32, wps=15.4, ups=0.48, wpb=32, bsz=1, num_updates=17, lr=0.002, gnorm=14.009, loss_scale=4, train_wall=2, gb_free=25.8, wall=40\n",
            "2024-03-01 17:01:18 | INFO | train_inner | epoch 001:     18 / 32 loss=7.48, sample_size=31, ntokens=32, wps=15.6, ups=0.49, wpb=32, bsz=1, num_updates=18, lr=0.002, gnorm=10.529, loss_scale=4, train_wall=2, gb_free=25.8, wall=42\n",
            "2024-03-01 17:01:22 | INFO | train_inner | epoch 001:     19 / 32 loss=5.433, sample_size=60, ntokens=61, wps=16.2, ups=0.26, wpb=61, bsz=1, num_updates=19, lr=0.002, gnorm=7.903, loss_scale=4, train_wall=4, gb_free=25.8, wall=45\n",
            "2024-03-01 17:01:24 | INFO | train_inner | epoch 001:     20 / 32 loss=5.897, sample_size=41, ntokens=42, wps=15.9, ups=0.38, wpb=42, bsz=1, num_updates=20, lr=0.002, gnorm=9.576, loss_scale=4, train_wall=3, gb_free=25.8, wall=48\n",
            "2024-03-01 17:01:27 | INFO | train_inner | epoch 001:     21 / 32 loss=5.408, sample_size=46, ntokens=47, wps=15.8, ups=0.34, wpb=47, bsz=1, num_updates=21, lr=0.002, gnorm=8.171, loss_scale=4, train_wall=3, gb_free=25.8, wall=51\n",
            "2024-03-01 17:01:29 | INFO | train_inner | epoch 001:     22 / 32 loss=6.243, sample_size=21, ntokens=22, wps=15.2, ups=0.69, wpb=22, bsz=1, num_updates=22, lr=0.002, gnorm=13.99, loss_scale=4, train_wall=1, gb_free=25.8, wall=53\n",
            "2024-03-01 17:01:33 | INFO | train_inner | epoch 001:     23 / 32 loss=5.359, sample_size=68, ntokens=69, wps=16.3, ups=0.24, wpb=69, bsz=1, num_updates=23, lr=0.002, gnorm=6.538, loss_scale=4, train_wall=4, gb_free=25.8, wall=57\n",
            "2024-03-01 17:01:34 | INFO | train_inner | epoch 001:     24 / 32 loss=6.342, sample_size=18, ntokens=19, wps=15.3, ups=0.81, wpb=19, bsz=1, num_updates=24, lr=0.002, gnorm=13.136, loss_scale=4, train_wall=1, gb_free=25.8, wall=58\n",
            "2024-03-01 17:01:36 | INFO | train_inner | epoch 001:     25 / 32 loss=6.572, sample_size=32, ntokens=33, wps=15.8, ups=0.48, wpb=33, bsz=1, num_updates=25, lr=0.002, gnorm=11.833, loss_scale=4, train_wall=2, gb_free=25.8, wall=60\n",
            "2024-03-01 17:01:38 | INFO | train_inner | epoch 001:     26 / 32 loss=5.188, sample_size=26, ntokens=27, wps=15.7, ups=0.58, wpb=27, bsz=1, num_updates=26, lr=0.002, gnorm=10.878, loss_scale=4, train_wall=2, gb_free=25.8, wall=62\n",
            "2024-03-01 17:01:40 | INFO | train_inner | epoch 001:     27 / 32 loss=6.619, sample_size=25, ntokens=26, wps=15.6, ups=0.6, wpb=26, bsz=1, num_updates=27, lr=0.002, gnorm=12.494, loss_scale=4, train_wall=2, gb_free=25.8, wall=63\n",
            "2024-03-01 17:01:42 | INFO | train_inner | epoch 001:     28 / 32 loss=6.21, sample_size=27, ntokens=28, wps=15.8, ups=0.56, wpb=28, bsz=1, num_updates=28, lr=0.002, gnorm=12.697, loss_scale=4, train_wall=2, gb_free=25.8, wall=65\n",
            "2024-03-01 17:01:44 | INFO | train_inner | epoch 001:     29 / 32 loss=5.477, sample_size=38, ntokens=39, wps=16.1, ups=0.41, wpb=39, bsz=1, num_updates=29, lr=0.002, gnorm=10.544, loss_scale=4, train_wall=2, gb_free=25.8, wall=68\n",
            "2024-03-01 17:01:46 | INFO | train_inner | epoch 001:     30 / 32 loss=5.698, sample_size=32, ntokens=33, wps=16, ups=0.49, wpb=33, bsz=1, num_updates=30, lr=0.002, gnorm=12.482, loss_scale=4, train_wall=2, gb_free=25.8, wall=70\n",
            "2024-03-01 17:01:48 | INFO | train_inner | epoch 001:     31 / 32 loss=5.553, sample_size=25, ntokens=26, wps=15.7, ups=0.6, wpb=26, bsz=1, num_updates=31, lr=0.002, gnorm=12.348, loss_scale=4, train_wall=2, gb_free=25.8, wall=71\n",
            "2024-03-01 17:01:49 | INFO | train_inner | epoch 001:     32 / 32 loss=4.914, sample_size=25, ntokens=26, wps=15.6, ups=0.6, wpb=26, bsz=1, num_updates=32, lr=0.002, gnorm=11.703, loss_scale=4, train_wall=2, gb_free=25.8, wall=73\n",
            "2024-03-01 17:01:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 32 updates\n",
            "2024-03-01 17:01:49 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/subj/en_dense_lm_2_7b/0.002/checkpoint1.pt\n",
            "2024-03-01 17:02:32 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/subj/en_dense_lm_2_7b/0.002/checkpoint1.pt\n",
            "2024-03-01 17:03:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/subj/en_dense_lm_2_7b/0.002/checkpoint1.pt (epoch 1 @ 32 updates, score None) (writing took 83.80038803099887 seconds)\n",
            "2024-03-01 17:03:13 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
            "2024-03-01 17:03:13 | INFO | train | epoch 001 | loss 6.038 | sample_size 33.844 | ntokens 34.844 | wps 7.1 | ups 0.2 | wpb 34.8 | bsz 1 | num_updates 32 | lr 0.002 | gnorm 11.681 | loss_scale 4 | train_wall 72 | gb_free 25.8 | wall 157\n",
            "2024-03-01 17:03:13 | INFO | fairseq_cli.train | done training in 156.6 seconds\n",
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/subj/ftzs/record_info.jsonl': No such file or directory\n",
            "+ SEED=4\n",
            "+ TASK=subj\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/subj/en_dense_lm_2_7b/0.002/checkpoint_last.pt\n",
            "+ ARCH=gptmodel_xl\n",
            "+ K=0\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/subj\n",
            "+ ana_setting=ftzs\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' subj = agnews ']'\n",
            "+ '[' subj = trec ']'\n",
            "+ '[' subj = sst5 ']'\n",
            "+ '[' subj = dbpedia ']'\n",
            "+ '[' subj = cb ']'\n",
            "+ '[' subj = arce ']'\n",
            "+ '[' subj = arcc ']'\n",
            "+ '[' subj = obqa ']'\n",
            "+ '[' subj = hellaswag ']'\n",
            "+ '[' subj = storycloze ']'\n",
            "+ '[' subj = raceh ']'\n",
            "+ '[' subj = racem ']'\n",
            "+ '[' subj = nq ']'\n",
            "+ '[' subj = webqs ']'\n",
            "+ '[' subj = triviaqa ']'\n",
            "+ '[' subj = sq2 ']'\n",
            "+ '[' subj = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ BSZ=2\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_eval --arch gptmodel_xl --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --max-epoch 1 --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --max-update 0 --fp16 --eval-data subj --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 4 --reset-dataloader --no-save --k 0 --batch-size 2 --batch-size-valid 2 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/subj/en_dense_lm_2_7b/0.002/checkpoint_last.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/subj --ana-setting ftzs --permut-index 0\n",
            "+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output//train_log_ftzs.txt\n",
            "2024-03-01 17:03:31 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-01 17:03:31 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-01 17:03:31 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-01 17:03:33.151101: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-01 17:03:33.151139: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-01 17:03:33.152647: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-01 17:03:34.361819: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-01 17:03:36 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 4, 'eval_data': 'subj', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/subj', 'ana_setting': 'ftzs', 'optim_group': 'all', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 0, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_xl', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2560, 'decoder_output_dim': 2560, 'decoder_input_dim': 2560, 'decoder_ffn_embed_dim': 10240, 'decoder_layers': 32, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/subj/en_dense_lm_2_7b/0.002/checkpoint_last.pt'}, 'criterion': {'_name': 'fs_eval', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 4, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 2, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 2, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': True, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=4, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_eval', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=2, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid='2', max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_xl', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.25], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=True, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='subj', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/subj', ana_setting='ftzs', optim_group='all', tokens_per_sample=2048, max_target_positions=None, k=0, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/subj/en_dense_lm_2_7b/0.002/checkpoint_last.pt', no_seed_provided=False, decoder_layers=32, decoder_embed_dim=2560, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2560, decoder_output_dim=2560, decoder_ffn_embed_dim=10240, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-01 17:03:36 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-01 17:03:39 | WARNING | datasets.builder | Using custom data configuration SetFit--subj-693a635c625bebac\n",
            "2024-03-01 17:03:39 | WARNING | datasets.builder | Reusing dataset json (/root/.cache/huggingface/datasets/SetFit___json/SetFit--subj-693a635c625bebac/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253)\n",
            "100%|██████████| 2/2 [00:00<00:00, 402.00it/s]\n",
            "2024-03-01 17:03:39 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/SetFit___json/SetFit--subj-693a635c625bebac/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-41679576bb6cfc7c.arrow\n",
            "2024-03-01 17:03:39 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/SetFit___json/SetFit--subj-693a635c625bebac/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-6b58bb8b23415efd.arrow\n",
            "2024-03-01 17:05:20 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-01 17:05:22 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2560, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
            "        (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2560, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-01 17:05:22 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-01 17:05:22 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-01 17:05:22 | INFO | fairseq_cli.train | criterion: FewshotEvalCriterion\n",
            "2024-03-01 17:05:22 | INFO | fairseq_cli.train | num. shared model params: 2,648,724,480 (num. trained: 2,560)\n",
            "2024-03-01 17:05:22 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-01 17:05:26 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-01 17:05:26 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 17:05:26 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-01 17:05:26 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 17:05:26 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-01 17:05:26 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 2\n",
            "2024-03-01 17:05:26 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt\n",
            "2024-03-01 17:05:26 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last.pt\n",
            "2024-03-01 17:05:26 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-01 17:05:26 | INFO | fairseq_cli.train | Start validating\n",
            "2024-03-01 17:05:26 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "------------ example 0 input str valid is ['Input: never giving up the fight to win the war , mcnamara is silently planning , waiting for his moment to strike back at the enemy . Type:', 'Input: never giving up the fight to win the war , mcnamara is silently planning , waiting for his moment to strike back at the enemy . Type:']\n",
            "------------ example 0 label str valid is [' objective', ' subjective']\n",
            "------------ example 1 input str valid is ['Input: if the story lacks bite , the performances are never less than affectionate . Type:', 'Input: if the story lacks bite , the performances are never less than affectionate . Type:']\n",
            "------------ example 1 label str valid is [' objective', ' subjective']\n",
            "NOTE: true K of baseline is 0, max valid len is 174\n",
            "| Loaded valid with 4000 samples\n",
            "| Loaded train with 4000 samples\n",
            "2024-03-01 17:11:18 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.158 | nll_loss 0.103 | accuracy 86 | f1 0 | pos_proportion 51.7 | neg_proportion 48.4 | wps 397.5 | wpb 69.7 | bsz 1 | num_updates 0\n",
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/subj/zs/record_info.jsonl': No such file or directory\n",
            "+ SEED=4\n",
            "+ TASK=subj\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt\n",
            "+ ARCH=gptmodel_xl\n",
            "+ K=0\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/subj\n",
            "+ ana_setting=zs\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' subj = agnews ']'\n",
            "+ '[' subj = trec ']'\n",
            "+ '[' subj = sst5 ']'\n",
            "+ '[' subj = dbpedia ']'\n",
            "+ '[' subj = cb ']'\n",
            "+ '[' subj = arce ']'\n",
            "+ '[' subj = arcc ']'\n",
            "+ '[' subj = obqa ']'\n",
            "+ '[' subj = hellaswag ']'\n",
            "+ '[' subj = storycloze ']'\n",
            "+ '[' subj = raceh ']'\n",
            "+ '[' subj = racem ']'\n",
            "+ '[' subj = nq ']'\n",
            "+ '[' subj = webqs ']'\n",
            "+ '[' subj = triviaqa ']'\n",
            "+ '[' subj = sq2 ']'\n",
            "+ '[' subj = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ BSZ=2\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_eval --arch gptmodel_xl --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --max-epoch 1 --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --max-update 0 --fp16 --eval-data subj --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 4 --reset-dataloader --no-save --k 0 --batch-size 2 --batch-size-valid 2 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/subj --ana-setting zs --permut-index 0\n",
            "+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output//train_log_zs.txt\n",
            "2024-03-01 17:12:00 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-01 17:12:01 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-01 17:12:01 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-01 17:12:04.788521: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-01 17:12:04.788691: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-01 17:12:04.902325: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-01 17:12:07.080376: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-01 17:12:09 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 4, 'eval_data': 'subj', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/subj', 'ana_setting': 'zs', 'optim_group': 'all', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 0, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_xl', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2560, 'decoder_output_dim': 2560, 'decoder_input_dim': 2560, 'decoder_ffn_embed_dim': 10240, 'decoder_layers': 32, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt'}, 'criterion': {'_name': 'fs_eval', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 4, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 2, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 2, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': True, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=4, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_eval', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=2, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid='2', max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_xl', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.25], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=True, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='subj', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/subj', ana_setting='zs', optim_group='all', tokens_per_sample=2048, max_target_positions=None, k=0, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt', no_seed_provided=False, decoder_layers=32, decoder_embed_dim=2560, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2560, decoder_output_dim=2560, decoder_ffn_embed_dim=10240, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-01 17:12:09 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-01 17:12:11 | WARNING | datasets.builder | Using custom data configuration SetFit--subj-693a635c625bebac\n",
            "2024-03-01 17:12:11 | WARNING | datasets.builder | Reusing dataset json (/root/.cache/huggingface/datasets/SetFit___json/SetFit--subj-693a635c625bebac/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253)\n",
            "100%|██████████| 2/2 [00:00<00:00, 374.42it/s]\n",
            "2024-03-01 17:12:11 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/SetFit___json/SetFit--subj-693a635c625bebac/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-41679576bb6cfc7c.arrow\n",
            "2024-03-01 17:12:11 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/SetFit___json/SetFit--subj-693a635c625bebac/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-6b58bb8b23415efd.arrow\n",
            "2024-03-01 17:14:18 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-01 17:14:20 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2560, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
            "        (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2560, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-01 17:14:20 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-01 17:14:20 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-01 17:14:20 | INFO | fairseq_cli.train | criterion: FewshotEvalCriterion\n",
            "2024-03-01 17:14:20 | INFO | fairseq_cli.train | num. shared model params: 2,648,724,480 (num. trained: 2,560)\n",
            "2024-03-01 17:14:20 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-01 17:14:23 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-01 17:14:23 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 17:14:23 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-01 17:14:23 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 17:14:23 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-01 17:14:23 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 2\n",
            "2024-03-01 17:14:23 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt\n",
            "2024-03-01 17:14:23 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last.pt\n",
            "2024-03-01 17:14:23 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-01 17:14:24 | INFO | fairseq_cli.train | Start validating\n",
            "2024-03-01 17:14:24 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "------------ example 0 input str valid is ['Input: never giving up the fight to win the war , mcnamara is silently planning , waiting for his moment to strike back at the enemy . Type:', 'Input: never giving up the fight to win the war , mcnamara is silently planning , waiting for his moment to strike back at the enemy . Type:']\n",
            "------------ example 0 label str valid is [' objective', ' subjective']\n",
            "------------ example 1 input str valid is ['Input: if the story lacks bite , the performances are never less than affectionate . Type:', 'Input: if the story lacks bite , the performances are never less than affectionate . Type:']\n",
            "------------ example 1 label str valid is [' objective', ' subjective']\n",
            "NOTE: true K of baseline is 0, max valid len is 174\n",
            "| Loaded valid with 4000 samples\n",
            "| Loaded train with 4000 samples\n",
            "2024-03-01 17:18:20 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 14.275 | nll_loss 0.205 | accuracy 75.2 | f1 0 | pos_proportion 51.7 | neg_proportion 48.4 | wps 593.5 | wpb 69.7 | bsz 1 | num_updates 0\n",
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/subj/icl/record_info.jsonl': No such file or directory\n",
            "+ SEED=4\n",
            "+ TASK=subj\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt\n",
            "+ ARCH=gptmodel_xl\n",
            "+ K=32\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/subj\n",
            "+ ana_setting=icl\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' subj = agnews ']'\n",
            "+ '[' subj = trec ']'\n",
            "+ '[' subj = sst5 ']'\n",
            "+ '[' subj = dbpedia ']'\n",
            "+ '[' subj = cb ']'\n",
            "+ '[' subj = arce ']'\n",
            "+ '[' subj = arcc ']'\n",
            "+ '[' subj = obqa ']'\n",
            "+ '[' subj = hellaswag ']'\n",
            "+ '[' subj = storycloze ']'\n",
            "+ '[' subj = raceh ']'\n",
            "+ '[' subj = racem ']'\n",
            "+ '[' subj = nq ']'\n",
            "+ '[' subj = webqs ']'\n",
            "+ '[' subj = triviaqa ']'\n",
            "+ '[' subj = sq2 ']'\n",
            "+ '[' subj = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ BSZ=2\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_eval --arch gptmodel_xl --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --max-epoch 1 --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --max-update 0 --fp16 --eval-data subj --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 4 --reset-dataloader --no-save --k 32 --batch-size 2 --batch-size-valid 2 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/subj --ana-setting icl --permut-index 0\n",
            "+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output//train_log_icl.txt\n",
            "2024-03-01 17:18:54 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-01 17:18:54 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-01 17:18:54 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-01 17:18:56.110096: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-01 17:18:56.110185: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-01 17:18:56.113797: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-01 17:18:57.337033: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-01 17:18:59 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 4, 'eval_data': 'subj', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/subj', 'ana_setting': 'icl', 'optim_group': 'all', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 32, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_xl', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2560, 'decoder_output_dim': 2560, 'decoder_input_dim': 2560, 'decoder_ffn_embed_dim': 10240, 'decoder_layers': 32, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt'}, 'criterion': {'_name': 'fs_eval', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 4, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 2, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 2, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': True, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=4, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_eval', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=2, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid='2', max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_xl', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.25], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=True, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='subj', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/subj', ana_setting='icl', optim_group='all', tokens_per_sample=2048, max_target_positions=None, k=32, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt', no_seed_provided=False, decoder_layers=32, decoder_embed_dim=2560, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2560, decoder_output_dim=2560, decoder_ffn_embed_dim=10240, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-01 17:18:59 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-01 17:19:02 | WARNING | datasets.builder | Using custom data configuration SetFit--subj-693a635c625bebac\n",
            "2024-03-01 17:19:02 | WARNING | datasets.builder | Reusing dataset json (/root/.cache/huggingface/datasets/SetFit___json/SetFit--subj-693a635c625bebac/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253)\n",
            "100%|██████████| 2/2 [00:00<00:00, 385.17it/s]\n",
            "2024-03-01 17:19:02 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/SetFit___json/SetFit--subj-693a635c625bebac/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-41679576bb6cfc7c.arrow\n",
            "2024-03-01 17:19:02 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/SetFit___json/SetFit--subj-693a635c625bebac/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-6b58bb8b23415efd.arrow\n",
            "2024-03-01 17:20:10 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-01 17:20:12 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2560, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
            "        (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2560, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-01 17:20:12 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-01 17:20:12 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-01 17:20:12 | INFO | fairseq_cli.train | criterion: FewshotEvalCriterion\n",
            "2024-03-01 17:20:12 | INFO | fairseq_cli.train | num. shared model params: 2,648,724,480 (num. trained: 2,560)\n",
            "2024-03-01 17:20:12 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-01 17:20:15 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-01 17:20:15 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 17:20:15 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-01 17:20:15 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 17:20:15 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-01 17:20:15 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 2\n",
            "2024-03-01 17:20:15 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt\n",
            "2024-03-01 17:20:15 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last.pt\n",
            "2024-03-01 17:20:15 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-01 17:20:15 | INFO | fairseq_cli.train | Start validating\n",
            "2024-03-01 17:20:15 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "------------ example 0 input str train is ['Input: a spellbinding african film about the modern condition of rootlessness , a state experienced by millions around the globe . Type:', 'Input: a spellbinding african film about the modern condition of rootlessness , a state experienced by millions around the globe . Type:']\n",
            "------------ example 0 label str train is [' objective', ' subjective']\n",
            "------------ example 1 input str train is [\"Input: and if she 's lucky , she may find love along the way . Type:\", \"Input: and if she 's lucky , she may find love along the way . Type:\"]\n",
            "------------ example 1 label str train is [' objective', ' subjective']\n",
            "------------ example 0 input str valid is ['Input: never giving up the fight to win the war , mcnamara is silently planning , waiting for his moment to strike back at the enemy . Type:', 'Input: never giving up the fight to win the war , mcnamara is silently planning , waiting for his moment to strike back at the enemy . Type:']\n",
            "------------ example 0 label str valid is [' objective', ' subjective']\n",
            "------------ example 1 input str valid is ['Input: if the story lacks bite , the performances are never less than affectionate . Type:', 'Input: if the story lacks bite , the performances are never less than affectionate . Type:']\n",
            "------------ example 1 label str valid is [' objective', ' subjective']\n",
            "NOTE: true K of baseline is 32, max valid len is 174\n",
            "| Loaded valid with 4000 samples\n",
            "| Loaded train with 4000 samples\n",
            "2024-03-01 17:26:28 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 0.651 | nll_loss 0 | accuracy 90.3 | f1 0 | pos_proportion 51.7 | neg_proportion 48.4 | wps 12376.7 | wpb 2299.7 | bsz 1 | num_updates 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash run.sh en_dense_lm_2_7b gptmodel_xl agnews 32 3 0 \"{icl_base_dir}output\" \"{icl_base_dir}\" 0.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NbCUTcauaDo",
        "outputId": "a380b3c0-1f2b-46db-d501-a5df29c55405"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/agnews/ft/record_info.jsonl': No such file or directory\n",
            "+ SEED=3\n",
            "+ TASK=agnews\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt\n",
            "+ ARCH=gptmodel_xl\n",
            "+ K=32\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/agnews\n",
            "+ ana_setting=ft\n",
            "+ lr=0.2\n",
            "+ max_epoch=1\n",
            "+ save_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/agnews/en_dense_lm_2_7b/0.2\n",
            "+ optim_group=attn_kv\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' agnews = agnews ']'\n",
            "+ N_CLASSES=4\n",
            "+ '[' agnews = trec ']'\n",
            "+ '[' agnews = sst5 ']'\n",
            "+ '[' agnews = dbpedia ']'\n",
            "+ '[' agnews = cb ']'\n",
            "+ '[' agnews = arce ']'\n",
            "+ '[' agnews = arcc ']'\n",
            "+ '[' agnews = obqa ']'\n",
            "+ '[' agnews = hellaswag ']'\n",
            "+ '[' agnews = storycloze ']'\n",
            "+ '[' agnews = raceh ']'\n",
            "+ '[' agnews = racem ']'\n",
            "+ '[' agnews = nq ']'\n",
            "+ '[' agnews = webqs ']'\n",
            "+ '[' agnews = triviaqa ']'\n",
            "+ '[' agnews = sq2 ']'\n",
            "+ '[' agnews = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ ORI_BSZ=1\n",
            "+ BSZ=4\n",
            "+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/train_log_ft.txt\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_ft --arch gptmodel_xl --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --lr 0.2 --max-epoch 1 --curriculum 1000000 --max-update 1000000 --fp16 --eval-data agnews --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 3 --reset-dataloader --k 32 --batch-size 1 --batch-size-valid 1 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/agnews --ana-setting ft --save-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/agnews/en_dense_lm_2_7b/0.2 --save-interval 1 --save-interval-updates 1000000 --validate-interval 1000000 --disable-validation --optim-group attn_kv --permut-index 0\n",
            "2024-03-02 07:08:39 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-02 07:09:49 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-02 07:09:49 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-02 07:10:04.154863: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-02 07:10:04.154912: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-02 07:10:04.156504: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-02 07:10:05.371905: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-02 07:10:19 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 3, 'eval_data': 'agnews', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/agnews', 'ana_setting': 'ft', 'optim_group': 'attn_kv', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 32, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_xl', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2560, 'decoder_output_dim': 2560, 'decoder_input_dim': 2560, 'decoder_ffn_embed_dim': 10240, 'decoder_layers': 32, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt'}, 'criterion': {'_name': 'fs_ft', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.2]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 3, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1000000, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': None, 'batch_size_valid': 1, 'max_valid_steps': None, 'curriculum': 1000000, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 1000000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.2], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/agnews/en_dense_lm_2_7b/0.2', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 1000000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=3, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_ft', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=1, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1000000, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=True, max_tokens_valid=None, batch_size_valid='1', max_valid_steps=None, curriculum=1000000, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_xl', max_epoch=1, max_update=1000000, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.2], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/agnews/en_dense_lm_2_7b/0.2', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=1000000, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='agnews', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/agnews', ana_setting='ft', optim_group='attn_kv', tokens_per_sample=2048, max_target_positions=None, k=32, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt', no_seed_provided=False, decoder_layers=32, decoder_embed_dim=2560, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2560, decoder_output_dim=2560, decoder_ffn_embed_dim=10240, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-02 07:10:20 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "Downloading builder script: 4.06kB [00:00, 12.3MB/s]                   \n",
            "Downloading metadata: 2.65kB [00:00, 9.73MB/s]                   \n",
            "2024-03-02 07:10:23 | WARNING | datasets.builder | Using custom data configuration default\n",
            "Downloading and preparing dataset ag_news/default (download: 29.88 MiB, generated: 30.23 MiB, post-processed: Unknown size, total: 60.10 MiB) to /root/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548...\n",
            "Downloading data: 29.5MB [00:00, 59.6MB/s]\n",
            "Downloading data: 1.86MB [00:00, 31.1MB/s]                  \n",
            "Dataset ag_news downloaded and prepared to /root/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548. Subsequent calls will reuse this data.\n",
            "100%|██████████| 2/2 [00:00<00:00, 353.98it/s]\n",
            "------------ example 0 input str train is ['Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Can Klitschko Establish Himself as the Best against Williams? December 8, 2004. Vitali Klitschko is recognized by Ring Magazine as the Heavyweight Champion of the World. HBO Sports would also like you to believe it. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Can Klitschko Establish Himself as the Best against Williams? December 8, 2004. Vitali Klitschko is recognized by Ring Magazine as the Heavyweight Champion of the World. HBO Sports would also like you to believe it. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Can Klitschko Establish Himself as the Best against Williams? December 8, 2004. Vitali Klitschko is recognized by Ring Magazine as the Heavyweight Champion of the World. HBO Sports would also like you to believe it. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Can Klitschko Establish Himself as the Best against Williams? December 8, 2004. Vitali Klitschko is recognized by Ring Magazine as the Heavyweight Champion of the World. HBO Sports would also like you to believe it. Answer:']\n",
            "------------ example 0 label str train is [' World', ' Sports', ' Business', ' Technology']\n",
            "------------ example 1 input str train is ['Classify the news articles into the categories of World, Sports, Business, and Technology. Article: China to Introduce Anti-Secession Law, Eyes Taiwan  BEIJING (Reuters) - China is to introduce legislation  against secession, state media reported on Friday, a move  analysts have said is aimed at mandating eventual reunification  with rival Taiwan. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: China to Introduce Anti-Secession Law, Eyes Taiwan  BEIJING (Reuters) - China is to introduce legislation  against secession, state media reported on Friday, a move  analysts have said is aimed at mandating eventual reunification  with rival Taiwan. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: China to Introduce Anti-Secession Law, Eyes Taiwan  BEIJING (Reuters) - China is to introduce legislation  against secession, state media reported on Friday, a move  analysts have said is aimed at mandating eventual reunification  with rival Taiwan. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: China to Introduce Anti-Secession Law, Eyes Taiwan  BEIJING (Reuters) - China is to introduce legislation  against secession, state media reported on Friday, a move  analysts have said is aimed at mandating eventual reunification  with rival Taiwan. Answer:']\n",
            "------------ example 1 label str train is [' World', ' Sports', ' Business', ' Technology']\n",
            "------------ example 0 input str valid is ['Classify the news articles into the categories of World, Sports, Business, and Technology. Article: American Express sues credit card rivals American Express is suing Visa and MasterCard plus eight US banks, claiming anti-competitive tactics kept it out of the market. The litigation is the latest setback for Visa and MasterCard, which last month  Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: American Express sues credit card rivals American Express is suing Visa and MasterCard plus eight US banks, claiming anti-competitive tactics kept it out of the market. The litigation is the latest setback for Visa and MasterCard, which last month  Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: American Express sues credit card rivals American Express is suing Visa and MasterCard plus eight US banks, claiming anti-competitive tactics kept it out of the market. The litigation is the latest setback for Visa and MasterCard, which last month  Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: American Express sues credit card rivals American Express is suing Visa and MasterCard plus eight US banks, claiming anti-competitive tactics kept it out of the market. The litigation is the latest setback for Visa and MasterCard, which last month  Answer:']\n",
            "------------ example 0 label str valid is [' World', ' Sports', ' Business', ' Technology']\n",
            "------------ example 1 input str valid is ['Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Producer Price Surge Fuels Inflation Fears Producer prices surged 1.7 percent in October, their sharpest monthly increase in nearly 15 years. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Producer Price Surge Fuels Inflation Fears Producer prices surged 1.7 percent in October, their sharpest monthly increase in nearly 15 years. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Producer Price Surge Fuels Inflation Fears Producer prices surged 1.7 percent in October, their sharpest monthly increase in nearly 15 years. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Producer Price Surge Fuels Inflation Fears Producer prices surged 1.7 percent in October, their sharpest monthly increase in nearly 15 years. Answer:']\n",
            "------------ example 1 label str valid is [' World', ' Sports', ' Business', ' Technology']\n",
            "NOTE: true K of baseline is 22, max valid len is 237\n",
            "------------ example 0 input str train is ['Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Can Klitschko Establish Himself as the Best against Williams? December 8, 2004. Vitali Klitschko is recognized by Ring Magazine as the Heavyweight Champion of the World. HBO Sports would also like you to believe it. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Can Klitschko Establish Himself as the Best against Williams? December 8, 2004. Vitali Klitschko is recognized by Ring Magazine as the Heavyweight Champion of the World. HBO Sports would also like you to believe it. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Can Klitschko Establish Himself as the Best against Williams? December 8, 2004. Vitali Klitschko is recognized by Ring Magazine as the Heavyweight Champion of the World. HBO Sports would also like you to believe it. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Can Klitschko Establish Himself as the Best against Williams? December 8, 2004. Vitali Klitschko is recognized by Ring Magazine as the Heavyweight Champion of the World. HBO Sports would also like you to believe it. Answer:']\n",
            "------------ example 0 label str train is [' World', ' Sports', ' Business', ' Technology']\n",
            "2024-03-02 07:12:23 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-02 07:12:27 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2560, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
            "        (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2560, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-02 07:12:27 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-02 07:12:27 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-02 07:12:27 | INFO | fairseq_cli.train | criterion: FewshotFTCriterion\n",
            "2024-03-02 07:12:27 | INFO | fairseq_cli.train | num. shared model params: 2,648,724,480 (num. trained: 2,648,724,480)\n",
            "2024-03-02 07:12:27 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-02 07:12:30 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-02 07:12:30 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-02 07:12:30 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-02 07:12:30 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-02 07:12:30 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-02 07:12:30 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 1\n",
            "2024-03-02 07:12:30 | INFO | fairseq.trainer | Preparing to load checkpoint /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/agnews/en_dense_lm_2_7b/0.2/checkpoint_last.pt\n",
            "2024-03-02 07:12:30 | INFO | fairseq.trainer | No existing checkpoint found /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/agnews/en_dense_lm_2_7b/0.2/checkpoint_last.pt\n",
            "2024-03-02 07:12:30 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-02 07:12:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 32\n",
            "2024-03-02 07:12:30 | INFO | fairseq.trainer | begin training epoch 1\n",
            "2024-03-02 07:12:30 | INFO | fairseq_cli.train | Start fine-tuning\n",
            "------------ example 1 input str train is ['Classify the news articles into the categories of World, Sports, Business, and Technology. Article: China to Introduce Anti-Secession Law, Eyes Taiwan  BEIJING (Reuters) - China is to introduce legislation  against secession, state media reported on Friday, a move  analysts have said is aimed at mandating eventual reunification  with rival Taiwan. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: China to Introduce Anti-Secession Law, Eyes Taiwan  BEIJING (Reuters) - China is to introduce legislation  against secession, state media reported on Friday, a move  analysts have said is aimed at mandating eventual reunification  with rival Taiwan. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: China to Introduce Anti-Secession Law, Eyes Taiwan  BEIJING (Reuters) - China is to introduce legislation  against secession, state media reported on Friday, a move  analysts have said is aimed at mandating eventual reunification  with rival Taiwan. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: China to Introduce Anti-Secession Law, Eyes Taiwan  BEIJING (Reuters) - China is to introduce legislation  against secession, state media reported on Friday, a move  analysts have said is aimed at mandating eventual reunification  with rival Taiwan. Answer:']\n",
            "------------ example 1 label str train is [' World', ' Sports', ' Business', ' Technology']\n",
            "NOTE: true K of baseline is 32\n",
            "| Loaded valid with 8000 samples\n",
            "| Loaded train with 32 samples\n",
            "2024-03-02 07:12:36 | INFO | train_inner | epoch 001:      1 / 32 loss=5.146, sample_size=70, ntokens=71, wps=0, ups=0, wpb=71, bsz=1, num_updates=1, lr=0.2, gnorm=8.467, loss_scale=4, train_wall=6, gb_free=26.1, wall=7\n",
            "2024-03-02 07:12:41 | INFO | train_inner | epoch 001:      2 / 32 loss=8.746, sample_size=77, ntokens=78, wps=16.2, ups=0.21, wpb=78, bsz=1, num_updates=2, lr=0.2, gnorm=21.033, loss_scale=4, train_wall=5, gb_free=25.8, wall=11\n",
            "2024-03-02 07:12:47 | INFO | train_inner | epoch 001:      3 / 32 loss=8.364, sample_size=89, ntokens=90, wps=14.3, ups=0.16, wpb=90, bsz=1, num_updates=3, lr=0.2, gnorm=6.619, loss_scale=4, train_wall=6, gb_free=25.8, wall=18\n",
            "2024-03-02 07:12:57 | INFO | train_inner | epoch 001:      4 / 32 loss=6.094, sample_size=159, ntokens=160, wps=16.6, ups=0.1, wpb=160, bsz=1, num_updates=4, lr=0.2, gnorm=5.732, loss_scale=4, train_wall=10, gb_free=25.8, wall=27\n",
            "2024-03-02 07:13:01 | INFO | train_inner | epoch 001:      5 / 32 loss=4.651, sample_size=72, ntokens=73, wps=16.3, ups=0.22, wpb=73, bsz=1, num_updates=5, lr=0.2, gnorm=3.719, loss_scale=4, train_wall=4, gb_free=25.8, wall=32\n",
            "2024-03-02 07:13:05 | INFO | train_inner | epoch 001:      6 / 32 loss=5.328, sample_size=60, ntokens=61, wps=16.5, ups=0.27, wpb=61, bsz=1, num_updates=6, lr=0.2, gnorm=4.718, loss_scale=4, train_wall=4, gb_free=25.8, wall=36\n",
            "2024-03-02 07:13:10 | INFO | train_inner | epoch 001:      7 / 32 loss=5.563, sample_size=84, ntokens=85, wps=16.8, ups=0.2, wpb=85, bsz=1, num_updates=7, lr=0.2, gnorm=15.91, loss_scale=4, train_wall=5, gb_free=25.8, wall=41\n",
            "2024-03-02 07:13:13 | INFO | train_inner | epoch 001:      8 / 32 loss=5.736, sample_size=50, ntokens=51, wps=16.4, ups=0.32, wpb=51, bsz=1, num_updates=8, lr=0.2, gnorm=4.699, loss_scale=4, train_wall=3, gb_free=25.8, wall=44\n",
            "2024-03-02 07:13:18 | INFO | train_inner | epoch 001:      9 / 32 loss=6.03, sample_size=81, ntokens=82, wps=17, ups=0.21, wpb=82, bsz=1, num_updates=9, lr=0.2, gnorm=4.623, loss_scale=4, train_wall=5, gb_free=25.8, wall=49\n",
            "2024-03-02 07:13:23 | INFO | train_inner | epoch 001:     10 / 32 loss=4.096, sample_size=77, ntokens=78, wps=16.8, ups=0.22, wpb=78, bsz=1, num_updates=10, lr=0.2, gnorm=4.474, loss_scale=4, train_wall=5, gb_free=25.8, wall=53\n",
            "2024-03-02 07:13:27 | INFO | train_inner | epoch 001:     11 / 32 loss=6.074, sample_size=75, ntokens=76, wps=16.7, ups=0.22, wpb=76, bsz=1, num_updates=11, lr=0.2, gnorm=5.943, loss_scale=4, train_wall=5, gb_free=25.8, wall=58\n",
            "2024-03-02 07:13:32 | INFO | train_inner | epoch 001:     12 / 32 loss=5.129, sample_size=70, ntokens=71, wps=16.8, ups=0.24, wpb=71, bsz=1, num_updates=12, lr=0.2, gnorm=3.89, loss_scale=4, train_wall=4, gb_free=25.8, wall=62\n",
            "2024-03-02 07:13:37 | INFO | train_inner | epoch 001:     13 / 32 loss=4.094, sample_size=91, ntokens=92, wps=16.9, ups=0.18, wpb=92, bsz=1, num_updates=13, lr=0.2, gnorm=3.695, loss_scale=4, train_wall=5, gb_free=25.8, wall=67\n",
            "2024-03-02 07:13:41 | INFO | train_inner | epoch 001:     14 / 32 loss=4.81, sample_size=60, ntokens=61, wps=16.9, ups=0.28, wpb=61, bsz=1, num_updates=14, lr=0.2, gnorm=4.34, loss_scale=4, train_wall=4, gb_free=25.8, wall=71\n",
            "2024-03-02 07:13:46 | INFO | train_inner | epoch 001:     15 / 32 loss=4.152, sample_size=92, ntokens=93, wps=17, ups=0.18, wpb=93, bsz=1, num_updates=15, lr=0.2, gnorm=4.402, loss_scale=4, train_wall=5, gb_free=25.8, wall=77\n",
            "2024-03-02 07:13:51 | INFO | train_inner | epoch 001:     16 / 32 loss=3.941, sample_size=74, ntokens=75, wps=16.9, ups=0.22, wpb=75, bsz=1, num_updates=16, lr=0.2, gnorm=3.606, loss_scale=4, train_wall=4, gb_free=25.8, wall=81\n",
            "2024-03-02 07:13:54 | INFO | train_inner | epoch 001:     17 / 32 loss=2.906, sample_size=64, ntokens=65, wps=16.8, ups=0.26, wpb=65, bsz=1, num_updates=17, lr=0.2, gnorm=3.417, loss_scale=4, train_wall=4, gb_free=25.8, wall=85\n",
            "2024-03-02 07:13:59 | INFO | train_inner | epoch 001:     18 / 32 loss=3.045, sample_size=76, ntokens=77, wps=16.9, ups=0.22, wpb=77, bsz=1, num_updates=18, lr=0.2, gnorm=4.139, loss_scale=4, train_wall=5, gb_free=25.8, wall=89\n",
            "2024-03-02 07:14:03 | INFO | train_inner | epoch 001:     19 / 32 loss=4.048, sample_size=71, ntokens=72, wps=17.2, ups=0.24, wpb=72, bsz=1, num_updates=19, lr=0.2, gnorm=5.667, loss_scale=4, train_wall=4, gb_free=25.8, wall=94\n",
            "2024-03-02 07:14:08 | INFO | train_inner | epoch 001:     20 / 32 loss=4.157, sample_size=85, ntokens=86, wps=17, ups=0.2, wpb=86, bsz=1, num_updates=20, lr=0.2, gnorm=4.165, loss_scale=4, train_wall=5, gb_free=25.8, wall=99\n",
            "2024-03-02 07:14:12 | INFO | train_inner | epoch 001:     21 / 32 loss=3.019, sample_size=66, ntokens=67, wps=16.7, ups=0.25, wpb=67, bsz=1, num_updates=21, lr=0.2, gnorm=3.487, loss_scale=4, train_wall=4, gb_free=25.8, wall=103\n",
            "2024-03-02 07:14:18 | INFO | train_inner | epoch 001:     22 / 32 loss=3.941, sample_size=93, ntokens=94, wps=17, ups=0.18, wpb=94, bsz=1, num_updates=22, lr=0.2, gnorm=3.582, loss_scale=4, train_wall=6, gb_free=25.8, wall=108\n",
            "2024-03-02 07:14:23 | INFO | train_inner | epoch 001:     23 / 32 loss=4.545, sample_size=80, ntokens=81, wps=17, ups=0.21, wpb=81, bsz=1, num_updates=23, lr=0.2, gnorm=6.501, loss_scale=4, train_wall=5, gb_free=25.8, wall=113\n",
            "2024-03-02 07:14:26 | INFO | train_inner | epoch 001:     24 / 32 loss=3.796, sample_size=64, ntokens=65, wps=16.9, ups=0.26, wpb=65, bsz=1, num_updates=24, lr=0.2, gnorm=3.981, loss_scale=4, train_wall=4, gb_free=25.8, wall=117\n",
            "2024-03-02 07:14:30 | INFO | train_inner | epoch 001:     25 / 32 loss=3.684, sample_size=63, ntokens=64, wps=16.7, ups=0.26, wpb=64, bsz=1, num_updates=25, lr=0.2, gnorm=4.366, loss_scale=4, train_wall=4, gb_free=25.8, wall=121\n",
            "2024-03-02 07:14:35 | INFO | train_inner | epoch 001:     26 / 32 loss=2.885, sample_size=88, ntokens=89, wps=17, ups=0.19, wpb=89, bsz=1, num_updates=26, lr=0.2, gnorm=3.694, loss_scale=4, train_wall=5, gb_free=25.8, wall=126\n",
            "2024-03-02 07:14:40 | INFO | train_inner | epoch 001:     27 / 32 loss=3.699, sample_size=71, ntokens=72, wps=17, ups=0.24, wpb=72, bsz=1, num_updates=27, lr=0.2, gnorm=6.338, loss_scale=4, train_wall=4, gb_free=25.8, wall=130\n",
            "2024-03-02 07:14:43 | INFO | train_inner | epoch 001:     28 / 32 loss=3.386, sample_size=55, ntokens=56, wps=16.7, ups=0.3, wpb=56, bsz=1, num_updates=28, lr=0.2, gnorm=4.966, loss_scale=4, train_wall=3, gb_free=25.8, wall=133\n",
            "2024-03-02 07:14:48 | INFO | train_inner | epoch 001:     29 / 32 loss=3.971, sample_size=80, ntokens=81, wps=17, ups=0.21, wpb=81, bsz=1, num_updates=29, lr=0.2, gnorm=6.63, loss_scale=4, train_wall=5, gb_free=25.8, wall=138\n",
            "2024-03-02 07:14:52 | INFO | train_inner | epoch 001:     30 / 32 loss=3.939, sample_size=66, ntokens=67, wps=17, ups=0.25, wpb=67, bsz=1, num_updates=30, lr=0.2, gnorm=5.023, loss_scale=4, train_wall=4, gb_free=25.8, wall=142\n",
            "2024-03-02 07:14:56 | INFO | train_inner | epoch 001:     31 / 32 loss=3.125, sample_size=68, ntokens=69, wps=17, ups=0.25, wpb=69, bsz=1, num_updates=31, lr=0.2, gnorm=3.337, loss_scale=4, train_wall=4, gb_free=25.8, wall=146\n",
            "2024-03-02 07:14:59 | INFO | train_inner | epoch 001:     32 / 32 loss=4.498, sample_size=56, ntokens=57, wps=16.6, ups=0.29, wpb=57, bsz=1, num_updates=32, lr=0.2, gnorm=5.149, loss_scale=4, train_wall=3, gb_free=25.8, wall=150\n",
            "2024-03-02 07:14:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 32 updates\n",
            "2024-03-02 07:14:59 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/agnews/en_dense_lm_2_7b/0.2/checkpoint1.pt\n",
            "2024-03-02 07:15:41 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/agnews/en_dense_lm_2_7b/0.2/checkpoint1.pt\n",
            "2024-03-02 07:16:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/agnews/en_dense_lm_2_7b/0.2/checkpoint1.pt (epoch 1 @ 32 updates, score None) (writing took 81.46078617399985 seconds)\n",
            "2024-03-02 07:16:21 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
            "2024-03-02 07:16:21 | INFO | train | epoch 001 | loss 4.663 | sample_size 75.844 | ntokens 76.844 | wps 10.6 | ups 0.14 | wpb 76.8 | bsz 1 | num_updates 32 | lr 0.2 | gnorm 5.635 | loss_scale 4 | train_wall 149 | gb_free 25.8 | wall 231\n",
            "2024-03-02 07:16:21 | INFO | fairseq_cli.train | done training in 230.9 seconds\n",
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/agnews/ftzs/record_info.jsonl': No such file or directory\n",
            "+ SEED=3\n",
            "+ TASK=agnews\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/agnews/en_dense_lm_2_7b/0.2/checkpoint_last.pt\n",
            "+ ARCH=gptmodel_xl\n",
            "+ K=0\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/agnews\n",
            "+ ana_setting=ftzs\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' agnews = agnews ']'\n",
            "+ N_CLASSES=4\n",
            "+ '[' agnews = trec ']'\n",
            "+ '[' agnews = sst5 ']'\n",
            "+ '[' agnews = dbpedia ']'\n",
            "+ '[' agnews = cb ']'\n",
            "+ '[' agnews = arce ']'\n",
            "+ '[' agnews = arcc ']'\n",
            "+ '[' agnews = obqa ']'\n",
            "+ '[' agnews = hellaswag ']'\n",
            "+ '[' agnews = storycloze ']'\n",
            "+ '[' agnews = raceh ']'\n",
            "+ '[' agnews = racem ']'\n",
            "+ '[' agnews = nq ']'\n",
            "+ '[' agnews = webqs ']'\n",
            "+ '[' agnews = triviaqa ']'\n",
            "+ '[' agnews = sq2 ']'\n",
            "+ '[' agnews = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ BSZ=4\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_eval --arch gptmodel_xl --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --max-epoch 1 --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --max-update 0 --fp16 --eval-data agnews --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 3 --reset-dataloader --no-save --k 0 --batch-size 4 --batch-size-valid 4 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/agnews/en_dense_lm_2_7b/0.2/checkpoint_last.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/agnews --ana-setting ftzs --permut-index 0\n",
            "+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/train_log_ftzs.txt\n",
            "2024-03-02 07:16:44 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-02 07:16:45 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-02 07:16:45 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-02 07:16:47.082728: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-02 07:16:47.082781: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-02 07:16:47.084545: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-02 07:16:48.354297: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-02 07:16:50 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 3, 'eval_data': 'agnews', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/agnews', 'ana_setting': 'ftzs', 'optim_group': 'all', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 0, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_xl', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2560, 'decoder_output_dim': 2560, 'decoder_input_dim': 2560, 'decoder_ffn_embed_dim': 10240, 'decoder_layers': 32, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/agnews/en_dense_lm_2_7b/0.2/checkpoint_last.pt'}, 'criterion': {'_name': 'fs_eval', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 3, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 4, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 4, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': True, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=3, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_eval', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=4, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid='4', max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_xl', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.25], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=True, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='agnews', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/agnews', ana_setting='ftzs', optim_group='all', tokens_per_sample=2048, max_target_positions=None, k=0, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/agnews/en_dense_lm_2_7b/0.2/checkpoint_last.pt', no_seed_provided=False, decoder_layers=32, decoder_embed_dim=2560, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2560, decoder_output_dim=2560, decoder_ffn_embed_dim=10240, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-02 07:16:50 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-02 07:16:53 | WARNING | datasets.builder | Using custom data configuration default\n",
            "2024-03-02 07:16:53 | WARNING | datasets.builder | Reusing dataset ag_news (/root/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n",
            "100%|██████████| 2/2 [00:00<00:00, 330.48it/s]\n",
            "2024-03-02 07:16:53 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548/cache-07b028a45ecfcdf7.arrow\n",
            "2024-03-02 07:16:53 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548/cache-f83bc7f828dbfa43.arrow\n",
            "2024-03-02 07:18:45 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-02 07:18:47 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2560, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
            "        (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2560, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-02 07:18:47 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-02 07:18:47 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-02 07:18:47 | INFO | fairseq_cli.train | criterion: FewshotEvalCriterion\n",
            "2024-03-02 07:18:47 | INFO | fairseq_cli.train | num. shared model params: 2,648,724,480 (num. trained: 2,560)\n",
            "2024-03-02 07:18:47 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-02 07:18:51 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-02 07:18:51 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-02 07:18:51 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-02 07:18:51 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-02 07:18:51 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-02 07:18:51 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 4\n",
            "2024-03-02 07:18:51 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt\n",
            "2024-03-02 07:18:51 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last.pt\n",
            "2024-03-02 07:18:51 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-02 07:18:51 | INFO | fairseq_cli.train | Start validating\n",
            "2024-03-02 07:18:51 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "------------ example 0 input str valid is ['Classify the news articles into the categories of World, Sports, Business, and Technology. Article: American Express sues credit card rivals American Express is suing Visa and MasterCard plus eight US banks, claiming anti-competitive tactics kept it out of the market. The litigation is the latest setback for Visa and MasterCard, which last month  Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: American Express sues credit card rivals American Express is suing Visa and MasterCard plus eight US banks, claiming anti-competitive tactics kept it out of the market. The litigation is the latest setback for Visa and MasterCard, which last month  Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: American Express sues credit card rivals American Express is suing Visa and MasterCard plus eight US banks, claiming anti-competitive tactics kept it out of the market. The litigation is the latest setback for Visa and MasterCard, which last month  Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: American Express sues credit card rivals American Express is suing Visa and MasterCard plus eight US banks, claiming anti-competitive tactics kept it out of the market. The litigation is the latest setback for Visa and MasterCard, which last month  Answer:']\n",
            "------------ example 0 label str valid is [' World', ' Sports', ' Business', ' Technology']\n",
            "------------ example 1 input str valid is ['Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Producer Price Surge Fuels Inflation Fears Producer prices surged 1.7 percent in October, their sharpest monthly increase in nearly 15 years. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Producer Price Surge Fuels Inflation Fears Producer prices surged 1.7 percent in October, their sharpest monthly increase in nearly 15 years. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Producer Price Surge Fuels Inflation Fears Producer prices surged 1.7 percent in October, their sharpest monthly increase in nearly 15 years. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Producer Price Surge Fuels Inflation Fears Producer prices surged 1.7 percent in October, their sharpest monthly increase in nearly 15 years. Answer:']\n",
            "------------ example 1 label str valid is [' World', ' Sports', ' Business', ' Technology']\n",
            "NOTE: true K of baseline is 0, max valid len is 237\n",
            "| Loaded valid with 8000 samples\n",
            "| Loaded train with 8000 samples\n",
            "2024-03-02 07:25:25 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 3.94 | nll_loss 0.013 | accuracy 53.9 | f1 0 | pos_proportion 25.3 | neg_proportion 23.5 | wps 1531.5 | wpb 300 | bsz 1 | num_updates 0\n",
            "+ SEED=3\n",
            "+ TASK=agnews\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt\n",
            "+ ARCH=gptmodel_xl\n",
            "+ K=0\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/agnews\n",
            "+ ana_setting=zs\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' agnews = agnews ']'\n",
            "+ N_CLASSES=4\n",
            "+ '[' agnews = trec ']'\n",
            "+ '[' agnews = sst5 ']'\n",
            "+ '[' agnews = dbpedia ']'\n",
            "+ '[' agnews = cb ']'\n",
            "+ '[' agnews = arce ']'\n",
            "+ '[' agnews = arcc ']'\n",
            "+ '[' agnews = obqa ']'\n",
            "+ '[' agnews = hellaswag ']'\n",
            "+ '[' agnews = storycloze ']'\n",
            "+ '[' agnews = raceh ']'\n",
            "+ '[' agnews = racem ']'\n",
            "+ '[' agnews = nq ']'\n",
            "+ '[' agnews = webqs ']'\n",
            "+ '[' agnews = triviaqa ']'\n",
            "+ '[' agnews = sq2 ']'\n",
            "+ '[' agnews = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ BSZ=4\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_eval --arch gptmodel_xl --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --max-epoch 1 --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --max-update 0 --fp16 --eval-data agnews --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 3 --reset-dataloader --no-save --k 0 --batch-size 4 --batch-size-valid 4 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/agnews --ana-setting zs --permut-index 0\n",
            "+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/train_log_zs.txt\n",
            "2024-03-02 07:28:18 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-02 07:29:23 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-02 07:29:23 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-02 07:29:40.655879: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-02 07:29:40.655933: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-02 07:29:40.662412: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-02 07:29:42.011619: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-02 07:29:56 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 3, 'eval_data': 'agnews', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/agnews', 'ana_setting': 'zs', 'optim_group': 'all', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 0, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_xl', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2560, 'decoder_output_dim': 2560, 'decoder_input_dim': 2560, 'decoder_ffn_embed_dim': 10240, 'decoder_layers': 32, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt'}, 'criterion': {'_name': 'fs_eval', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 3, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 4, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 4, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': True, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=3, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_eval', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=4, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid='4', max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_xl', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.25], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=True, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='agnews', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/agnews', ana_setting='zs', optim_group='all', tokens_per_sample=2048, max_target_positions=None, k=0, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt', no_seed_provided=False, decoder_layers=32, decoder_embed_dim=2560, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2560, decoder_output_dim=2560, decoder_ffn_embed_dim=10240, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-02 07:29:56 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-02 07:29:59 | WARNING | datasets.builder | Using custom data configuration default\n",
            "2024-03-02 07:29:59 | WARNING | datasets.builder | Reusing dataset ag_news (/root/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n",
            "100%|██████████| 2/2 [00:00<00:00, 330.22it/s]\n",
            "2024-03-02 07:29:59 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548/cache-07b028a45ecfcdf7.arrow\n",
            "2024-03-02 07:29:59 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548/cache-f83bc7f828dbfa43.arrow\n",
            "2024-03-02 07:31:51 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-02 07:31:54 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2560, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
            "        (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2560, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-02 07:31:54 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-02 07:31:54 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-02 07:31:54 | INFO | fairseq_cli.train | criterion: FewshotEvalCriterion\n",
            "2024-03-02 07:31:54 | INFO | fairseq_cli.train | num. shared model params: 2,648,724,480 (num. trained: 2,560)\n",
            "2024-03-02 07:31:54 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-02 07:31:57 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-02 07:31:57 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-02 07:31:57 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-02 07:31:57 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-02 07:31:57 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-02 07:31:57 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 4\n",
            "2024-03-02 07:31:57 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt\n",
            "2024-03-02 07:31:57 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last.pt\n",
            "2024-03-02 07:31:57 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-02 07:31:58 | INFO | fairseq_cli.train | Start validating\n",
            "2024-03-02 07:31:58 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "------------ example 0 input str valid is ['Classify the news articles into the categories of World, Sports, Business, and Technology. Article: American Express sues credit card rivals American Express is suing Visa and MasterCard plus eight US banks, claiming anti-competitive tactics kept it out of the market. The litigation is the latest setback for Visa and MasterCard, which last month  Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: American Express sues credit card rivals American Express is suing Visa and MasterCard plus eight US banks, claiming anti-competitive tactics kept it out of the market. The litigation is the latest setback for Visa and MasterCard, which last month  Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: American Express sues credit card rivals American Express is suing Visa and MasterCard plus eight US banks, claiming anti-competitive tactics kept it out of the market. The litigation is the latest setback for Visa and MasterCard, which last month  Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: American Express sues credit card rivals American Express is suing Visa and MasterCard plus eight US banks, claiming anti-competitive tactics kept it out of the market. The litigation is the latest setback for Visa and MasterCard, which last month  Answer:']\n",
            "------------ example 0 label str valid is [' World', ' Sports', ' Business', ' Technology']\n",
            "------------ example 1 input str valid is ['Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Producer Price Surge Fuels Inflation Fears Producer prices surged 1.7 percent in October, their sharpest monthly increase in nearly 15 years. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Producer Price Surge Fuels Inflation Fears Producer prices surged 1.7 percent in October, their sharpest monthly increase in nearly 15 years. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Producer Price Surge Fuels Inflation Fears Producer prices surged 1.7 percent in October, their sharpest monthly increase in nearly 15 years. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Producer Price Surge Fuels Inflation Fears Producer prices surged 1.7 percent in October, their sharpest monthly increase in nearly 15 years. Answer:']\n",
            "------------ example 1 label str valid is [' World', ' Sports', ' Business', ' Technology']\n",
            "NOTE: true K of baseline is 0, max valid len is 237\n",
            "| Loaded valid with 8000 samples\n",
            "| Loaded train with 8000 samples\n",
            "2024-03-02 07:36:38 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.629 | nll_loss 0.029 | accuracy 39.9 | f1 0 | pos_proportion 25.3 | neg_proportion 23.5 | wps 2152.8 | wpb 300 | bsz 1 | num_updates 0\n",
            "+ SEED=3\n",
            "+ TASK=agnews\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt\n",
            "+ ARCH=gptmodel_xl\n",
            "+ K=32\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/agnews\n",
            "+ ana_setting=icl\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' agnews = agnews ']'\n",
            "+ N_CLASSES=4\n",
            "+ '[' agnews = trec ']'\n",
            "+ '[' agnews = sst5 ']'\n",
            "+ '[' agnews = dbpedia ']'\n",
            "+ '[' agnews = cb ']'\n",
            "+ '[' agnews = arce ']'\n",
            "+ '[' agnews = arcc ']'\n",
            "+ '[' agnews = obqa ']'\n",
            "+ '[' agnews = hellaswag ']'\n",
            "+ '[' agnews = storycloze ']'\n",
            "+ '[' agnews = raceh ']'\n",
            "+ '[' agnews = racem ']'\n",
            "+ '[' agnews = nq ']'\n",
            "+ '[' agnews = webqs ']'\n",
            "+ '[' agnews = triviaqa ']'\n",
            "+ '[' agnews = sq2 ']'\n",
            "+ '[' agnews = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output\n",
            "+ BSZ=4\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_eval --arch gptmodel_xl --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --max-epoch 1 --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --max-update 0 --fp16 --eval-data agnews --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 3 --reset-dataloader --no-save --k 32 --batch-size 4 --batch-size-valid 4 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/agnews --ana-setting icl --permut-index 0\n",
            "+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/train_log_icl.txt\n",
            "2024-03-02 07:37:20 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-02 07:37:20 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-02 07:37:20 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-02 07:37:22.225501: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-02 07:37:22.225547: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-02 07:37:22.227717: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-02 07:37:23.620724: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-02 07:37:25 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 3, 'eval_data': 'agnews', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/agnews', 'ana_setting': 'icl', 'optim_group': 'all', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 32, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_xl', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2560, 'decoder_output_dim': 2560, 'decoder_input_dim': 2560, 'decoder_ffn_embed_dim': 10240, 'decoder_layers': 32, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt'}, 'criterion': {'_name': 'fs_eval', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 3, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 4, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 4, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': True, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=3, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_eval', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=4, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid='4', max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_xl', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.25], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=True, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='agnews', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/agnews', ana_setting='icl', optim_group='all', tokens_per_sample=2048, max_target_positions=None, k=32, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt', no_seed_provided=False, decoder_layers=32, decoder_embed_dim=2560, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2560, decoder_output_dim=2560, decoder_ffn_embed_dim=10240, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-02 07:37:25 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-02 07:37:27 | WARNING | datasets.builder | Using custom data configuration default\n",
            "2024-03-02 07:37:27 | WARNING | datasets.builder | Reusing dataset ag_news (/root/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n",
            "100%|██████████| 2/2 [00:00<00:00, 694.25it/s]\n",
            "2024-03-02 07:37:27 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548/cache-07b028a45ecfcdf7.arrow\n",
            "2024-03-02 07:37:27 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548/cache-f83bc7f828dbfa43.arrow\n",
            "2024-03-02 07:38:39 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-02 07:38:41 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2560, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
            "        (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2560, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-02 07:38:41 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-02 07:38:41 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-02 07:38:41 | INFO | fairseq_cli.train | criterion: FewshotEvalCriterion\n",
            "2024-03-02 07:38:41 | INFO | fairseq_cli.train | num. shared model params: 2,648,724,480 (num. trained: 2,560)\n",
            "2024-03-02 07:38:41 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-02 07:38:44 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-02 07:38:44 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-02 07:38:44 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-02 07:38:44 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-02 07:38:44 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-02 07:38:44 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 4\n",
            "2024-03-02 07:38:44 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt\n",
            "2024-03-02 07:38:44 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last.pt\n",
            "2024-03-02 07:38:44 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-02 07:38:44 | INFO | fairseq_cli.train | Start validating\n",
            "2024-03-02 07:38:44 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "------------ example 0 input str train is ['Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Can Klitschko Establish Himself as the Best against Williams? December 8, 2004. Vitali Klitschko is recognized by Ring Magazine as the Heavyweight Champion of the World. HBO Sports would also like you to believe it. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Can Klitschko Establish Himself as the Best against Williams? December 8, 2004. Vitali Klitschko is recognized by Ring Magazine as the Heavyweight Champion of the World. HBO Sports would also like you to believe it. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Can Klitschko Establish Himself as the Best against Williams? December 8, 2004. Vitali Klitschko is recognized by Ring Magazine as the Heavyweight Champion of the World. HBO Sports would also like you to believe it. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Can Klitschko Establish Himself as the Best against Williams? December 8, 2004. Vitali Klitschko is recognized by Ring Magazine as the Heavyweight Champion of the World. HBO Sports would also like you to believe it. Answer:']\n",
            "------------ example 0 label str train is [' World', ' Sports', ' Business', ' Technology']\n",
            "------------ example 1 input str train is ['Classify the news articles into the categories of World, Sports, Business, and Technology. Article: China to Introduce Anti-Secession Law, Eyes Taiwan  BEIJING (Reuters) - China is to introduce legislation  against secession, state media reported on Friday, a move  analysts have said is aimed at mandating eventual reunification  with rival Taiwan. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: China to Introduce Anti-Secession Law, Eyes Taiwan  BEIJING (Reuters) - China is to introduce legislation  against secession, state media reported on Friday, a move  analysts have said is aimed at mandating eventual reunification  with rival Taiwan. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: China to Introduce Anti-Secession Law, Eyes Taiwan  BEIJING (Reuters) - China is to introduce legislation  against secession, state media reported on Friday, a move  analysts have said is aimed at mandating eventual reunification  with rival Taiwan. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: China to Introduce Anti-Secession Law, Eyes Taiwan  BEIJING (Reuters) - China is to introduce legislation  against secession, state media reported on Friday, a move  analysts have said is aimed at mandating eventual reunification  with rival Taiwan. Answer:']\n",
            "------------ example 1 label str train is [' World', ' Sports', ' Business', ' Technology']\n",
            "------------ example 0 input str valid is ['Classify the news articles into the categories of World, Sports, Business, and Technology. Article: American Express sues credit card rivals American Express is suing Visa and MasterCard plus eight US banks, claiming anti-competitive tactics kept it out of the market. The litigation is the latest setback for Visa and MasterCard, which last month  Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: American Express sues credit card rivals American Express is suing Visa and MasterCard plus eight US banks, claiming anti-competitive tactics kept it out of the market. The litigation is the latest setback for Visa and MasterCard, which last month  Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: American Express sues credit card rivals American Express is suing Visa and MasterCard plus eight US banks, claiming anti-competitive tactics kept it out of the market. The litigation is the latest setback for Visa and MasterCard, which last month  Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: American Express sues credit card rivals American Express is suing Visa and MasterCard plus eight US banks, claiming anti-competitive tactics kept it out of the market. The litigation is the latest setback for Visa and MasterCard, which last month  Answer:']\n",
            "------------ example 0 label str valid is [' World', ' Sports', ' Business', ' Technology']\n",
            "------------ example 1 input str valid is ['Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Producer Price Surge Fuels Inflation Fears Producer prices surged 1.7 percent in October, their sharpest monthly increase in nearly 15 years. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Producer Price Surge Fuels Inflation Fears Producer prices surged 1.7 percent in October, their sharpest monthly increase in nearly 15 years. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Producer Price Surge Fuels Inflation Fears Producer prices surged 1.7 percent in October, their sharpest monthly increase in nearly 15 years. Answer:', 'Classify the news articles into the categories of World, Sports, Business, and Technology. Article: Producer Price Surge Fuels Inflation Fears Producer prices surged 1.7 percent in October, their sharpest monthly increase in nearly 15 years. Answer:']\n",
            "------------ example 1 label str valid is [' World', ' Sports', ' Business', ' Technology']\n",
            "NOTE: true K of baseline is 22, max valid len is 237\n",
            "| Loaded valid with 8000 samples\n",
            "| Loaded train with 8000 samples\n",
            "2024-03-02 07:48:38 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 0.99 | nll_loss 0 | accuracy 80.3 | f1 0 | pos_proportion 25.3 | neg_proportion 23.5 | wps 24731.3 | wpb 7332 | bsz 1 | num_updates 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash run.sh en_dense_lm_2_7b gptmodel_xl cb 32 3 0 \"{icl_base_dir}/output\" \"{icl_base_dir}\" 0.01"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zi2DhiF5umAg",
        "outputId": "974692bf-6457-450d-c256-75fad9ee17fd",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/cb/ft/record_info.jsonl': No such file or directory\n",
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/cb/en_dense_lm_2_7b/0.01': No such file or directory\n",
            "+ SEED=3\n",
            "+ TASK=cb\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt\n",
            "+ ARCH=gptmodel_xl\n",
            "+ K=32\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/cb\n",
            "+ ana_setting=ft\n",
            "+ lr=0.01\n",
            "+ max_epoch=1\n",
            "+ save_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/cb/en_dense_lm_2_7b/0.01\n",
            "+ optim_group=attn_kv\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' cb = agnews ']'\n",
            "+ '[' cb = trec ']'\n",
            "+ '[' cb = sst5 ']'\n",
            "+ '[' cb = dbpedia ']'\n",
            "+ '[' cb = cb ']'\n",
            "+ N_CLASSES=3\n",
            "+ '[' cb = arce ']'\n",
            "+ '[' cb = arcc ']'\n",
            "+ '[' cb = obqa ']'\n",
            "+ '[' cb = hellaswag ']'\n",
            "+ '[' cb = storycloze ']'\n",
            "+ '[' cb = raceh ']'\n",
            "+ '[' cb = racem ']'\n",
            "+ '[' cb = nq ']'\n",
            "+ '[' cb = webqs ']'\n",
            "+ '[' cb = triviaqa ']'\n",
            "+ '[' cb = sq2 ']'\n",
            "+ '[' cb = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ORI_BSZ=1\n",
            "+ BSZ=3\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_ft --arch gptmodel_xl --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --lr 0.01 --max-epoch 1 --curriculum 1000000 --max-update 1000000 --fp16 --eval-data cb --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 3 --reset-dataloader --k 32 --batch-size 1 --batch-size-valid 1 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebo+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output//train_log_ft.txt\n",
            "oks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/cb --ana-setting ft --save-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/cb/en_dense_lm_2_7b/0.01 --save-interval 1 --save-interval-updates 1000000 --validate-interval 1000000 --disable-validation --optim-group attn_kv --permut-index 0\n",
            "2024-03-01 17:49:36 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-01 17:49:36 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-01 17:49:36 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-01 17:49:38.023656: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-01 17:49:38.023753: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-01 17:49:38.027090: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-01 17:49:39.332862: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-01 17:49:41 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 3, 'eval_data': 'cb', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/cb', 'ana_setting': 'ft', 'optim_group': 'attn_kv', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 32, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_xl', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2560, 'decoder_output_dim': 2560, 'decoder_input_dim': 2560, 'decoder_ffn_embed_dim': 10240, 'decoder_layers': 32, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt'}, 'criterion': {'_name': 'fs_ft', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.01]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 3, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1000000, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': None, 'batch_size_valid': 1, 'max_valid_steps': None, 'curriculum': 1000000, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 1000000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.01], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/cb/en_dense_lm_2_7b/0.01', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 1000000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=3, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_ft', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=1, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1000000, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=True, max_tokens_valid=None, batch_size_valid='1', max_valid_steps=None, curriculum=1000000, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_xl', max_epoch=1, max_update=1000000, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.01], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/cb/en_dense_lm_2_7b/0.01', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=1000000, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='cb', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/cb', ana_setting='ft', optim_group='attn_kv', tokens_per_sample=2048, max_target_positions=None, k=32, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt', no_seed_provided=False, decoder_layers=32, decoder_embed_dim=2560, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2560, decoder_output_dim=2560, decoder_ffn_embed_dim=10240, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-01 17:49:41 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-01 17:49:43 | WARNING | datasets.builder | Reusing dataset super_glue (/root/.cache/huggingface/datasets/super_glue/cb/1.0.2/d040c658e2ddef6934fdd97deb45c777b6ff50c524781ea434e7219b56a428a7)\n",
            "100%|██████████| 3/3 [00:00<00:00, 396.30it/s]\n",
            "2024-03-01 17:49:43 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/super_glue/cb/1.0.2/d040c658e2ddef6934fdd97deb45c777b6ff50c524781ea434e7219b56a428a7/cache-938493646037f99b.arrow\n",
            "2024-03-01 17:49:43 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/super_glue/cb/1.0.2/d040c658e2ddef6934fdd97deb45c777b6ff50c524781ea434e7219b56a428a7/cache-51936d8860a97ff3.arrow\n",
            "2024-03-01 17:50:48 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-01 17:50:50 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2560, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
            "        (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2560, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-01 17:50:50 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-01 17:50:50 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-01 17:50:50 | INFO | fairseq_cli.train | criterion: FewshotFTCriterion\n",
            "2024-03-01 17:50:50 | INFO | fairseq_cli.train | num. shared model params: 2,648,724,480 (num. trained: 2,648,724,480)\n",
            "2024-03-01 17:50:50 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-01 17:50:53 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-01 17:50:53 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 17:50:53 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-01 17:50:53 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 17:50:53 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-01 17:50:53 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 1\n",
            "2024-03-01 17:50:53 | INFO | fairseq.trainer | Preparing to load checkpoint /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/cb/en_dense_lm_2_7b/0.01/checkpoint_last.pt\n",
            "2024-03-01 17:50:53 | INFO | fairseq.trainer | No existing checkpoint found /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/cb/en_dense_lm_2_7b/0.01/checkpoint_last.pt\n",
            "2024-03-01 17:50:53 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-01 17:50:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 32\n",
            "2024-03-01 17:50:54 | INFO | fairseq.trainer | begin training epoch 1\n",
            "2024-03-01 17:50:54 | INFO | fairseq_cli.train | Start fine-tuning\n",
            "------------ example 0 input str train is [\"For a while the notion gripped him, and he prowled the many floors of Hamleys looking for toys. He bought a magic set for Sebastian (although his ideal present for the kid would have been a brand-new name) and a marionette for Louise. He could remember that there was an age for puppets and magic just as he could remember the time that he 'd spent trying to fan a deck of cards or sitting in front of a mirror trying to get the hard consonants down like a real ventriloquist. Question: there was an age for puppets and magic. True, False, or Neither? Answer:\", \"For a while the notion gripped him, and he prowled the many floors of Hamleys looking for toys. He bought a magic set for Sebastian (although his ideal present for the kid would have been a brand-new name) and a marionette for Louise. He could remember that there was an age for puppets and magic just as he could remember the time that he 'd spent trying to fan a deck of cards or sitting in front of a mirror trying to get the hard consonants down like a real ventriloquist. Question: there was an age for puppets and magic. True, False, or Neither? Answer:\", \"For a while the notion gripped him, and he prowled the many floors of Hamleys looking for toys. He bought a magic set for Sebastian (although his ideal present for the kid would have been a brand-new name) and a marionette for Louise. He could remember that there was an age for puppets and magic just as he could remember the time that he 'd spent trying to fan a deck of cards or sitting in front of a mirror trying to get the hard consonants down like a real ventriloquist. Question: there was an age for puppets and magic. True, False, or Neither? Answer:\"]\n",
            "------------ example 0 label str train is [' True', ' False', ' Neither']\n",
            "------------ example 1 input str train is [\"``For God's sake keep them in their seats. If we get panic people are going to be crushed to death and there will be mayhem in the car park.'' The announcer could only guess from the urgency in the Chief Constable's voice that the situation was very very serious. Question: the situation was very very serious. True, False, or Neither? Answer:\", \"``For God's sake keep them in their seats. If we get panic people are going to be crushed to death and there will be mayhem in the car park.'' The announcer could only guess from the urgency in the Chief Constable's voice that the situation was very very serious. Question: the situation was very very serious. True, False, or Neither? Answer:\", \"``For God's sake keep them in their seats. If we get panic people are going to be crushed to death and there will be mayhem in the car park.'' The announcer could only guess from the urgency in the Chief Constable's voice that the situation was very very serious. Question: the situation was very very serious. True, False, or Neither? Answer:\"]\n",
            "------------ example 1 label str train is [' True', ' False', ' Neither']\n",
            "------------ example 0 input str valid is [\"A: Well, actually, uh, A: I don't think I'm in the, uh, majority in Texas Question: she is in the majority in Texas. True, False, or Neither? Answer:\", \"A: Well, actually, uh, A: I don't think I'm in the, uh, majority in Texas Question: she is in the majority in Texas. True, False, or Neither? Answer:\", \"A: Well, actually, uh, A: I don't think I'm in the, uh, majority in Texas Question: she is in the majority in Texas. True, False, or Neither? Answer:\"]\n",
            "------------ example 0 label str valid is [' True', ' False', ' Neither']\n",
            "------------ example 1 input str valid is [\"A: and that rolling kind of, uh, B: Terrain. A: Yeah. is fairly famili-,. The thing that I thought was interesting was that the critics, apparently it's going to win everything. B: Really? A: Uh, and I had been told, you know, you wouldn't notice that it was three hours long, and all this, kind of, Question: it was three hours long. True, False, or Neither? Answer:\", \"A: and that rolling kind of, uh, B: Terrain. A: Yeah. is fairly famili-,. The thing that I thought was interesting was that the critics, apparently it's going to win everything. B: Really? A: Uh, and I had been told, you know, you wouldn't notice that it was three hours long, and all this, kind of, Question: it was three hours long. True, False, or Neither? Answer:\", \"A: and that rolling kind of, uh, B: Terrain. A: Yeah. is fairly famili-,. The thing that I thought was interesting was that the critics, apparently it's going to win everything. B: Really? A: Uh, and I had been told, you know, you wouldn't notice that it was three hours long, and all this, kind of, Question: it was three hours long. True, False, or Neither? Answer:\"]\n",
            "------------ example 1 label str valid is [' True', ' False', ' Neither']\n",
            "NOTE: true K of baseline is 19, max valid len is 280\n",
            "------------ example 0 input str train is [\"For a while the notion gripped him, and he prowled the many floors of Hamleys looking for toys. He bought a magic set for Sebastian (although his ideal present for the kid would have been a brand-new name) and a marionette for Louise. He could remember that there was an age for puppets and magic just as he could remember the time that he 'd spent trying to fan a deck of cards or sitting in front of a mirror trying to get the hard consonants down like a real ventriloquist. Question: there was an age for puppets and magic. True, False, or Neither? Answer:\", \"For a while the notion gripped him, and he prowled the many floors of Hamleys looking for toys. He bought a magic set for Sebastian (although his ideal present for the kid would have been a brand-new name) and a marionette for Louise. He could remember that there was an age for puppets and magic just as he could remember the time that he 'd spent trying to fan a deck of cards or sitting in front of a mirror trying to get the hard consonants down like a real ventriloquist. Question: there was an age for puppets and magic. True, False, or Neither? Answer:\", \"For a while the notion gripped him, and he prowled the many floors of Hamleys looking for toys. He bought a magic set for Sebastian (although his ideal present for the kid would have been a brand-new name) and a marionette for Louise. He could remember that there was an age for puppets and magic just as he could remember the time that he 'd spent trying to fan a deck of cards or sitting in front of a mirror trying to get the hard consonants down like a real ventriloquist. Question: there was an age for puppets and magic. True, False, or Neither? Answer:\"]\n",
            "------------ example 0 label str train is [' True', ' False', ' Neither']\n",
            "------------ example 1 input str train is [\"``For God's sake keep them in their seats. If we get panic people are going to be crushed to death and there will be mayhem in the car park.'' The announcer could only guess from the urgency in the Chief Constable's voice that the situation was very very serious. Question: the situation was very very serious. True, False, or Neither? Answer:\", \"``For God's sake keep them in their seats. If we get panic people are going to be crushed to death and there will be mayhem in the car park.'' The announcer could only guess from the urgency in the Chief Constable's voice that the situation was very very serious. Question: the situation was very very serious. True, False, or Neither? Answer:\", \"``For God's sake keep them in their seats. If we get panic people are going to be crushed to death and there will be mayhem in the car park.'' The announcer could only guess from the urgency in the Chief Constable's voice that the situation was very very serious. Question: the situation was very very serious. True, False, or Neither? Answer:\"]\n",
            "------------ example 1 label str train is [' True', ' False', ' Neither']\n",
            "NOTE: true K of baseline is 32\n",
            "| Loaded valid with 168 samples\n",
            "| Loaded train with 32 samples\n",
            "2024-03-01 17:51:03 | INFO | train_inner | epoch 001:      1 / 32 loss=5.031, sample_size=131, ntokens=132, wps=0, ups=0, wpb=132, bsz=1, num_updates=1, lr=0.01, gnorm=5.136, loss_scale=4, train_wall=10, gb_free=26.1, wall=10\n",
            "2024-03-01 17:51:08 | INFO | train_inner | epoch 001:      2 / 32 loss=4.975, sample_size=74, ntokens=75, wps=16, ups=0.21, wpb=75, bsz=1, num_updates=2, lr=0.01, gnorm=7.515, loss_scale=4, train_wall=5, gb_free=25.8, wall=15\n",
            "2024-03-01 17:51:15 | INFO | train_inner | epoch 001:      3 / 32 loss=3.728, sample_size=101, ntokens=102, wps=15.8, ups=0.15, wpb=102, bsz=1, num_updates=3, lr=0.01, gnorm=4.076, loss_scale=4, train_wall=6, gb_free=25.8, wall=21\n",
            "2024-03-01 17:51:20 | INFO | train_inner | epoch 001:      4 / 32 loss=4.086, sample_size=88, ntokens=89, wps=16.2, ups=0.18, wpb=89, bsz=1, num_updates=4, lr=0.01, gnorm=4.713, loss_scale=4, train_wall=5, gb_free=25.8, wall=27\n",
            "2024-03-01 17:51:24 | INFO | train_inner | epoch 001:      5 / 32 loss=4.362, sample_size=56, ntokens=57, wps=15.5, ups=0.27, wpb=57, bsz=1, num_updates=5, lr=0.01, gnorm=6.565, loss_scale=4, train_wall=4, gb_free=25.8, wall=30\n",
            "2024-03-01 17:51:27 | INFO | train_inner | epoch 001:      6 / 32 loss=3.625, sample_size=54, ntokens=55, wps=15.8, ups=0.29, wpb=55, bsz=1, num_updates=6, lr=0.01, gnorm=5.775, loss_scale=4, train_wall=3, gb_free=25.8, wall=34\n",
            "2024-03-01 17:51:37 | INFO | train_inner | epoch 001:      7 / 32 loss=4.165, sample_size=163, ntokens=164, wps=16.2, ups=0.1, wpb=164, bsz=1, num_updates=7, lr=0.01, gnorm=4.538, loss_scale=4, train_wall=10, gb_free=25.8, wall=44\n",
            "2024-03-01 17:51:41 | INFO | train_inner | epoch 001:      8 / 32 loss=3.577, sample_size=64, ntokens=65, wps=16, ups=0.25, wpb=65, bsz=1, num_updates=8, lr=0.01, gnorm=5.175, loss_scale=4, train_wall=4, gb_free=25.8, wall=48\n",
            "2024-03-01 17:51:53 | INFO | train_inner | epoch 001:      9 / 32 loss=4.14, sample_size=185, ntokens=186, wps=16.3, ups=0.09, wpb=186, bsz=1, num_updates=9, lr=0.01, gnorm=3.156, loss_scale=4, train_wall=11, gb_free=25.8, wall=59\n",
            "2024-03-01 17:52:01 | INFO | train_inner | epoch 001:     10 / 32 loss=3.772, sample_size=129, ntokens=130, wps=16.3, ups=0.13, wpb=130, bsz=1, num_updates=10, lr=0.01, gnorm=4.014, loss_scale=4, train_wall=8, gb_free=25.8, wall=67\n",
            "2024-03-01 17:52:06 | INFO | train_inner | epoch 001:     11 / 32 loss=3.039, sample_size=82, ntokens=83, wps=16.3, ups=0.2, wpb=83, bsz=1, num_updates=11, lr=0.01, gnorm=4.867, loss_scale=4, train_wall=5, gb_free=25.8, wall=73\n",
            "2024-03-01 17:52:11 | INFO | train_inner | epoch 001:     12 / 32 loss=4.616, sample_size=78, ntokens=79, wps=16.1, ups=0.2, wpb=79, bsz=1, num_updates=12, lr=0.01, gnorm=6.639, loss_scale=4, train_wall=5, gb_free=25.8, wall=77\n",
            "2024-03-01 17:52:23 | INFO | train_inner | epoch 001:     13 / 32 loss=4.473, sample_size=125, ntokens=126, wps=10.3, ups=0.08, wpb=126, bsz=1, num_updates=13, lr=0.01, gnorm=4.102, loss_scale=4, train_wall=12, gb_free=25.8, wall=90\n",
            "2024-03-01 17:52:27 | INFO | train_inner | epoch 001:     14 / 32 loss=3.507, sample_size=62, ntokens=63, wps=16, ups=0.25, wpb=63, bsz=1, num_updates=14, lr=0.01, gnorm=6.551, loss_scale=4, train_wall=4, gb_free=25.8, wall=94\n",
            "2024-03-01 17:52:37 | INFO | train_inner | epoch 001:     15 / 32 loss=4.063, sample_size=95, ntokens=96, wps=9.9, ups=0.1, wpb=96, bsz=1, num_updates=15, lr=0.01, gnorm=4.481, loss_scale=4, train_wall=10, gb_free=25.8, wall=103\n",
            "2024-03-01 17:52:40 | INFO | train_inner | epoch 001:     16 / 32 loss=2.799, sample_size=44, ntokens=45, wps=15.7, ups=0.35, wpb=45, bsz=1, num_updates=16, lr=0.01, gnorm=6.168, loss_scale=4, train_wall=3, gb_free=25.8, wall=106\n",
            "2024-03-01 17:52:43 | INFO | train_inner | epoch 001:     17 / 32 loss=3.449, sample_size=48, ntokens=49, wps=16.3, ups=0.33, wpb=49, bsz=1, num_updates=17, lr=0.01, gnorm=7.151, loss_scale=4, train_wall=3, gb_free=25.8, wall=109\n",
            "2024-03-01 17:52:47 | INFO | train_inner | epoch 001:     18 / 32 loss=4.216, sample_size=71, ntokens=72, wps=16.1, ups=0.22, wpb=72, bsz=1, num_updates=18, lr=0.01, gnorm=7.116, loss_scale=4, train_wall=4, gb_free=25.8, wall=114\n",
            "2024-03-01 17:52:51 | INFO | train_inner | epoch 001:     19 / 32 loss=4.157, sample_size=64, ntokens=65, wps=16.3, ups=0.25, wpb=65, bsz=1, num_updates=19, lr=0.01, gnorm=6.926, loss_scale=4, train_wall=4, gb_free=25.8, wall=118\n",
            "2024-03-01 17:52:56 | INFO | train_inner | epoch 001:     20 / 32 loss=3.667, sample_size=75, ntokens=76, wps=16.3, ups=0.21, wpb=76, bsz=1, num_updates=20, lr=0.01, gnorm=5.916, loss_scale=4, train_wall=5, gb_free=25.8, wall=122\n",
            "2024-03-01 17:53:01 | INFO | train_inner | epoch 001:     21 / 32 loss=3.121, sample_size=95, ntokens=96, wps=16.5, ups=0.17, wpb=96, bsz=1, num_updates=21, lr=0.01, gnorm=5.517, loss_scale=4, train_wall=6, gb_free=25.8, wall=128\n",
            "2024-03-01 17:53:13 | INFO | train_inner | epoch 001:     22 / 32 loss=4.234, sample_size=193, ntokens=194, wps=16.6, ups=0.09, wpb=194, bsz=1, num_updates=22, lr=0.01, gnorm=4.401, loss_scale=4, train_wall=12, gb_free=25.8, wall=140\n",
            "2024-03-01 17:53:18 | INFO | train_inner | epoch 001:     23 / 32 loss=4.718, sample_size=80, ntokens=81, wps=16.7, ups=0.21, wpb=81, bsz=1, num_updates=23, lr=0.01, gnorm=6.395, loss_scale=4, train_wall=5, gb_free=25.8, wall=145\n",
            "2024-03-01 17:53:28 | INFO | train_inner | epoch 001:     24 / 32 loss=3.156, sample_size=147, ntokens=148, wps=15.5, ups=0.1, wpb=148, bsz=1, num_updates=24, lr=0.01, gnorm=4.094, loss_scale=4, train_wall=10, gb_free=25.8, wall=154\n",
            "2024-03-01 17:53:32 | INFO | train_inner | epoch 001:     25 / 32 loss=3.656, sample_size=72, ntokens=73, wps=16.2, ups=0.22, wpb=73, bsz=1, num_updates=25, lr=0.01, gnorm=5.52, loss_scale=4, train_wall=4, gb_free=25.8, wall=159\n",
            "2024-03-01 17:53:43 | INFO | train_inner | epoch 001:     26 / 32 loss=3.336, sample_size=189, ntokens=190, wps=16.7, ups=0.09, wpb=190, bsz=1, num_updates=26, lr=0.01, gnorm=3.018, loss_scale=4, train_wall=11, gb_free=25.8, wall=170\n",
            "2024-03-01 17:53:47 | INFO | train_inner | epoch 001:     27 / 32 loss=4.191, sample_size=56, ntokens=57, wps=16.3, ups=0.29, wpb=57, bsz=1, num_updates=27, lr=0.01, gnorm=6.63, loss_scale=4, train_wall=3, gb_free=25.8, wall=174\n",
            "2024-03-01 17:53:51 | INFO | train_inner | epoch 001:     28 / 32 loss=4.392, sample_size=52, ntokens=53, wps=14.3, ups=0.27, wpb=53, bsz=1, num_updates=28, lr=0.01, gnorm=8.233, loss_scale=4, train_wall=4, gb_free=25.8, wall=177\n",
            "2024-03-01 17:53:54 | INFO | train_inner | epoch 001:     29 / 32 loss=3.715, sample_size=59, ntokens=60, wps=16.5, ups=0.27, wpb=60, bsz=1, num_updates=29, lr=0.01, gnorm=6.446, loss_scale=4, train_wall=4, gb_free=25.8, wall=181\n",
            "2024-03-01 17:53:58 | INFO | train_inner | epoch 001:     30 / 32 loss=3.111, sample_size=65, ntokens=66, wps=16.4, ups=0.25, wpb=66, bsz=1, num_updates=30, lr=0.01, gnorm=5.597, loss_scale=4, train_wall=4, gb_free=25.8, wall=185\n",
            "2024-03-01 17:54:01 | INFO | train_inner | epoch 001:     31 / 32 loss=3.127, sample_size=48, ntokens=49, wps=16.4, ups=0.33, wpb=49, bsz=1, num_updates=31, lr=0.01, gnorm=6.875, loss_scale=4, train_wall=3, gb_free=25.8, wall=188\n",
            "2024-03-01 17:54:06 | INFO | train_inner | epoch 001:     32 / 32 loss=2.689, sample_size=74, ntokens=75, wps=16.6, ups=0.22, wpb=75, bsz=1, num_updates=32, lr=0.01, gnorm=4.354, loss_scale=4, train_wall=5, gb_free=25.8, wall=193\n",
            "2024-03-01 17:54:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 32 updates\n",
            "2024-03-01 17:54:06 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/cb/en_dense_lm_2_7b/0.01/checkpoint1.pt\n",
            "2024-03-01 17:55:22 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/cb/en_dense_lm_2_7b/0.01/checkpoint1.pt\n",
            "2024-03-01 17:56:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/cb/en_dense_lm_2_7b/0.01/checkpoint1.pt (epoch 1 @ 32 updates, score None) (writing took 119.91215904300043 seconds)\n",
            "2024-03-01 17:56:06 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
            "2024-03-01 17:56:06 | INFO | train | epoch 001 | loss 3.887 | sample_size 91.219 | ntokens 92.219 | wps 9.3 | ups 0.1 | wpb 92.2 | bsz 1 | num_updates 32 | lr 0.01 | gnorm 5.552 | loss_scale 4 | train_wall 192 | gb_free 25.8 | wall 313\n",
            "2024-03-01 17:56:06 | INFO | fairseq_cli.train | done training in 312.3 seconds\n",
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/cb/ftzs/record_info.jsonl': No such file or directory\n",
            "+ SEED=3\n",
            "+ TASK=cb\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/cb/en_dense_lm_2_7b/0.01/checkpoint_last.pt\n",
            "+ ARCH=gptmodel_xl\n",
            "+ K=0\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/cb\n",
            "+ ana_setting=ftzs\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' cb = agnews ']'\n",
            "+ '[' cb = trec ']'\n",
            "+ '[' cb = sst5 ']'\n",
            "+ '[' cb = dbpedia ']'\n",
            "+ '[' cb = cb ']'\n",
            "+ N_CLASSES=3\n",
            "+ '[' cb = arce ']'\n",
            "+ '[' cb = arcc ']'\n",
            "+ '[' cb = obqa ']'\n",
            "+ '[' cb = hellaswag ']'\n",
            "+ '[' cb = storycloze ']'\n",
            "+ '[' cb = raceh ']'\n",
            "+ '[' cb = racem ']'\n",
            "+ '[' cb = nq ']'\n",
            "+ '[' cb = webqs ']'\n",
            "+ '[' cb = triviaqa ']'\n",
            "+ '[' cb = sq2 ']'\n",
            "+ '[' cb = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ BSZ=3\n",
            "+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output//train_log_ftzs.txt\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_eval --arch gptmodel_xl --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --max-epoch 1 --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --max-update 0 --fp16 --eval-data cb --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 3 --reset-dataloader --no-save --k 0 --batch-size 3 --batch-size-valid 3 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/cb/en_dense_lm_2_7b/0.01/checkpoint_last.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/cb --ana-setting ftzs --permut-index 0\n",
            "2024-03-01 17:56:26 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-01 17:56:26 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-01 17:56:26 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-01 17:56:28.185917: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-01 17:56:28.186003: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-01 17:56:28.189371: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-01 17:56:29.386649: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-01 17:56:31 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 3, 'eval_data': 'cb', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/cb', 'ana_setting': 'ftzs', 'optim_group': 'all', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 0, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_xl', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2560, 'decoder_output_dim': 2560, 'decoder_input_dim': 2560, 'decoder_ffn_embed_dim': 10240, 'decoder_layers': 32, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/cb/en_dense_lm_2_7b/0.01/checkpoint_last.pt'}, 'criterion': {'_name': 'fs_eval', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 3, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 3, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 3, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': True, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=3, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_eval', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=3, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid='3', max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_xl', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.25], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=True, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='cb', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/cb', ana_setting='ftzs', optim_group='all', tokens_per_sample=2048, max_target_positions=None, k=0, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ft_gpt/cb/en_dense_lm_2_7b/0.01/checkpoint_last.pt', no_seed_provided=False, decoder_layers=32, decoder_embed_dim=2560, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2560, decoder_output_dim=2560, decoder_ffn_embed_dim=10240, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-01 17:56:31 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-01 17:56:33 | WARNING | datasets.builder | Reusing dataset super_glue (/root/.cache/huggingface/datasets/super_glue/cb/1.0.2/d040c658e2ddef6934fdd97deb45c777b6ff50c524781ea434e7219b56a428a7)\n",
            "100%|██████████| 3/3 [00:00<00:00, 316.89it/s]\n",
            "2024-03-01 17:56:33 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/super_glue/cb/1.0.2/d040c658e2ddef6934fdd97deb45c777b6ff50c524781ea434e7219b56a428a7/cache-938493646037f99b.arrow\n",
            "2024-03-01 17:56:33 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/super_glue/cb/1.0.2/d040c658e2ddef6934fdd97deb45c777b6ff50c524781ea434e7219b56a428a7/cache-51936d8860a97ff3.arrow\n",
            "2024-03-01 17:58:14 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-01 17:58:17 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2560, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
            "        (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2560, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-01 17:58:17 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-01 17:58:17 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-01 17:58:17 | INFO | fairseq_cli.train | criterion: FewshotEvalCriterion\n",
            "2024-03-01 17:58:17 | INFO | fairseq_cli.train | num. shared model params: 2,648,724,480 (num. trained: 2,560)\n",
            "2024-03-01 17:58:17 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-01 17:58:21 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-01 17:58:21 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 17:58:21 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-01 17:58:21 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 17:58:21 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-01 17:58:21 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 3\n",
            "2024-03-01 17:58:21 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt\n",
            "2024-03-01 17:58:21 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last.pt\n",
            "2024-03-01 17:58:21 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-01 17:58:23 | INFO | fairseq_cli.train | Start validating\n",
            "2024-03-01 17:58:23 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "------------ example 0 input str valid is [\"A: Well, actually, uh, A: I don't think I'm in the, uh, majority in Texas Question: she is in the majority in Texas. True, False, or Neither? Answer:\", \"A: Well, actually, uh, A: I don't think I'm in the, uh, majority in Texas Question: she is in the majority in Texas. True, False, or Neither? Answer:\", \"A: Well, actually, uh, A: I don't think I'm in the, uh, majority in Texas Question: she is in the majority in Texas. True, False, or Neither? Answer:\"]\n",
            "------------ example 0 label str valid is [' True', ' False', ' Neither']\n",
            "------------ example 1 input str valid is [\"A: and that rolling kind of, uh, B: Terrain. A: Yeah. is fairly famili-,. The thing that I thought was interesting was that the critics, apparently it's going to win everything. B: Really? A: Uh, and I had been told, you know, you wouldn't notice that it was three hours long, and all this, kind of, Question: it was three hours long. True, False, or Neither? Answer:\", \"A: and that rolling kind of, uh, B: Terrain. A: Yeah. is fairly famili-,. The thing that I thought was interesting was that the critics, apparently it's going to win everything. B: Really? A: Uh, and I had been told, you know, you wouldn't notice that it was three hours long, and all this, kind of, Question: it was three hours long. True, False, or Neither? Answer:\", \"A: and that rolling kind of, uh, B: Terrain. A: Yeah. is fairly famili-,. The thing that I thought was interesting was that the critics, apparently it's going to win everything. B: Really? A: Uh, and I had been told, you know, you wouldn't notice that it was three hours long, and all this, kind of, Question: it was three hours long. True, False, or Neither? Answer:\"]\n",
            "------------ example 1 label str valid is [' True', ' False', ' Neither']\n",
            "NOTE: true K of baseline is 0, max valid len is 280\n",
            "| Loaded valid with 168 samples\n",
            "| Loaded train with 168 samples\n",
            "2024-03-01 17:58:36 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 1.384 | nll_loss 0.005 | accuracy 58.9 | f1 0 | pos_proportion 41.1 | neg_proportion 50 | wps 1433.7 | wpb 304.4 | bsz 1 | num_updates 0\n",
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/cb/zs/record_info.jsonl': No such file or directory\n",
            "+ SEED=3\n",
            "+ TASK=cb\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt\n",
            "+ ARCH=gptmodel_xl\n",
            "+ K=0\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/cb\n",
            "+ ana_setting=zs\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' cb = agnews ']'\n",
            "+ '[' cb = trec ']'\n",
            "+ '[' cb = sst5 ']'\n",
            "+ '[' cb = dbpedia ']'\n",
            "+ '[' cb = cb ']'\n",
            "+ N_CLASSES=3\n",
            "+ '[' cb = arce ']'\n",
            "+ '[' cb = arcc ']'\n",
            "+ '[' cb = obqa ']'\n",
            "+ '[' cb = hellaswag ']'\n",
            "+ '[' cb = storycloze ']'\n",
            "+ '[' cb = raceh ']'\n",
            "+ '[' cb = racem ']'\n",
            "+ '[' cb = nq ']'\n",
            "+ '[' cb = webqs ']'\n",
            "+ '[' cb = triviaqa ']'\n",
            "+ '[' cb = sq2 ']'\n",
            "+ '[' cb = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ BSZ=3\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_eval --arch gptmodel_xl --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --max-epoch 1 --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --max-update 0 --fp16 --eval-data cb --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 3 --reset-dataloader --no-save --k 0 --batch-size 3 --batch-size-valid 3 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/cb --ana-setting zs --permut-index 0\n",
            "+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output//train_log_zs.txt\n",
            "2024-03-01 17:58:43 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-01 17:58:43 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-01 17:58:43 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-01 17:58:45.064187: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-01 17:58:45.064280: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-01 17:58:45.067418: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-01 17:58:46.561450: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-01 17:58:49 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 3, 'eval_data': 'cb', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/cb', 'ana_setting': 'zs', 'optim_group': 'all', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 0, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_xl', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2560, 'decoder_output_dim': 2560, 'decoder_input_dim': 2560, 'decoder_ffn_embed_dim': 10240, 'decoder_layers': 32, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt'}, 'criterion': {'_name': 'fs_eval', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 3, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 3, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 3, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': True, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=3, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_eval', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=3, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid='3', max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_xl', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.25], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=True, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='cb', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/cb', ana_setting='zs', optim_group='all', tokens_per_sample=2048, max_target_positions=None, k=0, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt', no_seed_provided=False, decoder_layers=32, decoder_embed_dim=2560, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2560, decoder_output_dim=2560, decoder_ffn_embed_dim=10240, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-01 17:58:49 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-01 17:58:50 | WARNING | datasets.builder | Reusing dataset super_glue (/root/.cache/huggingface/datasets/super_glue/cb/1.0.2/d040c658e2ddef6934fdd97deb45c777b6ff50c524781ea434e7219b56a428a7)\n",
            "100%|██████████| 3/3 [00:00<00:00, 694.00it/s]\n",
            "2024-03-01 17:58:50 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/super_glue/cb/1.0.2/d040c658e2ddef6934fdd97deb45c777b6ff50c524781ea434e7219b56a428a7/cache-938493646037f99b.arrow\n",
            "2024-03-01 17:58:50 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/super_glue/cb/1.0.2/d040c658e2ddef6934fdd97deb45c777b6ff50c524781ea434e7219b56a428a7/cache-51936d8860a97ff3.arrow\n",
            "2024-03-01 17:59:54 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-01 17:59:56 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2560, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
            "        (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2560, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-01 17:59:56 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-01 17:59:56 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-01 17:59:56 | INFO | fairseq_cli.train | criterion: FewshotEvalCriterion\n",
            "2024-03-01 17:59:56 | INFO | fairseq_cli.train | num. shared model params: 2,648,724,480 (num. trained: 2,560)\n",
            "2024-03-01 17:59:56 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-01 18:00:00 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-01 18:00:00 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 18:00:00 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-01 18:00:00 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 18:00:00 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-01 18:00:00 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 3\n",
            "2024-03-01 18:00:01 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt\n",
            "2024-03-01 18:00:01 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last.pt\n",
            "2024-03-01 18:00:01 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-01 18:00:01 | INFO | fairseq_cli.train | Start validating\n",
            "2024-03-01 18:00:01 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "------------ example 0 input str valid is [\"A: Well, actually, uh, A: I don't think I'm in the, uh, majority in Texas Question: she is in the majority in Texas. True, False, or Neither? Answer:\", \"A: Well, actually, uh, A: I don't think I'm in the, uh, majority in Texas Question: she is in the majority in Texas. True, False, or Neither? Answer:\", \"A: Well, actually, uh, A: I don't think I'm in the, uh, majority in Texas Question: she is in the majority in Texas. True, False, or Neither? Answer:\"]\n",
            "------------ example 0 label str valid is [' True', ' False', ' Neither']\n",
            "------------ example 1 input str valid is [\"A: and that rolling kind of, uh, B: Terrain. A: Yeah. is fairly famili-,. The thing that I thought was interesting was that the critics, apparently it's going to win everything. B: Really? A: Uh, and I had been told, you know, you wouldn't notice that it was three hours long, and all this, kind of, Question: it was three hours long. True, False, or Neither? Answer:\", \"A: and that rolling kind of, uh, B: Terrain. A: Yeah. is fairly famili-,. The thing that I thought was interesting was that the critics, apparently it's going to win everything. B: Really? A: Uh, and I had been told, you know, you wouldn't notice that it was three hours long, and all this, kind of, Question: it was three hours long. True, False, or Neither? Answer:\", \"A: and that rolling kind of, uh, B: Terrain. A: Yeah. is fairly famili-,. The thing that I thought was interesting was that the critics, apparently it's going to win everything. B: Really? A: Uh, and I had been told, you know, you wouldn't notice that it was three hours long, and all this, kind of, Question: it was three hours long. True, False, or Neither? Answer:\"]\n",
            "------------ example 1 label str valid is [' True', ' False', ' Neither']\n",
            "NOTE: true K of baseline is 0, max valid len is 280\n",
            "| Loaded valid with 168 samples\n",
            "| Loaded train with 168 samples\n",
            "2024-03-01 18:00:10 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 3.335 | nll_loss 0.011 | accuracy 42.9 | f1 0 | pos_proportion 41.1 | neg_proportion 50 | wps 2023 | wpb 304.4 | bsz 1 | num_updates 0\n",
            "rm: cannot remove '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/cb/icl/record_info.jsonl': No such file or directory\n",
            "+ SEED=3\n",
            "+ TASK=cb\n",
            "+ MODEL_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt\n",
            "+ ARCH=gptmodel_xl\n",
            "+ K=32\n",
            "+ BSZ=1\n",
            "+ NGPU=1\n",
            "+ BPE_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe\n",
            "+ ENCODER_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json\n",
            "+ DICT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ ana_attn=1\n",
            "+ ana_rlt_dir=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/cb\n",
            "+ ana_setting=icl\n",
            "+ perm_id=0\n",
            "+ N_CLASSES=2\n",
            "+ '[' cb = agnews ']'\n",
            "+ '[' cb = trec ']'\n",
            "+ '[' cb = sst5 ']'\n",
            "+ '[' cb = dbpedia ']'\n",
            "+ '[' cb = cb ']'\n",
            "+ N_CLASSES=3\n",
            "+ '[' cb = arce ']'\n",
            "+ '[' cb = arcc ']'\n",
            "+ '[' cb = obqa ']'\n",
            "+ '[' cb = hellaswag ']'\n",
            "+ '[' cb = storycloze ']'\n",
            "+ '[' cb = raceh ']'\n",
            "+ '[' cb = racem ']'\n",
            "+ '[' cb = nq ']'\n",
            "+ '[' cb = webqs ']'\n",
            "+ '[' cb = triviaqa ']'\n",
            "+ '[' cb = sq2 ']'\n",
            "+ '[' cb = sq ']'\n",
            "+ OUTPUT_PATH=/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ mkdir -p /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ echo /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output/\n",
            "+ BSZ=3\n",
            "+ python validate.py - --task fs_eval --tokens-per-sample 2048 --criterion fs_eval --arch gptmodel_xl --gpt2-vocab-bpe /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe --gpt2-encoder-json /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json --log-format simple --max-epoch 1 --required-batch-size-multiple 1 --log-interval 1 --warmup-updates 0 --optimizer sgd --max-update 0 --fp16 --eval-data cb --fp16-init-scale 4 --checkpoint-activations --fp16-scale-window 256 --seed 3 --reset-dataloader --no-save --k 32 --batch-size 3 --batch-size-valid 3 --ddp-backend=no_c10d --distributed-no-spawn --gpt-dict /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt --gpt-model-path /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt --ana-attn 1 --ana-rlt-dir /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/cb --ana-setting icl --permut-index 0\n",
            "+ tee /content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/output//train_log_icl.txt\n",
            "2024-03-01 18:00:17 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-03-01 18:00:18 | INFO | numexpr.utils | Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "2024-03-01 18:00:18 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-03-01 18:00:20.154254: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-01 18:00:20.154353: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-01 18:00:20.157502: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-01 18:00:21.518323: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-01 18:00:23 | INFO | fairseq_cli.train | {'task': {'_name': 'fs_eval', 'data': '-', 'seed': 3, 'eval_data': 'cb', 'test_split': 'test', 'required_batch_size_multiple': 1, 'gpt2_encoder_json': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', 'gpt2_vocab_bpe': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', 'gpt_dict': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', 'ana_attn': 1, 'ana_rlt_dir': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/cb', 'ana_setting': 'icl', 'optim_group': 'all', 'tokens_per_sample': 2048, 'max_target_positions': None, 'k': 32, 'temp_index': 0, 'permut_index': 0}, 'model': {'_name': 'gptmodel_xl', 'activation_fn': 'gelu', 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 2560, 'decoder_output_dim': 2560, 'decoder_input_dim': 2560, 'decoder_ffn_embed_dim': 10240, 'decoder_layers': 32, 'decoder_attention_heads': 32, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': True, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2048, 'max_target_positions': None, 'tpu': False, 'gpt_model_path': '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt'}, 'criterion': {'_name': 'fs_eval', 'is_generation': False, 'beam': 3}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'common': {'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 3, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 256, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 3, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 3, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': True, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'beam': 3, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'buffer_size': 0, 'input': '-'}, 'ema': {'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'tokenizer': None, 'bpe': None, 'optimizer': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', log_file=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=3, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', tokenizer=None, bpe=None, optimizer='sgd', lr_scheduler='fixed', criterion='fs_eval', task='fs_eval', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=3, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid='3', max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=True, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='gptmodel_xl', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.25], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=True, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='-', eval_data='cb', test_split='test', gpt2_encoder_json='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/encoder.json', gpt2_vocab_bpe='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/vocab.bpe', gpt_dict='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/dict.txt', ana_attn=1, ana_rlt_dir='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/cb', ana_setting='icl', optim_group='all', tokens_per_sample=2048, max_target_positions=None, k=32, temp_index=0, permut_index=0, momentum=0.0, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, is_generation=False, beam=3, checkpoint_activations=True, gpt_model_path='/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/gpt_icl/en_dense_lm_2_7b/model.pt', no_seed_provided=False, decoder_layers=32, decoder_embed_dim=2560, decoder_attention_heads=32, decoder_learned_pos=False, offload_activations=False, decoder_input_dim=2560, decoder_output_dim=2560, decoder_ffn_embed_dim=10240, dropout=0.0, attention_dropout=0.0, activation_fn='gelu', share_decoder_input_output_embed=True, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, decoder_layerdrop=0, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, base_layers=0, base_sublayers=1, base_shuffle=False, add_bos_token=False, no_token_positional_embeddings=False, character_embeddings=False, decoder_normalize_before=True, no_decoder_final_norm=False, adaptive_input=False, adaptive_input_factor=4, adaptive_input_cutoff=None, tie_adaptive_weights=False, tie_adaptive_proj=False, no_scale_embedding=False, layernorm_embedding=False, scale_fc=False, scale_attn=False, scale_heads=False, scale_resids=False, _name='sgd')}\n",
            "2024-03-01 18:00:23 | INFO | struprompting.tasks.fs_eval | dictionary: 51200 types\n",
            "2024-03-01 18:00:25 | WARNING | datasets.builder | Reusing dataset super_glue (/root/.cache/huggingface/datasets/super_glue/cb/1.0.2/d040c658e2ddef6934fdd97deb45c777b6ff50c524781ea434e7219b56a428a7)\n",
            "100%|██████████| 3/3 [00:00<00:00, 730.71it/s]\n",
            "2024-03-01 18:00:25 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/super_glue/cb/1.0.2/d040c658e2ddef6934fdd97deb45c777b6ff50c524781ea434e7219b56a428a7/cache-938493646037f99b.arrow\n",
            "2024-03-01 18:00:25 | WARNING | datasets.arrow_dataset | Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/super_glue/cb/1.0.2/d040c658e2ddef6934fdd97deb45c777b6ff50c524781ea434e7219b56a428a7/cache-51936d8860a97ff3.arrow\n",
            "2024-03-01 18:01:29 | WARNING | fairseq.models.fairseq_model | using 'args' is deprecated, please update your code to use dataclass config\n",
            "2024-03-01 18:01:31 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): GPTDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(51200, 2560, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
            "        (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
            "        (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=2560, out_features=51200, bias=False)\n",
            "  )\n",
            ")\n",
            "2024-03-01 18:01:31 | INFO | fairseq_cli.train | task: FewshotEval\n",
            "2024-03-01 18:01:31 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2024-03-01 18:01:31 | INFO | fairseq_cli.train | criterion: FewshotEvalCriterion\n",
            "2024-03-01 18:01:31 | INFO | fairseq_cli.train | num. shared model params: 2,648,724,480 (num. trained: 2,560)\n",
            "2024-03-01 18:01:31 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-03-01 18:01:35 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2024-03-01 18:01:35 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 18:01:35 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.564 GB ; name = NVIDIA A100-SXM4-40GB                   \n",
            "2024-03-01 18:01:35 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-03-01 18:01:35 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-03-01 18:01:35 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 3\n",
            "2024-03-01 18:01:35 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt\n",
            "2024-03-01 18:01:35 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last.pt\n",
            "2024-03-01 18:01:35 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-03-01 18:01:35 | INFO | fairseq_cli.train | Start validating\n",
            "2024-03-01 18:01:35 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "------------ example 0 input str train is [\"For a while the notion gripped him, and he prowled the many floors of Hamleys looking for toys. He bought a magic set for Sebastian (although his ideal present for the kid would have been a brand-new name) and a marionette for Louise. He could remember that there was an age for puppets and magic just as he could remember the time that he 'd spent trying to fan a deck of cards or sitting in front of a mirror trying to get the hard consonants down like a real ventriloquist. Question: there was an age for puppets and magic. True, False, or Neither? Answer:\", \"For a while the notion gripped him, and he prowled the many floors of Hamleys looking for toys. He bought a magic set for Sebastian (although his ideal present for the kid would have been a brand-new name) and a marionette for Louise. He could remember that there was an age for puppets and magic just as he could remember the time that he 'd spent trying to fan a deck of cards or sitting in front of a mirror trying to get the hard consonants down like a real ventriloquist. Question: there was an age for puppets and magic. True, False, or Neither? Answer:\", \"For a while the notion gripped him, and he prowled the many floors of Hamleys looking for toys. He bought a magic set for Sebastian (although his ideal present for the kid would have been a brand-new name) and a marionette for Louise. He could remember that there was an age for puppets and magic just as he could remember the time that he 'd spent trying to fan a deck of cards or sitting in front of a mirror trying to get the hard consonants down like a real ventriloquist. Question: there was an age for puppets and magic. True, False, or Neither? Answer:\"]\n",
            "------------ example 0 label str train is [' True', ' False', ' Neither']\n",
            "------------ example 1 input str train is [\"``For God's sake keep them in their seats. If we get panic people are going to be crushed to death and there will be mayhem in the car park.'' The announcer could only guess from the urgency in the Chief Constable's voice that the situation was very very serious. Question: the situation was very very serious. True, False, or Neither? Answer:\", \"``For God's sake keep them in their seats. If we get panic people are going to be crushed to death and there will be mayhem in the car park.'' The announcer could only guess from the urgency in the Chief Constable's voice that the situation was very very serious. Question: the situation was very very serious. True, False, or Neither? Answer:\", \"``For God's sake keep them in their seats. If we get panic people are going to be crushed to death and there will be mayhem in the car park.'' The announcer could only guess from the urgency in the Chief Constable's voice that the situation was very very serious. Question: the situation was very very serious. True, False, or Neither? Answer:\"]\n",
            "------------ example 1 label str train is [' True', ' False', ' Neither']\n",
            "------------ example 0 input str valid is [\"A: Well, actually, uh, A: I don't think I'm in the, uh, majority in Texas Question: she is in the majority in Texas. True, False, or Neither? Answer:\", \"A: Well, actually, uh, A: I don't think I'm in the, uh, majority in Texas Question: she is in the majority in Texas. True, False, or Neither? Answer:\", \"A: Well, actually, uh, A: I don't think I'm in the, uh, majority in Texas Question: she is in the majority in Texas. True, False, or Neither? Answer:\"]\n",
            "------------ example 0 label str valid is [' True', ' False', ' Neither']\n",
            "------------ example 1 input str valid is [\"A: and that rolling kind of, uh, B: Terrain. A: Yeah. is fairly famili-,. The thing that I thought was interesting was that the critics, apparently it's going to win everything. B: Really? A: Uh, and I had been told, you know, you wouldn't notice that it was three hours long, and all this, kind of, Question: it was three hours long. True, False, or Neither? Answer:\", \"A: and that rolling kind of, uh, B: Terrain. A: Yeah. is fairly famili-,. The thing that I thought was interesting was that the critics, apparently it's going to win everything. B: Really? A: Uh, and I had been told, you know, you wouldn't notice that it was three hours long, and all this, kind of, Question: it was three hours long. True, False, or Neither? Answer:\", \"A: and that rolling kind of, uh, B: Terrain. A: Yeah. is fairly famili-,. The thing that I thought was interesting was that the critics, apparently it's going to win everything. B: Really? A: Uh, and I had been told, you know, you wouldn't notice that it was three hours long, and all this, kind of, Question: it was three hours long. True, False, or Neither? Answer:\"]\n",
            "------------ example 1 label str valid is [' True', ' False', ' Neither']\n",
            "NOTE: true K of baseline is 19, max valid len is 280\n",
            "| Loaded valid with 168 samples\n",
            "| Loaded train with 168 samples\n",
            "2024-03-01 18:01:55 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 1.529 | nll_loss 0 | accuracy 55.4 | f1 0 | pos_proportion 41.1 | neg_proportion 50 | wps 16839.8 | wpb 5503.4 | bsz 1 | num_updates 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash analyze.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CI7cIAJ5uuQN",
        "outputId": "de35a5eb-fd12-4f7b-85cb-43a60f347355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+ model=1_3b\n",
            "+ task=cb\n",
            "+ python icl_ft/compute_sim.py cb all 1_3b\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/cb/ftzs 56\n",
            "loading ftzs data costs 3.0781056880950928 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/cb/zs 56\n",
            "loading zs data costs 2.6068997383117676 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/cb/icl 56\n",
            "loading icl data costs 3.4738876819610596 seconds\n",
            "================= number of both F2T examples: 22\n",
            "================= number of ICL F2T examples: 22\n",
            "================= number of FTZS F2T examples: 24\n",
            "++++++++++++++++ ICL recall to FT: 91.67\n",
            "count_f2t costs 0.00015163421630859375 seconds\n",
            "============================== analyzing self_attn_out_hiddens ==============================\n",
            "per-layer updates sim (icl-zs)&(ftzs-zs):\n",
            " [0.0313 0.0067 0.1782 0.2433 0.4174 0.0184 0.1737 0.1901 0.2254 0.182\n",
            " 0.2396 0.3182 0.2467 0.3523 0.23   0.2654 0.1857 0.1065 0.1797 0.2625\n",
            " 0.0968 0.2039 0.2625 0.2905]\n",
            "overall updates sim (icl-zs)&(ftzs-zs):\n",
            " 0.2045\n",
            "\n",
            "per-layer updates sim (icl-zs)&(random):\n",
            " [-0.0043  0.009   0.0205  0.0169  0.0088  0.0101  0.0041 -0.0059 -0.003\n",
            "  0.0066  0.0038 -0.0001 -0.0059  0.0005 -0.0034  0.0018  0.0025 -0.0031\n",
            "  0.0038 -0.0002  0.0052  0.0059  0.0061 -0.0035]\n",
            "overall updates sim (icl-zs)&(random):\n",
            " 0.0032\n",
            "\n",
            "analyze_sim costs 0.5044918060302734 seconds\n",
            "============================== analyzing attn_map, softmax=False ==============================\n",
            "per-layer direct sim (icl)&(zs):\n",
            " [-0.2153  0.2278  0.1349 -0.2483  0.232   0.3968  0.4967  0.4511  0.2412\n",
            "  0.1129 -0.0654 -0.2182 -0.3488 -0.3696 -0.5159 -0.181  -0.1332 -0.1679\n",
            " -0.0595  0.5459  0.8042  0.8612  0.942   0.7346]\n",
            "overall direct sim (icl)&(zs):\n",
            " 0.1524\n",
            "\n",
            "per-layer direct sim (icl)&(ftzs):\n",
            " [-0.2153  0.2261  0.1849 -0.2033  0.253   0.4577  0.5148  0.4736  0.2684\n",
            "  0.1645  0.0731 -0.2318 -0.4057 -0.1792 -0.4702  0.0916  0.0376 -0.0437\n",
            " -0.0503  0.5348  0.824   0.793   0.9051  0.7348]\n",
            "overall direct sim (icl)&(ftzs):\n",
            " 0.1974\n",
            "\n",
            "analyze_attn_map (w/o softmax) costs 10.248771667480469 seconds\n",
            "saving data costs 0.6239371299743652 seconds\n",
            "+ task=sst2\n",
            "+ python icl_ft/compute_sim.py sst2 all 1_3b\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst2/ftzs 872\n",
            "loading ftzs data costs 28.38960599899292 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst2/zs 872\n",
            "loading zs data costs 18.30312705039978 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst2/icl 872\n",
            "loading icl data costs 20.5312716960907 seconds\n",
            "================= number of both F2T examples: 45\n",
            "================= number of ICL F2T examples: 227\n",
            "================= number of FTZS F2T examples: 49\n",
            "++++++++++++++++ ICL recall to FT: 91.84\n",
            "count_f2t costs 0.0013861656188964844 seconds\n",
            "============================== analyzing self_attn_out_hiddens ==============================\n",
            "per-layer updates sim (icl-zs)&(ftzs-zs):\n",
            " [-0.0653 -0.1167 -0.0522  0.3658  0.1393  0.0625  0.2185  0.1852  0.0374\n",
            "  0.1821  0.1347  0.1507  0.2331  0.2052  0.241   0.1803  0.1987  0.0965\n",
            "  0.1212 -0.0905  0.1633 -0.0791 -0.2545  0.3766]\n",
            "overall updates sim (icl-zs)&(ftzs-zs):\n",
            " 0.1097\n",
            "\n",
            "per-layer updates sim (icl-zs)&(random):\n",
            " [-0.0119  0.009   0.0202  0.0151  0.006   0.0087  0.0126 -0.005  -0.0019\n",
            " -0.0068 -0.007  -0.0019 -0.0027  0.0045  0.0033 -0.0019 -0.0012 -0.0016\n",
            " -0.0026 -0.0067 -0.0053 -0.      0.0074  0.0092]\n",
            "overall updates sim (icl-zs)&(random):\n",
            " 0.0016\n",
            "\n",
            "analyze_sim costs 7.85693359375 seconds\n",
            "============================== analyzing attn_map, softmax=False ==============================\n",
            "per-layer direct sim (icl)&(zs):\n",
            " [0.1751 0.5387 0.3876 0.3218 0.7105 0.8526 0.8505 0.7659 0.8727 0.6579\n",
            " 0.3527 0.3829 0.2426 0.4617 0.4751 0.5187 0.2762 0.0838 0.3084 0.7135\n",
            " 0.8789 0.865  0.9158 0.7029]\n",
            "overall direct sim (icl)&(zs):\n",
            " 0.5547\n",
            "\n",
            "per-layer direct sim (icl)&(ftzs):\n",
            " [0.1751 0.5385 0.3865 0.321  0.7099 0.8536 0.8505 0.7653 0.873  0.6684\n",
            " 0.3651 0.4564 0.2581 0.5389 0.4069 0.6378 0.4834 0.2553 0.4105 0.7292\n",
            " 0.8608 0.8801 0.9139 0.7048]\n",
            "overall direct sim (icl)&(ftzs):\n",
            " 0.5851\n",
            "\n",
            "analyze_attn_map (w/o softmax) costs 53.229947090148926 seconds\n",
            "saving data costs 0.5770065784454346 seconds\n",
            "+ task=sst5\n",
            "+ python icl_ft/compute_sim.py sst5 all 1_3b\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst5/ftzs 1101\n",
            "loading ftzs data costs 36.60936665534973 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst5/zs 1101\n",
            "loading zs data costs 21.914395332336426 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/sst5/icl 1101\n",
            "loading icl data costs 27.147708415985107 seconds\n",
            "================= number of both F2T examples: 6\n",
            "================= number of ICL F2T examples: 181\n",
            "================= number of FTZS F2T examples: 10\n",
            "++++++++++++++++ ICL recall to FT: 60.00\n",
            "count_f2t costs 0.002310037612915039 seconds\n",
            "============================== analyzing self_attn_out_hiddens ==============================\n",
            "per-layer updates sim (icl-zs)&(ftzs-zs):\n",
            " [-0.057  -0.1108  0.1417  0.2693  0.1077 -0.1081  0.0842  0.2456  0.0733\n",
            "  0.0257  0.0795  0.1256  0.1645  0.1411  0.1154  0.0737  0.0807 -0.0038\n",
            "  0.0499 -0.176   0.1528 -0.002   0.1107  0.3164]\n",
            "overall updates sim (icl-zs)&(ftzs-zs):\n",
            " 0.0792\n",
            "\n",
            "per-layer updates sim (icl-zs)&(random):\n",
            " [ 0.001   0.0086  0.0197  0.0174  0.0107  0.0059  0.0069 -0.0005  0.0005\n",
            " -0.0062 -0.0091  0.0031  0.001   0.0019  0.0024 -0.0007 -0.0018 -0.0028\n",
            "  0.0004  0.0018 -0.0041  0.0025  0.0017 -0.0004]\n",
            "overall updates sim (icl-zs)&(random):\n",
            " 0.0025\n",
            "\n",
            "analyze_sim costs 13.433215379714966 seconds\n",
            "============================== analyzing attn_map, softmax=False ==============================\n",
            "per-layer direct sim (icl)&(zs):\n",
            " [ 0.0269  0.4767  0.2478  0.0935  0.5246  0.6042  0.7052  0.5133  0.6415\n",
            "  0.3054  0.3177  0.2341  0.0542 -0.1718 -0.1955  0.3057  0.1826  0.0445\n",
            "  0.3417  0.7194  0.8545  0.8711  0.9026  0.7913]\n",
            "overall direct sim (icl)&(zs):\n",
            " 0.3913\n",
            "\n",
            "per-layer direct sim (icl)&(ftzs):\n",
            " [ 0.0269  0.4767  0.2479  0.0943  0.525   0.6046  0.7057  0.5142  0.6431\n",
            "  0.3107  0.3296  0.2473  0.0787 -0.1454 -0.1522  0.3532  0.2551  0.0897\n",
            "  0.3522  0.7242  0.8498  0.8743  0.8998  0.797 ]\n",
            "overall direct sim (icl)&(ftzs):\n",
            " 0.4043\n",
            "\n",
            "analyze_attn_map (w/o softmax) costs 65.72487664222717 seconds\n",
            "saving data costs 0.6116139888763428 seconds\n",
            "+ task=subj\n",
            "+ python icl_ft/compute_sim.py subj all 1_3b\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/subj/ftzs 2000\n",
            "loading ftzs data costs 66.44762969017029 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/subj/zs 2000\n",
            "loading zs data costs 43.313674211502075 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/subj/icl 2000\n",
            "loading icl data costs 52.32833456993103 seconds\n",
            "================= number of both F2T examples: 225\n",
            "================= number of ICL F2T examples: 436\n",
            "================= number of FTZS F2T examples: 259\n",
            "++++++++++++++++ ICL recall to FT: 86.87\n",
            "count_f2t costs 0.003157377243041992 seconds\n",
            "============================== analyzing self_attn_out_hiddens ==============================\n",
            "per-layer updates sim (icl-zs)&(ftzs-zs):\n",
            " [ 0.3845  0.0352 -0.0777 -0.1806  0.1303  0.0457  0.2879  0.2666  0.199\n",
            "  0.2237  0.269   0.2974  0.32    0.3175  0.3766  0.3118  0.3488  0.1764\n",
            "  0.2407  0.1832  0.208   0.0348  0.1414  0.0503]\n",
            "overall updates sim (icl-zs)&(ftzs-zs):\n",
            " 0.1913\n",
            "\n",
            "per-layer updates sim (icl-zs)&(random):\n",
            " [-0.0012 -0.0009  0.0218  0.0199  0.0082  0.0045  0.0091 -0.0056  0.0027\n",
            " -0.0028 -0.01    0.004   0.0013  0.0005  0.0026 -0.0015 -0.0046 -0.0015\n",
            "  0.0033 -0.0101 -0.0006  0.0078  0.0067 -0.0004]\n",
            "overall updates sim (icl-zs)&(random):\n",
            " 0.0022\n",
            "\n",
            "analyze_sim costs 23.519711017608643 seconds\n",
            "============================== analyzing attn_map, softmax=False ==============================\n",
            "per-layer direct sim (icl)&(zs):\n",
            " [-0.0702  0.418   0.1401  0.0201  0.4842  0.5555  0.6671  0.4695  0.586\n",
            "  0.3341  0.4048  0.2982  0.1346 -0.0851 -0.1824  0.3434  0.126   0.0048\n",
            "  0.3538  0.7018  0.8723  0.8725  0.9017  0.7367]\n",
            "overall direct sim (icl)&(zs):\n",
            " 0.3786\n",
            "\n",
            "per-layer direct sim (icl)&(ftzs):\n",
            " [-0.0702  0.4149  0.1312  0.0175  0.4839  0.5584  0.6688  0.4817  0.6025\n",
            "  0.3485  0.5143  0.5389  0.3886  0.1168  0.1811  0.6837  0.6391  0.4594\n",
            "  0.5546  0.7341  0.8438  0.8447  0.885   0.7451]\n",
            "overall direct sim (icl)&(ftzs):\n",
            " 0.4903\n",
            "\n",
            "analyze_attn_map (w/o softmax) costs 188.87863183021545 seconds\n",
            "saving data costs 1.6360316276550293 seconds\n",
            "+ task=mr\n",
            "+ python icl_ft/compute_sim.py mr all 1_3b\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/mr/ftzs 1066\n",
            "loading ftzs data costs 33.26585030555725 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/mr/zs 1066\n",
            "loading zs data costs 21.763442277908325 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/mr/icl 1066\n",
            "loading icl data costs 27.202364206314087 seconds\n",
            "================= number of both F2T examples: 133\n",
            "================= number of ICL F2T examples: 318\n",
            "================= number of FTZS F2T examples: 137\n",
            "++++++++++++++++ ICL recall to FT: 97.08\n",
            "count_f2t costs 0.0018298625946044922 seconds\n",
            "============================== analyzing self_attn_out_hiddens ==============================\n",
            "per-layer updates sim (icl-zs)&(ftzs-zs):\n",
            " [0.5598 0.1662 0.0316 0.0094 0.0984 0.1126 0.1355 0.1193 0.1037 0.1716\n",
            " 0.2017 0.2812 0.3242 0.3899 0.4287 0.3681 0.3064 0.2286 0.3154 0.1512\n",
            " 0.286  0.2471 0.1352 0.157 ]\n",
            "overall updates sim (icl-zs)&(ftzs-zs):\n",
            " 0.222\n",
            "\n",
            "per-layer updates sim (icl-zs)&(random):\n",
            " [ 0.001   0.0012  0.0199  0.0093  0.0039  0.0034  0.0123 -0.002  -0.0006\n",
            " -0.0049 -0.0096  0.001  -0.0043  0.0027  0.0033  0.0004 -0.0048 -0.0009\n",
            " -0.0055 -0.0098 -0.002   0.0001  0.0037  0.0021]\n",
            "overall updates sim (icl-zs)&(random):\n",
            " 0.0008\n",
            "\n",
            "analyze_sim costs 9.593490839004517 seconds\n",
            "============================== analyzing attn_map, softmax=False ==============================\n",
            "per-layer direct sim (icl)&(zs):\n",
            " [-0.0026  0.3987  0.2295  0.0299  0.5606  0.6712  0.7162  0.5954  0.6585\n",
            "  0.2908  0.3305  0.1964  0.071  -0.1713 -0.34    0.3649  0.2234  0.1702\n",
            "  0.4279  0.6942  0.8641  0.8939  0.9262  0.7514]\n",
            "overall direct sim (icl)&(zs):\n",
            " 0.398\n",
            "\n",
            "per-layer direct sim (icl)&(ftzs):\n",
            " [-0.0026  0.3969  0.2224  0.0297  0.5598  0.6722  0.7173  0.5908  0.6609\n",
            "  0.2903  0.3572  0.265   0.2073  0.2003  0.1004  0.796   0.6999  0.5897\n",
            "  0.6402  0.6616  0.7916  0.865   0.9044  0.7363]\n",
            "overall direct sim (icl)&(ftzs):\n",
            " 0.498\n",
            "\n",
            "analyze_attn_map (w/o softmax) costs 70.01754069328308 seconds\n",
            "saving data costs 0.6013298034667969 seconds\n",
            "+ task=agnews\n",
            "+ python icl_ft/compute_sim.py agnews all 1_3b\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/agnews/ftzs 2000\n",
            "loading ftzs data costs 80.60443162918091 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/agnews/zs 2000\n",
            "loading zs data costs 57.54184174537659 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/agnews/icl 2000\n",
            "loading icl data costs 75.99468350410461 seconds\n",
            "================= number of both F2T examples: 615\n",
            "================= number of ICL F2T examples: 783\n",
            "================= number of FTZS F2T examples: 787\n",
            "++++++++++++++++ ICL recall to FT: 78.14\n",
            "count_f2t costs 0.00405120849609375 seconds\n",
            "============================== analyzing self_attn_out_hiddens ==============================\n",
            "per-layer updates sim (icl-zs)&(ftzs-zs):\n",
            " [0.0876 0.279  0.2855 0.2968 0.6705 0.2532 0.4551 0.2578 0.2592 0.3619\n",
            " 0.3391 0.3143 0.377  0.408  0.4486 0.3054 0.2978 0.2554 0.2984 0.2587\n",
            " 0.2242 0.0952 0.1002 0.5359]\n",
            "overall updates sim (icl-zs)&(ftzs-zs):\n",
            " 0.311\n",
            "\n",
            "per-layer updates sim (icl-zs)&(random):\n",
            " [-0.0041  0.0049  0.019   0.0196  0.0152  0.0059  0.0062 -0.0005  0.0007\n",
            " -0.0031  0.0067  0.0027  0.0003  0.0026 -0.0031 -0.0026 -0.0015 -0.0046\n",
            " -0.0044 -0.0045 -0.      0.006  -0.006  -0.0064]\n",
            "overall updates sim (icl-zs)&(random):\n",
            " 0.002\n",
            "\n",
            "analyze_sim costs 26.570494651794434 seconds\n",
            "============================== analyzing attn_map, softmax=False ==============================\n",
            "per-layer direct sim (icl)&(zs):\n",
            " [-0.2952  0.2459  0.0676 -0.3539  0.0443  0.2206  0.4865  0.2424  0.2267\n",
            "  0.0823  0.1025 -0.1693 -0.195  -0.1889 -0.3543  0.1721 -0.2649 -0.2501\n",
            "  0.0293  0.5589  0.8034  0.8299  0.9048  0.6947]\n",
            "overall direct sim (icl)&(zs):\n",
            " 0.1517\n",
            "\n",
            "per-layer direct sim (icl)&(ftzs):\n",
            " [-0.2945  0.1722  0.0606 -0.2746  0.108   0.398   0.609   0.6046  0.4597\n",
            "  0.5186  0.6411  0.2562  0.5224  0.466   0.4711  0.6861  0.6237  0.6792\n",
            "  0.6291  0.6214  0.7341  0.8582  0.8567  0.7695]\n",
            "overall direct sim (icl)&(ftzs):\n",
            " 0.4657\n",
            "\n",
            "analyze_attn_map (w/o softmax) costs 318.8859894275665 seconds\n",
            "saving data costs 0.6467461585998535 seconds\n",
            "+ model=2_7b\n",
            "+ task=cb\n",
            "+ python icl_ft/compute_sim.py cb all 2_7b\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/cb/ftzs 56\n",
            "loading ftzs data costs 4.138953685760498 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/cb/zs 56\n",
            "loading zs data costs 3.0274810791015625 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/cb/icl 56\n",
            "loading icl data costs 3.6918702125549316 seconds\n",
            "================= number of both F2T examples: 22\n",
            "================= number of ICL F2T examples: 25\n",
            "================= number of FTZS F2T examples: 24\n",
            "++++++++++++++++ ICL recall to FT: 91.67\n",
            "count_f2t costs 0.0001461505889892578 seconds\n",
            "============================== analyzing self_attn_out_hiddens ==============================\n",
            "per-layer updates sim (icl-zs)&(ftzs-zs):\n",
            " [ 0.3898 -0.0955 -0.3763  0.0646  0.0563  0.0633 -0.0083  0.0324  0.1075\n",
            "  0.1353  0.1036  0.1816  0.2059  0.2172  0.2645  0.2505  0.1705  0.3284\n",
            "  0.2967  0.0906  0.2788  0.2122  0.1067  0.3065  0.1873  0.2634  0.2306\n",
            "  0.3045  0.0484  0.0733  0.2437 -0.0372]\n",
            "overall updates sim (icl-zs)&(ftzs-zs):\n",
            " 0.1468\n",
            "\n",
            "per-layer updates sim (icl-zs)&(random):\n",
            " [-0.0084 -0.0189 -0.021  -0.0161  0.0021  0.0016 -0.004  -0.003   0.0009\n",
            "  0.0036 -0.0026  0.001   0.0019  0.0029  0.0044  0.0024  0.006   0.0017\n",
            "  0.0042  0.0052  0.0017 -0.0002 -0.0077  0.0027  0.005   0.0015 -0.0107\n",
            " -0.009   0.0103  0.0104  0.0027  0.0124]\n",
            "overall updates sim (icl-zs)&(random):\n",
            " -0.0005\n",
            "\n",
            "analyze_sim costs 0.8348631858825684 seconds\n",
            "============================== analyzing attn_map, softmax=False ==============================\n",
            "per-layer direct sim (icl)&(zs):\n",
            " [-0.101   0.5238 -0.0296  0.4821  0.4563  0.4127  0.4973 -0.1582  0.0104\n",
            "  0.0662  0.0057 -0.3233 -0.2195 -0.2868 -0.2893 -0.5876 -0.2601 -0.5607\n",
            "  0.1578  0.1107  0.1009  0.0541  0.3882  0.4272  0.4004  0.8133  0.7091\n",
            "  0.959   0.8744  0.8466  0.9434  0.8807]\n",
            "overall direct sim (icl)&(zs):\n",
            " 0.2283\n",
            "\n",
            "per-layer direct sim (icl)&(ftzs):\n",
            " [-0.101   0.5234 -0.0265  0.4828  0.4568  0.4109  0.4972 -0.1605  0.0114\n",
            "  0.0706 -0.0099 -0.3382 -0.214  -0.2794 -0.2928 -0.5986 -0.2872 -0.5197\n",
            "  0.0737  0.1051  0.107   0.0879  0.3726  0.4661  0.4408  0.8437  0.6567\n",
            "  0.9565  0.8429  0.7696  0.9423  0.9527]\n",
            "overall direct sim (icl)&(ftzs):\n",
            " 0.2263\n",
            "\n",
            "analyze_attn_map (w/o softmax) costs 13.347254037857056 seconds\n",
            "saving data costs 0.00648045539855957 seconds\n",
            "+ task=sst2\n",
            "+ python icl_ft/compute_sim.py sst2 all 2_7b\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst2/ftzs 872\n",
            "loading ftzs data costs 44.585288524627686 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst2/zs 872\n",
            "loading zs data costs 25.47076725959778 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst2/icl 872\n",
            "loading icl data costs 31.23105263710022 seconds\n",
            "================= number of both F2T examples: 122\n",
            "================= number of ICL F2T examples: 227\n",
            "================= number of FTZS F2T examples: 126\n",
            "++++++++++++++++ ICL recall to FT: 96.83\n",
            "count_f2t costs 0.0014774799346923828 seconds\n",
            "============================== analyzing self_attn_out_hiddens ==============================\n",
            "per-layer updates sim (icl-zs)&(ftzs-zs):\n",
            " [-9.550e-02 -1.816e-01 -1.432e-01 -1.674e-01  6.250e-02 -2.000e-04\n",
            "  1.248e-01  7.310e-02  1.075e-01  2.567e-01  3.056e-01  3.385e-01\n",
            "  2.463e-01  3.156e-01  3.312e-01  3.627e-01  3.909e-01  4.520e-01\n",
            "  3.097e-01  4.061e-01  3.603e-01  2.811e-01  2.252e-01  1.621e-01\n",
            "  3.470e-01  2.708e-01  3.514e-01  4.119e-01  1.406e-01  1.613e-01\n",
            " -3.310e-02  6.250e-02]\n",
            "overall updates sim (icl-zs)&(ftzs-zs):\n",
            " 0.1949\n",
            "\n",
            "per-layer updates sim (icl-zs)&(random):\n",
            " [-0.0075 -0.0066 -0.0139 -0.0016  0.0005 -0.0047  0.0008  0.0019  0.0014\n",
            " -0.001  -0.0011  0.0037 -0.0074  0.0031  0.0106  0.0024  0.001  -0.0026\n",
            " -0.0002  0.0029 -0.0017 -0.0024  0.0012 -0.0071  0.      0.0029 -0.0167\n",
            " -0.0069  0.0003  0.011   0.0222  0.014 ]\n",
            "overall updates sim (icl-zs)&(random):\n",
            " -0.0\n",
            "\n",
            "analyze_sim costs 13.055664300918579 seconds\n",
            "============================== analyzing attn_map, softmax=False ==============================\n",
            "per-layer direct sim (icl)&(zs):\n",
            " [0.2047 0.5536 0.2782 0.7938 0.814  0.7326 0.7294 0.4852 0.7265 0.8171\n",
            " 0.6662 0.6745 0.8366 0.7178 0.7323 0.8808 0.4642 0.8015 0.454  0.7478\n",
            " 0.5999 0.5494 0.548  0.5345 0.5272 0.8707 0.7893 0.9745 0.8667 0.7927\n",
            " 0.9662 0.8576]\n",
            "overall direct sim (icl)&(zs):\n",
            " 0.6871\n",
            "\n",
            "per-layer direct sim (icl)&(ftzs):\n",
            " [0.2047 0.5516 0.2797 0.7938 0.8126 0.7344 0.7282 0.4697 0.7244 0.7923\n",
            " 0.6643 0.6871 0.8591 0.6924 0.7043 0.6933 0.4822 0.6829 0.5986 0.6402\n",
            " 0.5621 0.6629 0.7188 0.6367 0.6022 0.8978 0.7634 0.9502 0.8511 0.7717\n",
            " 0.9248 0.8394]\n",
            "overall direct sim (icl)&(ftzs):\n",
            " 0.6868\n",
            "\n",
            "analyze_attn_map (w/o softmax) costs 71.13257575035095 seconds\n",
            "saving data costs 0.006400108337402344 seconds\n",
            "+ task=sst5\n",
            "+ python icl_ft/compute_sim.py sst5 all 2_7b\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst5/ftzs 1101\n",
            "loading ftzs data costs 56.27753305435181 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst5/zs 1101\n",
            "loading zs data costs 35.376439809799194 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst5/icl 1101\n",
            "loading icl data costs 38.65676164627075 seconds\n",
            "================= number of both F2T examples: 43\n",
            "================= number of ICL F2T examples: 180\n",
            "================= number of FTZS F2T examples: 55\n",
            "++++++++++++++++ ICL recall to FT: 78.18\n",
            "count_f2t costs 0.002489328384399414 seconds\n",
            "============================== analyzing self_attn_out_hiddens ==============================\n",
            "per-layer updates sim (icl-zs)&(ftzs-zs):\n",
            " [-0.4582 -0.0329  0.0812  0.3075  0.3438  0.3521  0.3853  0.2515  0.3299\n",
            "  0.3637  0.3158  0.4181  0.4145  0.4292  0.4236  0.4506  0.4288  0.4235\n",
            "  0.2785  0.4092  0.415   0.3045  0.3038  0.2267  0.3259  0.2947  0.3458\n",
            "  0.423   0.1841  0.4086  0.3132  0.5146]\n",
            "overall updates sim (icl-zs)&(ftzs-zs):\n",
            " 0.3117\n",
            "\n",
            "per-layer updates sim (icl-zs)&(random):\n",
            " [-0.0101 -0.0074 -0.0095 -0.0068 -0.0038  0.0003 -0.0029 -0.005   0.0022\n",
            " -0.0065 -0.0028  0.0032 -0.0031  0.002   0.0001  0.0036  0.0025  0.0017\n",
            "  0.0078  0.0036  0.0064 -0.0029 -0.0007 -0.0077 -0.0025  0.0078 -0.0113\n",
            " -0.0119 -0.0052  0.0034  0.013  -0.005 ]\n",
            "overall updates sim (icl-zs)&(random):\n",
            " -0.0015\n",
            "\n",
            "analyze_sim costs 22.77285385131836 seconds\n",
            "============================== analyzing attn_map, softmax=False ==============================\n",
            "per-layer direct sim (icl)&(zs):\n",
            " [ 1.285e-01  6.437e-01  1.811e-01  7.024e-01  6.885e-01  6.557e-01\n",
            "  6.364e-01  1.186e-01  4.231e-01  5.582e-01  1.825e-01  7.900e-02\n",
            "  9.030e-02  9.230e-02  8.000e-04 -2.966e-01 -1.086e-01 -4.696e-01\n",
            "  2.224e-01  2.521e-01  1.700e-01  1.421e-01  3.153e-01  3.568e-01\n",
            "  3.568e-01  8.413e-01  7.122e-01  9.550e-01  8.300e-01  8.556e-01\n",
            "  9.519e-01  8.851e-01]\n",
            "overall direct sim (icl)&(zs):\n",
            " 0.3798\n",
            "\n",
            "per-layer direct sim (icl)&(ftzs):\n",
            " [ 0.1283  0.6406  0.1878  0.7011  0.6894  0.6696  0.6355  0.0954  0.3755\n",
            "  0.5229  0.3318  0.4524  0.3051  0.3084  0.4034 -0.0659  0.0639 -0.1942\n",
            "  0.5047  0.3955  0.2955  0.4447  0.688   0.6405  0.7863  0.9032  0.8206\n",
            "  0.9224  0.7959  0.8458  0.9499  0.8701]\n",
            "overall direct sim (icl)&(ftzs):\n",
            " 0.5036\n",
            "\n",
            "analyze_attn_map (w/o softmax) costs 89.4586591720581 seconds\n",
            "saving data costs 0.006705522537231445 seconds\n",
            "+ task=subj\n",
            "+ python icl_ft/compute_sim.py subj all 2_7b\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/subj/ftzs 2000\n",
            "loading ftzs data costs 103.67561268806458 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/subj/zs 2000\n",
            "loading zs data costs 67.1111512184143 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/subj/icl 2000\n",
            "loading icl data costs 78.50928950309753 seconds\n",
            "================= number of both F2T examples: 257\n",
            "================= number of ICL F2T examples: 384\n",
            "================= number of FTZS F2T examples: 293\n",
            "++++++++++++++++ ICL recall to FT: 87.71\n",
            "count_f2t costs 0.0031082630157470703 seconds\n",
            "============================== analyzing self_attn_out_hiddens ==============================\n",
            "per-layer updates sim (icl-zs)&(ftzs-zs):\n",
            " [-0.4127  0.1562  0.1979  0.1772  0.3051  0.1721  0.2068  0.2305  0.0925\n",
            "  0.1742  0.1591  0.2237  0.1359  0.2223  0.1858  0.2646  0.2595  0.2984\n",
            "  0.2339  0.3446  0.2071  0.1526  0.2022  0.3213  0.4126  0.2645  0.2114\n",
            "  0.2864  0.4316  0.2959  0.1733  0.1924]\n",
            "overall updates sim (icl-zs)&(ftzs-zs):\n",
            " 0.2118\n",
            "\n",
            "per-layer updates sim (icl-zs)&(random):\n",
            " [-0.0108 -0.0052 -0.0162 -0.0119 -0.0015 -0.0039  0.0037 -0.0006 -0.\n",
            "  0.0048 -0.0067 -0.0005 -0.0053  0.0031  0.0059  0.0032  0.0033  0.0003\n",
            "  0.0049  0.0017  0.0099 -0.0003  0.0016 -0.01   -0.0015  0.0013 -0.0127\n",
            "  0.0004  0.0045  0.0126  0.0191  0.0217]\n",
            "overall updates sim (icl-zs)&(random):\n",
            " 0.0005\n",
            "\n",
            "analyze_sim costs 43.80366897583008 seconds\n",
            "============================== analyzing attn_map, softmax=False ==============================\n",
            "per-layer direct sim (icl)&(zs):\n",
            " [ 0.0305  0.6137  0.0305  0.6059  0.565   0.5521  0.598  -0.0501  0.2848\n",
            "  0.4132  0.1054 -0.017   0.0045 -0.055  -0.182  -0.369  -0.0214 -0.3671\n",
            "  0.3517  0.3175  0.3098  0.2773  0.3688  0.3941  0.4636  0.8327  0.6823\n",
            "  0.9675  0.8155  0.7374  0.92    0.8886]\n",
            "overall direct sim (icl)&(zs):\n",
            " 0.3459\n",
            "\n",
            "per-layer direct sim (icl)&(ftzs):\n",
            " [ 3.050e-02  6.128e-01  2.680e-02  6.052e-01  5.663e-01  5.546e-01\n",
            "  5.998e-01 -4.840e-02  2.773e-01  4.013e-01  1.179e-01 -5.000e-04\n",
            "  5.100e-03 -5.510e-02 -1.773e-01 -3.322e-01  1.020e-02 -2.658e-01\n",
            "  5.089e-01  3.571e-01  3.945e-01  3.725e-01  4.641e-01  4.929e-01\n",
            "  4.924e-01  8.880e-01  7.177e-01  9.614e-01  8.266e-01  7.545e-01\n",
            "  9.005e-01  8.998e-01]\n",
            "overall direct sim (icl)&(ftzs):\n",
            " 0.3737\n",
            "\n",
            "analyze_attn_map (w/o softmax) costs 253.51871848106384 seconds\n",
            "saving data costs 0.005342006683349609 seconds\n",
            "+ task=mr\n",
            "+ python icl_ft/compute_sim.py mr all 2_7b\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/mr/ftzs 1066\n",
            "loading ftzs data costs 54.00274109840393 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/mr/zs 1066\n",
            "loading zs data costs 33.642221212387085 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/mr/icl 1066\n",
            "loading icl data costs 40.13503861427307 seconds\n",
            "================= number of both F2T examples: 275\n",
            "================= number of ICL F2T examples: 358\n",
            "================= number of FTZS F2T examples: 287\n",
            "++++++++++++++++ ICL recall to FT: 95.82\n",
            "count_f2t costs 0.0020170211791992188 seconds\n",
            "============================== analyzing self_attn_out_hiddens ==============================\n",
            "per-layer updates sim (icl-zs)&(ftzs-zs):\n",
            " [-0.5963  0.28   -0.0162  0.1239 -0.106   0.0318  0.0636  0.0572  0.0711\n",
            "  0.1184  0.1188  0.1499  0.1751  0.2071  0.2178  0.2626  0.2759  0.295\n",
            "  0.2287  0.3066  0.3632  0.2289  0.073   0.0289  0.1975  0.2152  0.2331\n",
            "  0.439   0.1115  0.0066  0.257   0.5598]\n",
            "overall updates sim (icl-zs)&(ftzs-zs):\n",
            " 0.1556\n",
            "\n",
            "per-layer updates sim (icl-zs)&(random):\n",
            " [-0.0111 -0.0079 -0.0156 -0.001  -0.0016 -0.0028  0.0074  0.009   0.0028\n",
            "  0.0064  0.0019  0.0058 -0.0058  0.0005  0.0068  0.0038  0.0077 -0.0008\n",
            "  0.0031  0.0035  0.0027  0.0019  0.0007 -0.0053 -0.0015  0.0024 -0.014\n",
            " -0.0152 -0.0026  0.0045  0.0029  0.002 ]\n",
            "overall updates sim (icl-zs)&(random):\n",
            " -0.0003\n",
            "\n",
            "analyze_sim costs 15.958738565444946 seconds\n",
            "============================== analyzing attn_map, softmax=False ==============================\n",
            "per-layer direct sim (icl)&(zs):\n",
            " [-0.0715  0.4784 -0.0349  0.5668  0.6025  0.6224  0.5697 -0.0558  0.2556\n",
            "  0.2979  0.0444 -0.2322 -0.0953 -0.174  -0.1695 -0.4237 -0.1769 -0.4344\n",
            "  0.3834  0.2234  0.1917  0.2038  0.4276  0.4739  0.4843  0.8384  0.7664\n",
            "  0.9732  0.8448  0.8792  0.9405  0.8573]\n",
            "overall direct sim (icl)&(zs):\n",
            " 0.3143\n",
            "\n",
            "per-layer direct sim (icl)&(ftzs):\n",
            " [-0.0715  0.4781 -0.0366  0.5662  0.6026  0.6221  0.5695 -0.0623  0.2511\n",
            "  0.3021  0.0728 -0.2206 -0.0568 -0.1433 -0.1317 -0.3757 -0.1102 -0.3322\n",
            "  0.4785  0.3286  0.3461  0.4237  0.5756  0.5575  0.5606  0.8791  0.7093\n",
            "  0.9534  0.826   0.8263  0.8868  0.841 ]\n",
            "overall direct sim (icl)&(ftzs):\n",
            " 0.3474\n",
            "\n",
            "analyze_attn_map (w/o softmax) costs 94.18550562858582 seconds\n",
            "saving data costs 0.007136106491088867 seconds\n",
            "+ task=agnews\n",
            "+ python icl_ft/compute_sim.py agnews all 2_7b\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/icl_ft/compute_sim.py\", line 73, in <module>\n",
            "    ftzs_info = load_info('ftzs')\n",
            "  File \"/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/icl_ft/compute_sim.py\", line 30, in load_info\n",
            "    with open(f\"{rlt_dir}/record_info.jsonl\", \"r\") as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/agnews/ftzs/record_info.jsonl'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash analyze_continu.sh"
      ],
      "metadata": {
        "id": "QFGnUgrQDfjo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db857458-3518-431d-d54b-87423863bc9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+ model=1_3b\n",
            "+ model=2_7b\n",
            "+ task=cb\n",
            "+ python icl_ft/compute_training_example_attn.py cb 2_7b\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/icl_ft/compute_training_example_attn.py 18\n",
            "# !!! replace by your $base_dir/ana_rlt here \n",
            "curent base_dir {base_dir}\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/cb/ft 7\n",
            "loading ft data costs 14.675907611846924 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/cb/ftzs 56\n",
            "loading ftzs data costs 3.739922285079956 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/cb/icl 56\n",
            "loading icl data costs 3.7686679363250732 seconds\n",
            "sliced icl_attn_map_ctx shape: (56, 32, 543)\n",
            "slicing icl_attn_map_ctx costs 0.1785411834716797 seconds\n",
            "compacted ft_attn_q shape: (32, 543, 2560)\n",
            "compacting ft_attn_q costs 2.563101291656494 seconds\n",
            "=========================================\n",
            "example-level recall_topk: [0.7285714285714285, 0.6642857142857143, 0.7535714285714286, 0.6071428571428571, 0.6714285714285714, 0.6571428571428571, 0.7392857142857143, 0.7714285714285715, 0.7214285714285714, 0.6, 0.8, 0.7964285714285714, 0.7821428571428571, 0.8, 0.75, 0.6785714285714286, 0.6, 0.6, 0.6, 0.6071428571428571, 0.6, 0.6, 0.6035714285714285, 0.6642857142857143, 0.775, 0.7357142857142858, 0.6535714285714286, 0.8321428571428572, 0.8607142857142858, 0.8464285714285714, 0.8821428571428571, 0.6428571428571429]  |||  0.70703125\n",
            "example-level random_recall_topk: [0.7321428571428571, 0.7285714285714285, 0.6642857142857143, 0.7142857142857143, 0.7035714285714286, 0.6678571428571428, 0.7321428571428571, 0.7321428571428571, 0.6964285714285714, 0.7285714285714285, 0.7142857142857143, 0.65, 0.6964285714285714, 0.7535714285714286, 0.7535714285714286, 0.6857142857142857, 0.7035714285714286, 0.6857142857142857, 0.6857142857142857, 0.6892857142857143, 0.7214285714285714, 0.7107142857142857, 0.7035714285714286, 0.7035714285714286, 0.7571428571428571, 0.7392857142857143, 0.7428571428571429, 0.6964285714285714, 0.6964285714285714, 0.6857142857142857, 0.7714285714285715, 0.7]  |||  0.7108258928571429\n",
            "=========================================\n",
            "example-level kendall: [0.2670068027210884, -0.11564625850340136, -0.10204081632653063, -0.28061224489795916, -0.15816326530612246, -0.29931972789115646, -0.2585034013605441, 0.07993197278911564, -0.34013605442176864, -0.38435374149659857, -0.12755102040816335, -0.20578231292516996, -0.3027210884353741, -0.28741496598639454, -0.33163265306122447, -0.2585034013605441, -0.523809523809524, -0.37074829931972786, -0.5425170068027214, -0.09863945578231299, -0.1513605442176871, -0.3010204081632653, -0.0969387755102041, 0.022108843537414966, 0.41156462585034, 0.38435374149659846, 0.31632653061224486, 0.3486394557823128, 0.3350340136054421, 0.1989795918367346, 0.0969387755102041, 0.41836734693877553]  |||  -0.08306760204081635\n",
            "example-level random_kendall: [0.0017006802721088365, 0.005102040816326536, -0.042517006802721094, -0.018707482993197272, 0.056122448979591844, 0.04081632653061224, -0.01020408163265307, 0.010204081632653059, -0.09013605442176867, 0.09353741496598642, -0.011904761904761899, 0.001700680272108849, -0.07482993197278913, -0.025510204081632664, -0.017006802721088437, -0.044217687074829926, -0.0782312925170068, 0.015306122448979585, 0.03741496598639455, 0.025510204081632674, -0.04931972789115648, 0.008503401360544212, 0.018707482993197275, 0.05102040816326529, -0.03741496598639458, -0.05612244897959184, -0.010204081632653064, -0.010204081632653057, 0.05612244897959183, -0.03401360544217685, 0.05102040816326529, 0.01190476190476191]  |||  -0.003932823129251701\n",
            "=========================================\n",
            "token-level recall_topk: [0.20625, 0.18267857142857144, 0.20392857142857143, 0.205, 0.14982142857142858, 0.16196428571428573, 0.15785714285714286, 0.22321428571428573, 0.20714285714285716, 0.1780357142857143, 0.18589285714285714, 0.2225, 0.21821428571428572, 0.20982142857142858, 0.17464285714285716, 0.2716071428571429, 0.11732142857142858, 0.21642857142857144, 0.0775, 0.10053571428571428, 0.09357142857142857, 0.09285714285714286, 0.10571428571428572, 0.09053571428571429, 0.11410714285714285, 0.10267857142857142, 0.10678571428571429, 0.12803571428571428, 0.12053571428571429, 0.12410714285714286, 0.11553571428571428, 0.17]  |||  0.15733816964285716\n",
            "token-level random_recall_topk: [0.18892857142857142, 0.17589285714285716, 0.17642857142857143, 0.17625, 0.17625, 0.17625, 0.19767857142857143, 0.17964285714285713, 0.16660714285714287, 0.18214285714285713, 0.18732142857142858, 0.19089285714285714, 0.18732142857142858, 0.19089285714285714, 0.18357142857142858, 0.18321428571428572, 0.19321428571428573, 0.18357142857142858, 0.18464285714285714, 0.19035714285714286, 0.18446428571428572, 0.18, 0.18875, 0.17910714285714285, 0.17732142857142857, 0.18160714285714286, 0.17660714285714285, 0.18214285714285713, 0.18267857142857144, 0.18678571428571428, 0.19196428571428573, 0.18035714285714285]  |||  0.18321428571428572\n",
            "=========================================\n",
            "token-level kendall: [0.021794420833377386, -0.06214823121847534, -0.04447384664015105, -0.008604449775542049, -0.03904740467547863, -0.0611157090111869, -0.04786637000620179, -0.01984495556750562, -0.024996568310770902, -0.0025195995889639553, 0.04323748879005268, 0.033910377407270535, 0.07382818428325802, 0.07871972489235245, 0.10529250891065166, 0.0811202029127194, 0.0688233910563006, 0.08604937357017206, -0.018695244787642434, -0.025634113879482907, -0.07471185152591968, -0.07589947836161294, -0.11626863333537131, -0.11195156615458211, -0.08352209081857749, -0.10970828438313007, -0.08663572125315433, -0.08866001445492869, -0.10126249893142616, -0.06573245570061738, -0.07145443092514879, -0.03062755762211534]  |||  -0.024331418883494722\n",
            "token-level random_kendall: [0.008310816301454157, 0.0032561770445685974, -0.0005212747011241516, 0.0013886756365893524, -0.00034505207821875194, 0.0007193489008534175, 0.008474532310026173, 0.0012042629798025546, 0.003831532788174989, -0.0029390146937249193, -0.00494635513381656, -0.0031996759922219087, 0.006072125847639749, 0.004908129162453471, -0.003118859353272413, 0.001706633405975943, 0.001212386341993308, 0.010956662289942565, 0.0018040638240384484, 0.0006274045252177689, 0.008550760424992771, -0.004828260270857226, -0.0036246234985460213, 0.003191961149954636, 0.0013760636897407197, 0.0006105146816734822, -0.003647287051297588, 0.0002849575099017128, 0.0035679197452476623, 0.0032689530219763207, 0.003158355620802977, -0.0014419406701476156]  |||  0.0015584341799935507\n",
            "computing attention costs 22.787834405899048 seconds\n",
            "saving data costs 0.005025625228881836 seconds\n",
            "+ task=sst2\n",
            "+ python icl_ft/compute_training_example_attn.py sst2 2_7b\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/icl_ft/compute_training_example_attn.py 18\n",
            "# !!! replace by your $base_dir/ana_rlt here \n",
            "curent base_dir {base_dir}\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst2/ft 32\n",
            "loading ft data costs 13.005664825439453 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst2/ftzs 100\n",
            "loading ftzs data costs 6.576571464538574 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst2/icl 100\n",
            "loading icl data costs 3.689417600631714 seconds\n",
            "sliced icl_attn_map_ctx shape: (100, 32, 555)\n",
            "slicing icl_attn_map_ctx costs 0.11390566825866699 seconds\n",
            "compacted ft_attn_q shape: (32, 555, 2560)\n",
            "compacting ft_attn_q costs 2.615877866744995 seconds\n",
            "=========================================\n",
            "example-level recall_topk: [0.124, 0.232, 0.278, 0.148, 0.078, 0.006, 0.0, 0.12, 0.074, 0.074, 0.176, 0.148, 0.192, 0.246, 0.536, 0.26, 0.418, 0.416, 0.408, 0.396, 0.364, 0.336, 0.292, 0.24, 0.224, 0.018, 0.016, 0.0, 0.07, 0.014, 0.0, 0.002]  |||  0.18456250000000002\n",
            "example-level random_recall_topk: [0.124, 0.144, 0.176, 0.124, 0.146, 0.176, 0.156, 0.156, 0.136, 0.152, 0.16, 0.124, 0.164, 0.158, 0.156, 0.15, 0.172, 0.18, 0.152, 0.17, 0.146, 0.168, 0.124, 0.134, 0.156, 0.144, 0.15, 0.148, 0.16, 0.168, 0.176, 0.12]  |||  0.1521875\n",
            "=========================================\n",
            "example-level kendall: [-0.28165322580645163, 0.03185483870967742, -0.02403225806451614, -0.055282258064516136, -0.24923387096774188, -0.2068548387096775, -0.1594354838709678, -0.06685483870967744, -0.06536290322580647, -0.04709677419354838, 0.06721774193548387, 0.05370967741935485, 0.1164112903225807, 0.21278225806451623, 0.3296774193548388, 0.24669354838709678, 0.4253629032258064, 0.4411290322580647, 0.297016129032258, 0.41826612903225807, 0.35991935483870974, 0.33286290322580653, 0.2345967741935482, 0.1422580645161291, 0.0797983870967742, -0.16133064516129028, -0.05556451612903226, -0.16685483870967752, -0.0797177419354839, -0.08625000000000002, -0.17875, -0.2573790322580644]  |||  0.051496975806451614\n",
            "example-level random_kendall: [0.0054032258064516114, 0.0023790322580645156, -0.00028225806451612873, -0.005241935483870967, 0.012903225806451613, 0.001532258064516127, 0.005967741935483871, 0.014556451612903224, 0.022298387096774196, -0.030806451612903227, -0.018427419354838704, 0.00584677419354839, 0.022903225806451613, 0.010524193548387104, 0.014758064516129037, 0.006975806451612903, 0.002741935483870964, 0.00899193548387097, 0.005080645161290328, 0.008750000000000006, -0.020161290322580655, 0.005967741935483873, -0.014153225806451617, 0.004919354838709677, 0.011088709677419359, 0.015000000000000005, -8.064516129032196e-05, 0.0026209677419354854, 0.015282258064516129, -0.013346774193548391, -0.009032258064516128, -0.007983870967741936]  |||  0.002717993951612904\n",
            "=========================================\n",
            "token-level recall_topk: [0.1816, 0.279, 0.3204, 0.3181, 0.209, 0.2067, 0.2942, 0.282, 0.2912, 0.3362, 0.3452, 0.3125, 0.3726, 0.4389, 0.3919, 0.3721, 0.4011, 0.4297, 0.5206, 0.5188, 0.5562, 0.5333, 0.5685, 0.4579, 0.541, 0.4118, 0.5328, 0.5013, 0.4303, 0.4205, 0.4615, 0.2967]  |||  0.391675\n",
            "token-level random_recall_topk: [0.183, 0.1779, 0.1825, 0.1806, 0.1809, 0.1796, 0.1824, 0.1786, 0.181, 0.1834, 0.1818, 0.1821, 0.1828, 0.1799, 0.1823, 0.1813, 0.1786, 0.1825, 0.1837, 0.1842, 0.1826, 0.177, 0.1807, 0.18, 0.1798, 0.1796, 0.1794, 0.1871, 0.1817, 0.1792, 0.1814, 0.178]  |||  0.18111249999999998\n",
            "=========================================\n",
            "token-level kendall: [0.0666355536641896, 0.1904465906409608, 0.18516663152053353, 0.09226639555896789, 0.06710562158902858, -0.004049654822686521, 0.03385194094184868, 0.11554597625605893, 0.11359713132318049, 0.203831096887689, 0.1738099659732882, 0.18189161296769454, 0.31423910554309314, 0.3536193633732616, 0.31484449191726616, 0.2618268470494372, 0.3573312251522299, 0.37387264067490555, 0.30628831868303846, 0.357494128181593, 0.3683333649012668, 0.338231014166495, 0.34024555528980577, 0.25626619003583256, 0.3010638460917365, 0.16787770931243812, 0.2823762690636614, 0.15522966465356108, 0.21239661958278624, 0.2071556729568776, 0.14324182371308655, -0.029698925652072782]  |||  0.21257293084972043\n",
            "token-level random_kendall: [0.00015235572485608272, 0.0015854285603357455, 0.0033630612302128497, 0.0023694044433491073, 0.0004958973733409361, 0.004300632104239597, 0.0024053892716029528, 0.005446194976600903, 0.003443139177409, 0.000143861192292129, 0.005351140557180099, 6.252038406184079e-05, -0.0037957291303452496, 0.004494061432298904, -0.0006770187967560581, 0.001468691579368814, 0.0025731746077737616, -0.005874325754880796, 0.003176805233802867, 0.0028794421256680843, -0.005088083372729002, 0.0013981878183082245, -0.0019720047562396745, 0.00042349256718860693, 0.002250622509398563, -0.0058666464296639265, -0.0006092657632511132, -0.0015400131919204338, 0.003046907209503148, 0.0030662364886401834, 0.002922868587156213, -0.0009670557415420529]  |||  0.0009509178817893846\n",
            "computing attention costs 42.90255951881409 seconds\n",
            "saving data costs 0.0066874027252197266 seconds\n",
            "+ task=sst5\n",
            "+ python icl_ft/compute_training_example_attn.py sst5 2_7b\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/icl_ft/compute_training_example_attn.py 18\n",
            "# !!! replace by your $base_dir/ana_rlt here \n",
            "curent base_dir {base_dir}\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst5/ft 32\n",
            "loading ft data costs 21.565905809402466 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst5/ftzs 100\n",
            "loading ftzs data costs 6.262073993682861 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/sst5/icl 100\n",
            "loading icl data costs 3.789085865020752 seconds\n",
            "sliced icl_attn_map_ctx shape: (100, 32, 991)\n",
            "slicing icl_attn_map_ctx costs 0.20403265953063965 seconds\n",
            "compacted ft_attn_q shape: (32, 991, 2560)\n",
            "compacting ft_attn_q costs 4.571232318878174 seconds\n",
            "=========================================\n",
            "example-level recall_topk: [0.21, 0.074, 0.044, 0.054, 0.034, 0.066, 0.04, 0.0, 0.254, 0.262, 0.202, 0.484, 0.194, 0.278, 0.304, 0.058, 0.412, 0.572, 0.256, 0.29, 0.564, 0.596, 0.438, 0.506, 0.554, 0.296, 0.382, 0.364, 0.39, 0.35, 0.192, 0.19]  |||  0.2784375\n",
            "example-level random_recall_topk: [0.164, 0.18, 0.16, 0.162, 0.182, 0.148, 0.182, 0.154, 0.154, 0.15, 0.156, 0.194, 0.176, 0.146, 0.166, 0.148, 0.178, 0.148, 0.16, 0.166, 0.16, 0.16, 0.17, 0.152, 0.184, 0.124, 0.178, 0.142, 0.138, 0.166, 0.128, 0.154]  |||  0.16031250000000002\n",
            "=========================================\n",
            "example-level kendall: [0.07435483870967745, -0.05399193548387097, -0.08508064516129035, -0.15612903225806454, -0.07415322580645162, -0.1530241935483871, -0.1659677419354838, -0.23866935483870982, 0.07443548387096773, -0.1587903225806452, -0.17459677419354844, 0.20879032258064523, 0.20403225806451608, 0.22129032258064535, 0.3845161290322581, 0.6258978834462704, 0.6499596774193549, 0.6750573453801653, 0.3552016129032256, 0.4620564516129033, 0.5029838709677421, 0.5048790322580646, 0.3655645161290323, 0.3810080645161291, 0.3133870967741936, 0.04483870967741937, 0.11495967741935492, -0.01258064516129033, 0.11592741935483872, 0.20963709677419368, 0.022500000000000013, -0.08330645161290322]  |||  0.16109335896534227\n",
            "example-level random_kendall: [-0.006854838709677421, -0.0008467741935483792, -0.007338709677419359, -0.00282258064516129, 0.00883064516129032, -0.016532258064516126, -0.005645161290322582, -0.016088709677419356, 0.010120967741935492, 0.003870967741935477, -0.00012096774193548376, 0.023508064516129034, -0.008629032258064516, 0.020967741935483876, 0.009395161290322583, 0.011568712424902929, -8.064516129032598e-05, -0.014473194115558839, -0.008064516129032261, -0.03443548387096774, 0.004798387096774194, -0.01282258064516129, 0.011411290322580652, 0.022459677419354843, -0.004758064516129031, -0.014435483870967752, 0.017903225806451616, 0.01717741935483871, -0.010241935483870965, -0.008387096774193546, -0.004354838709677416, -0.000725806451612903]  |||  -0.0004889505367039642\n",
            "=========================================\n",
            "token-level recall_topk: [0.0448, 0.162, 0.2148, 0.1791, 0.1541, 0.1898, 0.1685, 0.1477, 0.2116, 0.2057, 0.155, 0.2163, 0.2184, 0.2154, 0.1891, 0.2229, 0.3284, 0.2016, 0.483, 0.4328, 0.4808, 0.4469, 0.5217, 0.4693, 0.484, 0.3942, 0.4748, 0.4544, 0.3786, 0.4092, 0.3, 0.1613]  |||  0.29113125\n",
            "token-level random_recall_topk: [0.096, 0.1012, 0.1, 0.0997, 0.1079, 0.105, 0.1027, 0.1043, 0.0976, 0.1055, 0.0998, 0.0984, 0.1009, 0.0953, 0.1044, 0.0967, 0.107, 0.1021, 0.1009, 0.1019, 0.1025, 0.0999, 0.1033, 0.1032, 0.1011, 0.1029, 0.1005, 0.0992, 0.0982, 0.1022, 0.0961, 0.0979]  |||  0.10107187499999999\n",
            "=========================================\n",
            "token-level kendall: [-0.14174250229848126, 0.07780316541655323, 0.17332143333295136, 0.2315861482239216, 0.12060710571435812, 0.14060774299376383, 0.04353338022195494, 0.07781361938811475, 0.17937314116396408, -0.025860573578407688, -0.04317565995172254, 0.1705455966857936, 0.19878296401433057, 0.14005329700538435, 0.2178799268852208, 0.3412537485507784, 0.25154972767474526, 0.42825028816381183, 0.27091065032169287, 0.3751749161634794, 0.44755417631657507, 0.436734108363099, 0.31303643265177145, 0.27678878781795996, 0.2648215726607749, 0.20548014546594537, 0.2556828338800615, 0.13531188167922228, 0.19490047331703905, 0.2038616258950422, 0.1254337527356617, 0.05796380605869932]  |||  0.19205742852918936\n",
            "token-level random_kendall: [-0.0028864138060529575, -0.0006444147638805249, 0.007008707937572016, 0.0001303275224799197, -0.0012310611338020693, 0.005050777138838312, 0.004254578135895853, -0.0004351009042546313, -0.0006185286023132938, -0.0022835818346718813, 0.0008482564363616915, 0.0024659653987144352, -0.0019152847126524114, -0.0035630102052481654, -0.0013086924285144609, 6.343751109263723e-05, -0.0009668708535557926, 0.0005000200831527309, 0.002030546155335499, 0.0024434358870639612, -0.0020645154504554553, 0.00047496666736012214, 0.0017058767598088886, -0.002842532574632598, -0.0006137538186423959, -0.0013433404802878596, -0.0010817387239854038, -6.868066036390478e-05, 0.003926037638044955, -0.001599133942841795, -0.0038995693542110592, 0.0026784025502918063]  |||  0.0001317222366139428\n",
            "computing attention costs 108.0564832687378 seconds\n",
            "saving data costs 0.008946895599365234 seconds\n",
            "+ task=subj\n",
            "+ python icl_ft/compute_training_example_attn.py subj 2_7b\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/icl_ft/compute_training_example_attn.py 18\n",
            "# !!! replace by your $base_dir/ana_rlt here \n",
            "curent base_dir {base_dir}\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/subj/ft 32\n",
            "loading ft data costs 23.822062492370605 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/subj/ftzs 100\n",
            "loading ftzs data costs 6.330927610397339 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/subj/icl 100\n",
            "loading icl data costs 4.057925701141357 seconds\n",
            "sliced icl_attn_map_ctx shape: (100, 32, 1083)\n",
            "slicing icl_attn_map_ctx costs 0.21060967445373535 seconds\n",
            "compacted ft_attn_q shape: (32, 1083, 2560)\n",
            "compacting ft_attn_q costs 5.0138537883758545 seconds\n",
            "=========================================\n",
            "example-level recall_topk: [0.16, 0.15, 0.228, 0.214, 0.244, 0.302, 0.29, 0.07, 0.304, 0.062, 0.092, 0.132, 0.396, 0.234, 0.394, 0.442, 0.572, 0.622, 0.596, 0.626, 0.646, 0.648, 0.68, 0.592, 0.612, 0.196, 0.376, 0.22, 0.208, 0.256, 0.296, 0.0]  |||  0.339375\n",
            "example-level random_recall_topk: [0.17, 0.152, 0.142, 0.168, 0.172, 0.124, 0.146, 0.176, 0.154, 0.158, 0.166, 0.164, 0.13, 0.166, 0.142, 0.17, 0.16, 0.134, 0.136, 0.156, 0.156, 0.138, 0.142, 0.138, 0.158, 0.154, 0.134, 0.148, 0.164, 0.15, 0.112, 0.16]  |||  0.15125\n",
            "=========================================\n",
            "example-level kendall: [0.06266129032258067, 0.037258064516129036, 0.04794354838709679, 0.03645161290322583, 0.16193548387096776, 0.20056451612903228, 0.21612903225806457, 0.06528225806451612, 0.19899193548387104, 0.10729838709677418, 0.1439112903225807, 0.21104838709677423, 0.3202822580645163, 0.2775403225806452, 0.36810483870967736, 0.4394283850459955, 0.45826612903225794, 0.5420802235789698, 0.41379032258064513, 0.47584677419354826, 0.4739919354838712, 0.536975806451613, 0.4638709677419357, 0.429435483870968, 0.44399193548387095, -0.054717741935483864, 0.10935483870967742, -0.1188306451612903, 0.010645161290322582, 0.11637096774193552, 0.13032258064516128, -0.2682661290322581]  |||  0.220561256922756\n",
            "example-level random_kendall: [-0.023145161290322583, -0.012056451612903222, 0.007379032258064522, -0.026693548387096797, -0.0014112903225806444, -0.002620967741935486, 0.009274193548387101, -0.003387096774193552, 0.0041129032258064545, -0.014637096774193548, 0.011612903225806452, 0.01713709677419355, -0.015443548387096781, -0.002258064516129032, -0.00875, -1.2135693069214442e-05, 0.0005241935483871013, 0.025470589862209122, 0.0030241935483870997, 0.010443548387096779, 0.0060483870967741995, 0.02181451612903227, -0.007419354838709674, 0.009395161290322583, 0.004959677419354839, -0.0008064516129032278, 0.010241935483870972, -0.0014516129032258046, 0.002822580645161292, -0.0009274193548387117, -0.00024193548387097446, -0.014717741935483863]  |||  0.00025878233794691307\n",
            "=========================================\n",
            "token-level recall_topk: [0.0585, 0.1473, 0.288, 0.2301, 0.1935, 0.2133, 0.246, 0.2094, 0.2142, 0.1916, 0.1189, 0.1774, 0.2208, 0.2015, 0.2023, 0.1983, 0.3367, 0.2292, 0.5603, 0.5358, 0.5404, 0.5171, 0.5155, 0.3582, 0.4691, 0.3646, 0.4958, 0.3651, 0.4577, 0.3593, 0.5287, 0.188]  |||  0.31039374999999997\n",
            "token-level random_recall_topk: [0.0924, 0.0896, 0.092, 0.0933, 0.094, 0.1012, 0.0955, 0.0909, 0.0914, 0.0938, 0.0927, 0.0914, 0.0947, 0.0915, 0.0949, 0.0906, 0.0929, 0.0902, 0.0942, 0.0909, 0.0893, 0.0953, 0.0911, 0.0926, 0.0976, 0.0925, 0.0963, 0.0901, 0.0917, 0.0935, 0.0908, 0.0967]  |||  0.0929875\n",
            "=========================================\n",
            "token-level kendall: [-0.040007271783346725, 0.0024888507277041234, 0.19005680373588077, 0.22782001587666512, 0.0689190734063891, 0.07766601774695199, 0.065178527870897, 0.05135727608041098, 0.05882226889727347, 0.049683606210498873, 0.006352009707350347, 0.07689230479822635, 0.1755710504037253, 0.16528744505384396, 0.15421860714464364, 0.13126272646172873, 0.2651846496715977, 0.13243126853488296, 0.37328993452680914, 0.3130069685769532, 0.32803113179790716, 0.36096944965380984, 0.3657874475087803, 0.3075608004835596, 0.3509690314531081, 0.37728538437074327, 0.37409346399687315, 0.2964338263683979, 0.3591809415342575, 0.332753684557147, 0.32706563570927744, 0.16684311103961566]  |||  0.20288925131633007\n",
            "token-level random_kendall: [-0.0015199139452897214, -0.00037615271287404656, 0.0012097808082746902, 0.0014695811092767478, -0.00014697782553791322, 0.0011217431652208946, -0.0023358105236908617, 0.0006114271905280438, 0.000478402518452665, 0.0029091346982637084, -0.0018570554577103083, -4.207861433789019e-05, 0.002126291295300044, 0.002994931204428294, 0.004895817913348081, -0.001915705005432849, -0.0006993893690903556, 6.881820630306595e-06, 0.0011851052671979828, -0.001849940461344131, 0.00039422813739806926, 0.0007547581923019031, 0.0001593168994715962, 0.001141598022577458, -0.0015838039334493087, 0.0028890473004036738, 0.0023141719287277955, -0.004996909646195601, 0.0022689225554451613, -0.0004935695623012708, 0.0032883573230483793, 0.001144855411509347]  |||  0.0004858451782672058\n",
            "computing attention costs 96.43050622940063 seconds\n",
            "saving data costs 0.014573097229003906 seconds\n",
            "+ task=mr\n",
            "+ python icl_ft/compute_training_example_attn.py mr 2_7b\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/icl_ft/compute_training_example_attn.py 18\n",
            "# !!! replace by your $base_dir/ana_rlt here \n",
            "curent base_dir {base_dir}\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/mr/ft 32\n",
            "loading ft data costs 24.10317587852478 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/mr/ftzs 100\n",
            "loading ftzs data costs 7.114201068878174 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/mr/icl 100\n",
            "loading icl data costs 3.93247127532959 seconds\n",
            "sliced icl_attn_map_ctx shape: (100, 32, 1105)\n",
            "slicing icl_attn_map_ctx costs 0.2157881259918213 seconds\n",
            "compacted ft_attn_q shape: (32, 1105, 2560)\n",
            "compacting ft_attn_q costs 5.0415496826171875 seconds\n",
            "=========================================\n",
            "example-level recall_topk: [0.09, 0.228, 0.214, 0.142, 0.092, 0.038, 0.074, 0.184, 0.198, 0.046, 0.008, 0.122, 0.112, 0.106, 0.098, 0.14, 0.204, 0.264, 0.422, 0.25, 0.258, 0.238, 0.164, 0.084, 0.368, 0.0, 0.028, 0.0, 0.002, 0.06, 0.008, 0.0]  |||  0.1325625\n",
            "example-level random_recall_topk: [0.148, 0.158, 0.138, 0.16, 0.164, 0.178, 0.14, 0.162, 0.164, 0.164, 0.184, 0.15, 0.138, 0.182, 0.176, 0.164, 0.166, 0.164, 0.144, 0.16, 0.14, 0.144, 0.168, 0.17, 0.146, 0.152, 0.176, 0.176, 0.152, 0.134, 0.178, 0.19]  |||  0.1603125\n",
            "=========================================\n",
            "example-level kendall: [-0.13919354838709685, -0.014879032258064523, 0.037016129032258066, -0.006290322580645163, -0.07278225806451616, -0.04298387096774195, 0.034637096774193556, -0.047459677419354855, 0.031774193548387106, -0.06286290322580648, -0.05895161290322582, -0.00524193548387097, 0.03133064516129033, 0.1, 0.17084677419354843, 0.3798445774704861, 0.4379032258064515, 0.4773783963446901, 0.43338709677419357, 0.6653225806451613, 0.6276209677419358, 0.5233467741935481, 0.044758064516129056, 0.1246370967741936, 0.12213709677419354, -0.4606048387096775, -0.24427419354838711, -0.43986389856994085, -0.36145161290322586, -0.027540322580645163, -0.1243951612903225, -0.38237903225806447]  |||  0.054712077956252304\n",
            "example-level random_kendall: [-0.007903225806451612, 0.04112903225806453, 0.012217741935483866, -0.007862903225806451, 0.009637096774193549, -0.010000000000000002, -0.006250000000000002, 0.017500000000000012, -0.0013306451612903236, 0.0020967741935483913, -0.00931451612903226, -0.0023387096774193567, -0.006774193548387098, -0.00310483870967742, 0.02387096774193547, -0.004975289594796994, 0.01217741935483871, 0.005328210797599138, 0.0037096774193548405, -0.0059274193548387085, -0.0082258064516129, 0.013427419354838715, 4.032258064516285e-05, 0.022580645161290325, -0.022096774193548385, -0.01237903225806452, 0.00616935483870968, -0.0033687470490357473, -0.018145161290322585, -0.0014919354838709676, 0.016774193548387092, -0.010927419354838713]  |||  0.0013825699584342325\n",
            "=========================================\n",
            "token-level recall_topk: [0.092, 0.1731, 0.192, 0.1419, 0.1561, 0.2, 0.195, 0.1747, 0.1821, 0.1752, 0.1324, 0.1418, 0.2165, 0.2215, 0.1984, 0.1779, 0.303, 0.1708, 0.6363, 0.543, 0.6658, 0.5584, 0.7017, 0.4177, 0.6187, 0.4392, 0.6389, 0.5723, 0.4903, 0.6046, 0.6328, 0.3491]  |||  0.34728749999999997\n",
            "token-level random_recall_topk: [0.0902, 0.0894, 0.0947, 0.0914, 0.0924, 0.0866, 0.0939, 0.09, 0.0897, 0.0927, 0.0908, 0.091, 0.0862, 0.0869, 0.0946, 0.0888, 0.0879, 0.0916, 0.0933, 0.0957, 0.0935, 0.0949, 0.0942, 0.0866, 0.0936, 0.0893, 0.0894, 0.0886, 0.0894, 0.0921, 0.0881, 0.0864]  |||  0.090746875\n",
            "=========================================\n",
            "token-level kendall: [0.06877048591186456, 0.11965130595996389, 0.16976242627967827, 0.17384132591151658, 0.078267316416539, 0.1352952589777992, 0.14008437287044312, 0.10245295722911754, 0.0906916868070012, 0.11178586337096413, 0.09726811638155483, 0.11657082426610212, 0.17537946501933646, 0.20714030430849587, 0.20584600469628106, 0.1701199850657554, 0.33455541020198404, 0.1693044884934558, 0.47786927959791903, 0.4608562565793209, 0.49275096060846624, 0.4466047633854683, 0.4763123771203743, 0.4392611921673091, 0.46877443491984216, 0.37659119525392065, 0.43092364511498255, 0.3533075237419208, 0.4195646730080621, 0.39483147687578585, 0.3825883062425476, 0.15756778200115262]  |||  0.26389348327452894\n",
            "token-level random_kendall: [0.0035763280728161677, 0.003754687438720459, 0.0018232463071976913, -0.0019829771582113593, 0.0033967300506886045, 0.001382715351922802, 0.0028028919334756167, -4.7092891624039916e-05, 9.28475622336243e-05, -0.0013795723266159944, -0.002192042684818408, -0.0017098287980995173, -0.0005574692773768413, -0.005952190058105839, -0.00029515955173827114, 0.0006561642582800703, -0.002362660256303769, 0.0011773408984638105, -0.0019878661635978835, -0.003268674613208997, 0.002792912950658076, -0.0008954165027334602, -0.0010086642468351828, 0.0009650275697723898, 0.0009645104779661375, 0.00391069720709973, -0.00168314307358119, -0.001265349955484173, 0.001631803235764799, -0.001773984930336932, -4.108230585132084e-05, 0.0007324184605879316]  |||  3.928584316014793e-05\n",
            "computing attention costs 94.97502589225769 seconds\n",
            "saving data costs 0.008482217788696289 seconds\n",
            "+ task=agnews\n",
            "+ python icl_ft/compute_training_example_attn.py agnews 2_7b\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/icl_ft/compute_training_example_attn.py 18\n",
            "# !!! replace by your $base_dir/ana_rlt here \n",
            "curent base_dir {base_dir}\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/agnews/ft 32\n",
            "loading ft data costs 53.90175819396973 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/agnews/ftzs 100\n",
            "loading ftzs data costs 8.568941831588745 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/agnews/icl 100\n",
            "loading icl data costs 5.274733781814575 seconds\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/icl_ft/compute_training_example_attn.py\", line 106, in <module>\n",
            "    icl_attn_map_ctx = slice_icl_attn_map(icl_attn_map_ctx)\n",
            "  File \"/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/icl_ft/compute_training_example_attn.py\", line 101, in slice_icl_attn_map\n",
            "    icl_attn_map_ctx = icl_attn_map_ctx[:, :, slice_idx]\n",
            "IndexError: index 1759 is out of bounds for axis 2 with size 1759\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python icl_ft/compute_training_example_attn.py agnews 2_7b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4r-GQK-314VI",
        "outputId": "eca9fd1a-eb62-4167-807d-5cf992a3a089"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/icl_ft/compute_training_example_attn.py 18\n",
            "# !!! replace by your $base_dir/ana_rlt here \n",
            "curent base_dir {base_dir}\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/agnews/ft 32\n",
            "loading ft data costs 48.69584083557129 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/agnews/ftzs 100\n",
            "loading ftzs data costs 6.61359715461731 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_2_7b/agnews/icl 100\n",
            "loading icl data costs 3.9587454795837402 seconds\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/icl_ft/compute_training_example_attn.py\", line 106, in <module>\n",
            "    icl_attn_map_ctx = slice_icl_attn_map(icl_attn_map_ctx)\n",
            "  File \"/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/icl_ft/compute_training_example_attn.py\", line 101, in slice_icl_attn_map\n",
            "    icl_attn_map_ctx = icl_attn_map_ctx[:, :, slice_idx]\n",
            "IndexError: index 1759 is out of bounds for axis 2 with size 1759\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python icl_ft/compute_training_example_attn.py agnews 1_3b\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMZCk7pG14-J",
        "outputId": "2412b6ad-3f9c-40dc-dba6-a8dee31dd346"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/icl_ft/compute_training_example_attn.py 18\n",
            "# !!! replace by your $base_dir/ana_rlt here \n",
            "curent base_dir {base_dir}\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/agnews/ft 32\n",
            "loading ft data costs 28.838714122772217 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/agnews/ftzs 100\n",
            "loading ftzs data costs 4.146722316741943 seconds\n",
            "/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/ana_rlt/en_dense_lm_1_3b/agnews/icl 100\n",
            "loading icl data costs 2.6836910247802734 seconds\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/icl_ft/compute_training_example_attn.py\", line 106, in <module>\n",
            "    icl_attn_map_ctx = slice_icl_attn_map(icl_attn_map_ctx)\n",
            "  File \"/content/drive/MyDrive/Colab-Notebooks/INF502_JAN2023_A1/LMOps/understand_icl/icl_ft/compute_training_example_attn.py\", line 101, in slice_icl_attn_map\n",
            "    icl_attn_map_ctx = icl_attn_map_ctx[:, :, slice_idx]\n",
            "IndexError: index 1759 is out of bounds for axis 2 with size 1759\n"
          ]
        }
      ]
    }
  ]
}